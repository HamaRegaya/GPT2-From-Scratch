{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamaRegaya/GPT2-From-Scratch/blob/main/Copy_of_Train_gpt2_from_scratch_Python_NumPy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vgzUZ5y56Ko"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Ce notebook représente une implémentation fondamentale de GPT-2 en Python/Numpy, réalisée par notre équipe composée de Aya Omezzine, Mohamed Aziz Omezzine, Yahya Samet, et Mohamed Regaya. L'objectif est de comprendre et de maîtriser le fonctionnement de GPT-2 en créant notre propre version à partir de zéro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWJwIC4m56Ks"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DmF3sxC56Ks",
        "outputId": "c3bb4bc0-53f4-4333-98b6-31b741daa32d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running as a Jupyter notebook - intended for development only!\n"
          ]
        }
      ],
      "source": [
        "# Vérifie si le notebook est exécuté dans Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    # Installe la bibliothèque Easy-Transformer depuis GitHub\n",
        "    %pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
        "\n",
        "    # Installe une autre version de node pour accélérer PySvelte\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "\n",
        "    # Installe la bibliothèque PySvelte depuis GitHub\n",
        "    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "\n",
        "    # Installe les bibliothèques fancy_einsum et einops\n",
        "    %pip install fancy_einsum\n",
        "    %pip install einops\n",
        "\n",
        "# Si une exception est levée, cela signifie que le notebook est exécuté dans Jupyter Notebook\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSKaI4Ab56Ku"
      },
      "outputs": [],
      "source": [
        "# Importe le module einops pour la manipulation flexible des dimensions\n",
        "import einops\n",
        "\n",
        "# Importe la fonction einsum du module fancy_einsum pour une utilisation simplifiée des opérations einsum\n",
        "from fancy_einsum import einsum\n",
        "\n",
        "# Importe la classe dataclass du module dataclasses pour créer des classes de données\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# Importe la classe EasyTransformer du module easy_transformer pour l'utilisation de modèles de transformer\n",
        "from easy_transformer import EasyTransformer\n",
        "\n",
        "# Importe le module torch pour les opérations et structures de données tensorielles\n",
        "import torch\n",
        "\n",
        "# Importe le module nn du package torch pour la définition de couches de réseaux de neurones\n",
        "import torch.nn as nn\n",
        "\n",
        "# Importe le module numpy pour le calcul numérique et la manipulation de tableaux\n",
        "import numpy as np\n",
        "\n",
        "# Importe le module math pour les fonctions mathématiques standard\n",
        "import math\n",
        "\n",
        "# Importe la fonction get_corner, gelu_new, tokenize_and_concatenate du module utils du package easy_transformer\n",
        "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
        "\n",
        "# Importe le module tqdm.auto pour l'affichage de la barre de progression lors de l'exécution de boucles\n",
        "import tqdm.auto as tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5daWwYN56Ku",
        "outputId": "79ac79f4-502d-4ee8-eed9-0004c1486814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moving model to device:  cuda\n",
            "Finished loading pretrained model gpt2-small into EasyTransformer!\n"
          ]
        }
      ],
      "source": [
        "# Charge un modèle GPT-2 pré-entraîné avec des configurations spécifiques\n",
        "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvGaOYhg56Ku"
      },
      "source": [
        "# Comprendre les inputs et les outputs d'un Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhaFTFgH56Ku"
      },
      "source": [
        "## Quel est l'objectif d'un transformeur ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXYerGAW56Ku"
      },
      "source": [
        "**Les transformers existent pour modéliser du texte !**\n",
        "\n",
        "Nous allons nous concentrer sur les transformers de style GPT-2. Leur caractéristique clé : ils génèrent du texte ! Vous fournissez du langage, et le modèle génère une distribution de probabilité sur les tokens. Et vous pouvez répéter l'échantillonnage à partir de cela pour générer du texte !\n",
        "\n",
        "### Comment le modèle est-il entraîné ?\n",
        "\n",
        "Vous lui donnez une quantité de texte, et vous l'entraînez à prédire le token suivant.\n",
        "\n",
        "Il est important de noter que si vous donnez 100 tokens à un modèle dans une séquence, il prédit le token suivant pour chaque préfixe, c'est-à-dire qu'il produit 100 prédictions. C'est un peu étrange, mais c'est beaucoup plus facile à réaliser ainsi. De plus, cela rend l'entraînement plus efficace, car vous obtenez 100 retours d'information au lieu d'un seul.\n",
        "\n",
        "#### Objection: N'est-ce pas trivial pour les 99 premiers ?\n",
        "\n",
        "Non ! Nous faisons en sorte que le transformeur ait une attention causale. L'élément clé est qu'il ne peut déplacer l'information que vers l'avant dans la séquence. La prédiction de ce qui vient après le token 50 dépend uniquement des 50 premiers tokens, et non du token 51. (Jargon : *autoregressif*)\n",
        "\n",
        "### Conclusion importante :\n",
        "\n",
        "Les transformers sont des *moteurs de modélisation de séquence*. Ils effectuent le même traitement en parallèle à chaque position de séquence, peuvent déplacer l'information entre les positions avec attention, et peuvent conceptuellement prendre une séquence de longueur arbitraire (ce qui n'est pas vraiment vrai, voir plus tard)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xuh52qZ56Kv"
      },
      "source": [
        "## Tokens - Entrées du Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-xEtmQ356Kv"
      },
      "source": [
        "Point clé : L'entrée est du langage (c'est-à-dire une séquence de caractères, de chaînes de caractères, etc.).\n",
        "\n",
        "### Comment convertissons-nous le langage en vecteurs ?\n",
        "\n",
        "Les modèles d'apprentissage automatique prennent en entrée des vecteurs, pas des choses étranges comme du langage - comment procédons-nous à la conversion ?\n",
        "\n",
        "#### Idée : entiers en vecteurs\n",
        "\n",
        "Nous créons essentiellement une table de recherche. Appelée embedding.\n",
        "\n",
        "Jargon: **One-hot encoding**Nous faisons correspondre, par exemple, des nombres de 1 à 100 à un vecteur de 100 dimensions, avec un 1 à la k-ème position et des 0 partout ailleurs. L'intuition clé est que les encodages one-hot permettent de considérer chaque entier indépendamment - utile lorsque les entiers correspondent à des étiquettes. integers = labels.\n",
        "\n",
        "Dimensions = things qui varient indépendamment. Chaque entrée a sa propre dimension, donc chaque entrée peut être considérée indépendamment, nous n'incorporons aucune relation.\n",
        "\n",
        "Lookup tables <=> Multipliez une matrice fixe par le vecteur encodé en one-hot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5D0V-St56Kv"
      },
      "source": [
        "### Tokens:  Langage en séquence d'entiers\n",
        "\n",
        "Idée centrale : Nous avons besoin d'un modèle capable de traiter du texte arbitraire. Nous voulons le convertir en entiers, et nous voulons que ces entiers soient dans une plage bornée.\n",
        "\n",
        "**Idée :** Former un vocabulaire !\n",
        "\n",
        "**Idée 1:** Obtenir un dictionnaire !\n",
        "\n",
        "**Problème:** Il ne peut pas gérer du texte arbitraire (par exemple, des URL, de la ponctuation, etc.) et ne peut pas gérer les fautes d'orthographe..\n",
        "\n",
        "**Idée 2:** Vocabulaire = 256 caractères ASCII. Taille de vocabulaire fixe, peut gérer du texte arbitraire, etc.\n",
        "\n",
        "**Problème:** Perd la structure du langage - certaines séquences de caractères sont plus significatives que d'autres.\n",
        "\n",
        "Par exemple, \"langage\" est beaucoup plus significatif que \"hjksdfiu\" - nous voulons que le premier soit un seul token, le deuxième non. C'est une utilisation plus efficace de notre vocabulaire.\n",
        "\n",
        "#### Que se passe-t-il réellement ?\n",
        "\n",
        "Cette chose super maudite appelée Encodage Byte-Pair (BPE)\n",
        "\n",
        "\n",
        "Nous commençons avec les 256 caractères ASCII comme nos tokens, puis trouvons la paire de tokens la plus courante, et la fusionnons en un nouveau token. Par exemple, \" t\" est la paire la plus courante, donc c'est notre prochain token ! Répéter 50000 fois..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf7Anhhl56Kv",
        "outputId": "1bc9c918-fc45-4b01-9639-632f3793fc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
            "\n",
            "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
            "\n",
            "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Trie le vocabulaire du modèle GPT-2 par ordre alphabétique des tokens\n",
        "sorted_vocab = sorted(list(reference_gpt2.tokenizer.vocab.items()), key=lambda n:n[1])\n",
        "\n",
        "# Affiche les 20 premiers tokens et leurs indices dans le vocabulaire trié\n",
        "print(sorted_vocab[:20])\n",
        "print()\n",
        "\n",
        "# Affiche les tokens et leurs indices dans le vocabulaire trié, de l'index 250 à l'index 269\n",
        "print(sorted_vocab[250:270])\n",
        "print()\n",
        "\n",
        "# Affiche les tokens et leurs indices dans le vocabulaire trié, de l'index 990 à l'index 1009\n",
        "print(sorted_vocab[990:1010])\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78x76PEl56Kv"
      },
      "source": [
        "Cela devient bizarre et ésotérique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVHEuZIV56Kw",
        "outputId": "ae0af259-d89b-4a73-ba6a-b69b29c13c99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Revolution', 50237),\n",
              " ('Ġsnipers', 50238),\n",
              " ('Ġreverted', 50239),\n",
              " ('Ġconglomerate', 50240),\n",
              " ('Terry', 50241),\n",
              " ('794', 50242),\n",
              " ('Ġharsher', 50243),\n",
              " ('Ġdesolate', 50244),\n",
              " ('ĠHitman', 50245),\n",
              " ('Commission', 50246),\n",
              " ('Ġ(/', 50247),\n",
              " ('âĢ¦.\"', 50248),\n",
              " ('Compar', 50249),\n",
              " ('Ġamplification', 50250),\n",
              " ('ominated', 50251),\n",
              " ('Ġregress', 50252),\n",
              " ('ĠCollider', 50253),\n",
              " ('Ġinformants', 50254),\n",
              " ('Ġgazed', 50255),\n",
              " ('<|endoftext|>', 50256)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Affiche les 20 derniers tokens et leurs indices dans le vocabulaire trié\n",
        "print(sorted_vocab[-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwaVzK4956Kw"
      },
      "source": [
        "Utilisez la méthode `to_tokens`pour convertir du texte en nombres\n",
        "\n",
        "Préfixe avec un jeton spécial pour donner à l'attention une position de repos, désactivez avec `prepend_bos=False`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8R1aj7j56Kw",
        "outputId": "3549aea0-a883-4a1f-f2a5-a3fc1a0fa4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50256, 15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,\n",
            "          6067,     0]])\n",
            "tensor([[15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,  6067,\n",
            "             0]])\n"
          ]
        }
      ],
      "source": [
        "# Convertit le texte en nombres en utilisant la méthode to_tokens avec un préfixe de jeton spécial (par défaut)\n",
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\"))\n",
        "\n",
        "# Convertit le texte en nombres en utilisant la méthode to_tokens sans préfixe de jeton spécial (prepend_bos=False)\n",
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\", prepend_bos=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a3P6epd56Kw"
      },
      "source": [
        "###  Lamentation : La tokenisation est difficile\n",
        "\n",
        "Que ce soit une majuscule ou un espace au début d'un mot, cela compte!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl_wy1OU56Kw",
        "outputId": "ec73431d-35b1-4704-ea11-0c98fc320ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<|endoftext|>', 'R', 'alph']\n",
            "['<|endoftext|>', ' Ralph']\n",
            "['<|endoftext|>', ' r', 'alph']\n",
            "['<|endoftext|>', 'ral', 'ph']\n"
          ]
        }
      ],
      "source": [
        "# Convertit le token \"Ralph\" en une chaîne de caractères de jetons en utilisant le modèle reference_gpt2\n",
        "print(reference_gpt2.to_str_tokens(\"Ralph\"))\n",
        "\n",
        "# Convertit le token \" Ralph\" (avec un espace initial) en une chaîne de caractères de jetons en utilisant le modèle reference_gpt2\n",
        "print(reference_gpt2.to_str_tokens(\" Ralph\"))\n",
        "\n",
        "# Convertit le token \" ralph\" (avec une minuscule) en une chaîne de caractères de jetons en utilisant le modèle reference_gpt2\n",
        "print(reference_gpt2.to_str_tokens(\" ralph\"))\n",
        "\n",
        "# Convertit le token \"ralph\" (en minuscules) en une chaîne de caractères de jetons en utilisant le modèle reference_gpt2\n",
        "print(reference_gpt2.to_str_tokens(\"ralph\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmGCJprH56Kw"
      },
      "source": [
        "L'arithmétique est un véritable gâchis : Les longueurs sont incohérentes, les nombres communs se regroupent..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JH-gGIG56Kw",
        "outputId": "ae77cbf5-e285-4440-a434-87f44cfd0d87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<|endoftext|>',\n",
              " '568',\n",
              " '73',\n",
              " '+',\n",
              " '318',\n",
              " '46',\n",
              " '23',\n",
              " '=',\n",
              " '123',\n",
              " '45',\n",
              " '67',\n",
              " '89',\n",
              " '-',\n",
              " '1',\n",
              " '000000',\n",
              " '000']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convertit la chaîne de caractères en tokens utilisés par le modèle GPT-2\n",
        "tokens = reference_gpt2.to_str_tokens(\"56873+3184623=123456789-1000000000\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTBi004y56Kw"
      },
      "source": [
        "###Conclusion Principale :\n",
        "* Nous apprenons un dictionnaire de vocabulaire de  tokens (sous-mots).\n",
        "\n",
        "* Nous convertissons (approximativement) sans perte le langage en entiers en le tokenisant.\n",
        "\n",
        "* Nous convertissons les entiers en vecteurs via une table de recherche.\n",
        "\n",
        "* Remarque : l'entrée du transformeur est une séquence de *tokens* (c'est-à-dire des entiers), pas des vecteurs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK8PhUDE56Kx"
      },
      "source": [
        "## Logits - Sorties du Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLDx2LME56Kx"
      },
      "source": [
        "**Objectif :** Distribution de probabilité sur les prochains tokens. (pour chaque *préfixe* de la séquence - étant donné n tokens, nous faisons n prédictions pour le prochain token)\n",
        "\n",
        "**Problème :** Comment convertir un vecteur en une distribution de probabilité ?\n",
        "\n",
        "**Answer:** Utiliser un softmax ($x_i \\to \\frac{e^{x_i}}{\\sum e^{x_j}}$),'exponentielle rend tout positif, la normalisation fait que la somme est égale à un.\n",
        "\n",
        "Ainsi, le modèle produit un tenseur de logits, un vecteur de taille $d_{vocab}$ pour chaque token d'entrée.\n",
        "\n",
        "Nous pouvons utiliser cela pour générer des éléments !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjDi41Jn56Kx"
      },
      "source": [
        "## Generation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weaEo6wX56Kx"
      },
      "source": [
        "**Étape  1:** Convertir le texte en j tokens\n",
        "\n",
        "Shape = batch x position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4zLmb4H56Kx",
        "outputId": "dc007058-869a-4833-ad64-9a4f1dfb39ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0]])\n",
            "torch.Size([1, 35])\n",
            "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
          ]
        }
      ],
      "source": [
        "# Définit un texte de référence\n",
        "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
        "\n",
        "# Convertit le texte de référence en tokens avec le modèle GPT-2\n",
        "tokens = reference_gpt2.to_tokens(reference_text)\n",
        "\n",
        "# Affiche les tokens générés\n",
        "print(tokens)\n",
        "\n",
        "# Affiche la forme (shape) des tokens\n",
        "print(tokens.shape)\n",
        "\n",
        "# Convertit les tokens en chaînes de caractères\n",
        "print(reference_gpt2.to_str_tokens(tokens))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB6CS92s56Kx"
      },
      "source": [
        "**Étape  2:** Mapper les tokens aux logits\n",
        "\n",
        "(run_with_cache signifie mettre en cache toutes les activations intermédiaires, ce qui n'est pas important pour le moment)\n",
        "\n",
        "shape = batch x position x d_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH3wvZyq56Kx",
        "outputId": "e8a7978d-0a3f-48f3-907b-7f2dfb8fce5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "# Transfère les données des jetons vers le GPU pour accélérer le traitement si possible\n",
        "tokens = tokens.cuda()\n",
        "\n",
        "# Exécute le modèle GPT-2 avec en mémoire cache pour traiter les jetons et obtenir les logits de sortie\n",
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "\n",
        "# Affiche la forme des logits, c'est-à-dire la taille de la sortie du modèle\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLqnlrmB56Kx"
      },
      "source": [
        "**Étape  3:** Convertir les logits en une distribution avec un softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE7Y-Fqq56Kx",
        "outputId": "4b8024bc-c11a-4e45-fd6c-4570ee220734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 35, 50257])\n",
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "# Calcule le log softmax des logits pour obtenir les probabilités log-softmax\n",
        "log_probs = logits.log_softmax(dim=-1)\n",
        "\n",
        "# Calcule le softmax des logits pour obtenir les probabilités softmax\n",
        "probs = logits.log_softmax(dim=-1)\n",
        "\n",
        "# Affiche les dimensions des probabilités log-softmax et softmax\n",
        "print(log_probs.shape)\n",
        "print(probs.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzJiF8pF56Ky"
      },
      "source": [
        "**Étape bonus :** Quel est le Token suivant le plus probable à chaque position ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNp_GggW56Ky",
        "outputId": "7f9fcd0a-4778-4aac-b478-23d37919d724"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<|endoftext|>', '\\n'),\n",
              " ('I', \"'m\"),\n",
              " (' am', ' a'),\n",
              " (' an', ' avid'),\n",
              " (' amazing', ' person'),\n",
              " (' aut', 'od'),\n",
              " ('ore', 'sp'),\n",
              " ('gressive', '.'),\n",
              " (',', ' and'),\n",
              " (' dec', 'ently'),\n",
              " ('oder', ','),\n",
              " ('-', 'driven'),\n",
              " ('only', ' programmer'),\n",
              " (',', ' and'),\n",
              " (' G', 'IM'),\n",
              " ('PT', '-'),\n",
              " ('-', 'only'),\n",
              " ('2', '.'),\n",
              " (' style', ','),\n",
              " (' transformer', '.'),\n",
              " ('.', ' I'),\n",
              " (' One', ' of'),\n",
              " (' day', ' I'),\n",
              " (' I', ' will'),\n",
              " (' will', ' be'),\n",
              " (' exceed', ' my'),\n",
              " (' human', 'ly'),\n",
              " (' level', ' of'),\n",
              " (' intelligence', ' and'),\n",
              " (' and', ' I'),\n",
              " (' take', ' over'),\n",
              " (' over', ' the'),\n",
              " (' the', ' world'),\n",
              " (' world', '.'),\n",
              " ('!', ' I')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine les jetons originaux et les jetons décodés en une liste de tuples\n",
        "list(zip(reference_gpt2.to_str_tokens(reference_text), reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09bFdLBX56Ky"
      },
      "source": [
        "\n",
        "**Étape 4 :** Mapper la distribution à un token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n91Ylvld56Ky",
        "outputId": "809f26b1-3d0b-454a-bb6e-e9246b4aaca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(314, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Calcul du prochain token en prenant l'indice de la valeur maximale dans les logits du dernier token généré\n",
        "next_token = logits[0, -1].argmax(dim=-1)\n",
        "\n",
        "# Affichage du prochain token\n",
        "print(next_token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59TaclI356Ky"
      },
      "source": [
        "**Step 5:** Ajoutez ceci à la fin de l'entrée, puis relancez.\n",
        "\n",
        "(Il existe des moyens plus efficaces de le faire, mais peu importe, cela n'a pas d'importance conceptuellement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_8D8zCu56Ky",
        "outputId": "6e70ca77-683f-4a05-8d00-a43efaac4959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New Input: tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0,   314]], device='cuda:0')\n",
            "torch.Size([1, 36])\n",
            "New Input: <|endoftext|>I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world! I\n",
            "torch.Size([1, 36, 50257])\n",
            "tensor(716, device='cuda:0')\n",
            " am\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "# Concatène le token suivant à la séquence actuelle pour former la nouvelle séquence d'entrée\n",
        "next_tokens = torch.cat([tokens, torch.tensor(next_token, device='cuda', dtype=torch.int64)[None, None]], dim=-1)\n",
        "\n",
        "# Passe la nouvelle séquence d'entrée au modèle GPT-2 pour obtenir de nouveaux logits\n",
        "new_logits = reference_gpt2(next_tokens)\n",
        "\n",
        "# Affiche la nouvelle séquence d'entrée\n",
        "print(\"Nouvelle Entrée :\", next_tokens)\n",
        "\n",
        "# Affiche la forme de la nouvelle séquence d'entrée\n",
        "print(next_tokens.shape)\n",
        "\n",
        "# Affiche la nouvelle séquence d'entrée décodée\n",
        "print(\"Nouvelle Entrée décodée :\", reference_gpt2.tokenizer.decode(next_tokens[0]))\n",
        "\n",
        "# Affiche la forme des nouveaux logits\n",
        "print(new_logits.shape)\n",
        "\n",
        "# Affiche l'indice du token prédit avec la plus grande probabilité dans les nouveaux logits\n",
        "print(new_logits[-1, -1].argmax(-1))\n",
        "\n",
        "# Affiche le token prédit avec la plus grande probabilité décodé\n",
        "print(reference_gpt2.tokenizer.decode(new_logits[-1, -1].argmax(-1)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEdSDOVr56Ky"
      },
      "source": [
        "## Principales conclusions :\n",
        "\n",
        "* Prend en entrée du langage et prédit le prochain token (pour chaque token de manière causale).\n",
        "* Nous convertissons les entiers en vecteurs avec une table de recherche.\n",
        "\n",
        "* La sortie est un vecteur de logits (un pour chaque token d'entrée). Nous le convertissons en une distribution de probabilité avec un softmax, puis pouvons convertir cela en un token (par exemple, en prenant le plus grand logit, ou en échantillonnant).\n",
        "\n",
        "* Nous ajoutons cela à l'entrée + exécutons à nouveau pour générer plus de texte (Jargon: *autoregressive*)\n",
        "\n",
        "* Point de niveau méta : Les transformers sont des modèles d'opération de séquence, ils prennent en entrée une séquence, effectuent un traitement en parallèle à chaque position, et utilisent l'attention pour déplacer l'information entre les positions !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxN53Z7856Ky"
      },
      "source": [
        "# Implémentation propre du Transformer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STceROwX56K6"
      },
      "source": [
        "![](https://github.com/neelnanda-io/Easy-Transformer/blob/clean-transformer-demo/transformer_overview.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjifwLfK56K6"
      },
      "source": [
        "High-Level architecture:\n",
        "\n",
        "Go watch my [Transformer Circuits walkthrough](https://www.youtube.com/watch?v=KV5gbOmHbjU) if you want more intuitions!\n",
        "\n",
        "(Diagram is bottom to top)\n",
        "\n",
        "* Tokens d'entrée, entiers\n",
        "* L'embedding est une table de recherche qui mappe les tokens à des vecteurs\n",
        "    * Résidant dans*residual stream*\n",
        "* Residual stream -la somme de toutes les sorties précédentes des couches du modèle, est l'entrée de chaque nouvelle couche.\n",
        "    * Vraiment fondamental. C'est l'objet central du transformer.\n",
        "        * C'est ainsi que le modèle se souvient des choses, déplace l'information entre les couches pour la composition, et c'est le médium utilisé pour stocker l'information que l'attention déplace entre les positions.\n",
        "* Ensuite, nous avons une série de $n_{layers}$ blocs transformateurs\n",
        "    * un bloc contient une couche d'attention et une couche MLP, mais nous disons qu'un transformer a k couches s'il a k blocs (c'est-à-dire 2k couches au total).\n",
        "* Tout d'abord, nous avons l'attention. Cela déplace l'information des positions précédentes dans la séquence au token actuel.\n",
        "    * Nous faisons cela pour chaque token en parallèle en utilisant les mêmes paramètres. La seule différence est que nous regardons en arrière seulement, donc les tokens plus tardifs ont plus de place pour regarder en arrière.\n",
        "        * Nous regardons en arrière pour pouvoir prédire le prochain token sans tricher.\n",
        "    * Seule partie d'un transformer qui déplace l'information entre les positions.\n",
        "    * Composée de $n_heads$  têtes - chacune avec ses propres paramètres, son propre motif d'attention, et sa propre information sur la façon de copier les choses de la source à la destination.\n",
        "        * Les têtes agissent de manière indépendante et additive, nous ajoutons simplement leurs sorties ensemble, et de retour dans le flux\n",
        "    * Chaque tête :\n",
        "        * Produit un motif d'attention pour chaque token de destination, une distribution de probabilité des tokens source précédents (y compris le token actuel) pondérant la quantité d'information à copier.\n",
        "            * Faites cela pour chaque paire de tokens\n",
        "            * Copiez l'information de la même manière depuis chaque token source.\n",
        "                * Ce que nous copions dépend du flux résiduel du token source. Cela ne signifie pas nécessairement l'information sur quel token texte se trouve à la position du token source\n",
        "                * Copier = appliquer une map linéaire.\n",
        "        * Point fondamental : Déterminer quels tokens source copier l'info est un circuit séparé de déterminer comment copier cette information.\n",
        "        * Dimension interne de la tête $d_{head} = \\frac{d_{model}}{n_{heads}}\n",
        "* MLP Layers - standard neural network. Single hidden layer, linear map -> GELU activation -> linear map\n",
        "    * L'activation exacte n'est pas conceptuellement importante.\n",
        "    * MLa dimension médiane est normalement $d_{mlp} = 4 \\times d_{model}$\n",
        "        * Pourquoi les ratios sont ce qu'ils sont n'est pas super important - cela n'a pas beaucoup d'importance, les gens ont essentiellement suivi aveuglément ce que GPT a fait.\n",
        "    * Intuition - une fois que l'attention a déplacé l'information pertinente vers une seule position dans le flux résiduel, les MLP peuvent réellement faire des calculs, de la réflexion, chercher de l'information, etc.\n",
        "        * Un gros problème ouvert dans l'interprétabilité mécanistique des transformers est ce qui se passe à l'intérieur des MLPs\n",
        "        * Underlying intuition - linear map -> non-linearity -> linear map est la force la plus puissante de l'univers et peut approximer des fonctions arbitraires. Je ne sais pas mec, ça marche simplement\n",
        "    * Appliquer une map linéaire, allant du flux résiduel final à un vecteur de logits - c'est la sortie.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIzc3LBd56K7"
      },
      "source": [
        "### Choses bonus - moins importantes conceptuellement mais détails techniques clés\n",
        "* LayerNorm\n",
        "    * Fonction de normalisation simple appliquée au début de chaque couche - MLP, Attn et Unembed\n",
        "    * Convertit chaque vecteur d'entrée (indépendamment en parallèle pour chaque vecteur de flux résiduel de lot x position) pour avoir une moyenne zéro et une variance 1.\n",
        "    * Petite digression mathématique sympa : La mise à l'échelle et la translation ne sont qu'une map linéaire. LayerNorm est uniquement appliqué immédiatement avant une autre map linéaire. Combiner linéaire avec linéaire = linéaire, donc nous pouvons simplement intégrer cela dans une seule couche linéaire efficace et l'ignorer.\n",
        "        * `fold_ln=True` flag dans `from_pretrained` Petite digression mathématique sympa : La mise à l'échelle et la translation ne sont qu'une map linéaire.\n",
        "        * LayerNorm est uniquement appliqué immédiatement avant une autre map linéaire. Combiner linéaire avec linéaire = linéaire, donc nous pouvons simplement intégrer cela dans une seule couche linéaire efficace et l'ignorer.\n",
        "    * LayerNorm est super difficile, car la partie de mise à l'échelle n'est pas linéaire, donc vous ne pouvez pas penser à différentes parties de l'entrée indépendamment. Mais c'est presque linéaire - si vous changez une petite partie de l'entrée, c'est linéaire, mais si vous changez suffisamment pour altérer considérablement la norme, ce n'est pas linéaire\n",
        "* Positional Information\n",
        "    * **Problème :** L'attention fonctionne sur toutes les paires de positions. Cela signifie qu'elle est symétrique par rapport à la position - le calcul d'attention du token 5 au token 1 et du token 5 au token 2 est le même par défaut\n",
        "    * Nous nous concentrerons sur **learned, absolute positional embeddings**. Cela signifie que nous apprenons une table de recherche qui mappe l'index de la position de chaque token à un vecteur de flux résiduel, et ajoutons cela à l'embedding.\n",
        "        * Notez que nous ajoutons plutôt que de concaténer. C'est parce que le flux résiduel est une mémoire partagée, et probablement sous une superposition significative (le modèle compresse plus de fonctionnalités là-dedans que le modèle n'a de dimensions)\n",
        "        *Nous ne concaténons pratiquement jamais à l'intérieur d'un transformer, sauf pour faire des trucs bizarres comme générer du texte efficacement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4-RUDsS56K7"
      },
      "source": [
        "# Code Réel!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKJltKsO56K8"
      },
      "source": [
        "## Imprimer toutes les  Activation Shapes du modèle de référence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMFLDRpA56K8"
      },
      "source": [
        "Clé:\n",
        "```\n",
        "batch = 32  # Nombre d'échantillons dans un batch\n",
        "position = 35  # Position dans la séquence\n",
        "d_model = 768  # Dimension du modèle\n",
        "n_heads = 12  # Nombre de têtes d'attention\n",
        "n_layers = 12  # Nombre de couches dans le modèle\n",
        "d_mlp = 3072  # Dimension de la couche MLP (4 * d_model)\n",
        "d_head = 64  # Dimension interne d'une tête d'attention (d_model / n_heads)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SpQuw1u56K8",
        "outputId": "6ef5353d-17b7-401d-8a62-335d02ca1486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hook_embed torch.Size([1, 35, 768])\n",
            "hook_pos_embed torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 35, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_attn torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_z torch.Size([1, 35, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 35, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 35, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 35, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 35, 768])\n",
            "ln_final.hook_scale torch.Size([1, 35, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 35, 768])\n"
          ]
        }
      ],
      "source": [
        "# Parcourir chaque élément dans cache_dict\n",
        "for activation_name, activation in cache.cache_dict.items():\n",
        "\n",
        "    # Vérifier si activation_name contient \".0.\" ou si \"blocks\" n'est pas dans le nom\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "\n",
        "        # Afficher activation_name et sa forme\n",
        "        print(activation_name, activation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8dvp1BZ56K8"
      },
      "source": [
        "## Imprimer toutes les formes des paramètres du modèle de référence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KJt2hmE56K8",
        "outputId": "c8318611-0f0b-4adb-df6f-39a74a57f2a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embed.W_E torch.Size([50257, 768])\n",
            "pos_embed.W_pos torch.Size([1024, 768])\n",
            "blocks.0.ln1.w torch.Size([768])\n",
            "blocks.0.ln1.b torch.Size([768])\n",
            "blocks.0.ln2.w torch.Size([768])\n",
            "blocks.0.ln2.b torch.Size([768])\n",
            "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
            "blocks.0.attn.b_Q torch.Size([12, 64])\n",
            "blocks.0.attn.b_K torch.Size([12, 64])\n",
            "blocks.0.attn.b_V torch.Size([12, 64])\n",
            "blocks.0.attn.b_O torch.Size([768])\n",
            "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
            "blocks.0.mlp.b_in torch.Size([3072])\n",
            "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
            "blocks.0.mlp.b_out torch.Size([768])\n",
            "ln_final.w torch.Size([768])\n",
            "ln_final.b torch.Size([768])\n",
            "unembed.W_U torch.Size([768, 50257])\n",
            "unembed.b_U torch.Size([50257])\n"
          ]
        }
      ],
      "source": [
        "# Parcourir chaque paramètre nommé dans reference_gpt2\n",
        "for name, param in reference_gpt2.named_parameters():\n",
        "\n",
        "    # Vérifier si le nom du paramètre contient \".0.\" ou si \"blocks\" n'est pas dans le nom\n",
        "    if \".0.\" in name or \"blocks\" not in name:\n",
        "\n",
        "        # Afficher le nom du paramètre et sa forme\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saDYKnxk56K9"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7GE-JVG56K9",
        "outputId": "3fa6b000-71a1-4c2d-f489-ff5cacc8ebf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EasyTransformerConfig(n_layers=12, d_model=768, n_ctx=1024, d_head=64, model_name='gpt2-small', n_heads=12, d_mlp=3072, act_fn='gelu_new', d_vocab=50257, eps=1e-05, use_attn_result=False, use_attn_scale=True, use_local_attn=False, model_family='gpt2', checkpoint=None, tokenizer_name='gpt2', window_size=None, attn_types=None, init_mode='gpt2', normalization_type='LN', device='cuda', attention_dir='causal', attn_only=False, seed=42, initializer_range=0.02886751345948129, init_weights=False, scale_attn_by_inverse_layer_idx=False, positional_embedding_type='standard', final_rms=False, d_vocab_out=50257, parallel_attn_mlp=False, rotary_dim=64, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# Comme référence - notez qu'il y a beaucoup de choses ici qui ne nous intéressent pas, concernant les détails internes de la bibliothèque ou d'autres architectures\n",
        "print(reference_gpt2.cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aV8ULNU56K9"
      },
      "source": [
        "Nous définissons une configuration simplifiée pour notre modèle.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8bJ6hta56K9",
        "outputId": "8017fb85-fa62-491f-b853-930ae7352204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768  # Dimension du modèle\n",
        "    debug: bool = True  # Mode de débogage\n",
        "    layer_norm_eps: float = 1e-5  # Epsilon pour la normalisation des couches\n",
        "    d_vocab: int = 50257  # Dimension du vocabulaire\n",
        "    init_range: float = 0.02  # Plage d'initialisation\n",
        "    n_ctx: int = 1024  # Contexte\n",
        "    d_head: int = 64  # Dimension de la tête d'attention\n",
        "    d_mlp: int = 3072  # Dimension de la couche MLP\n",
        "    n_heads: int = 12  # Nombre de têtes d'attention\n",
        "    n_layers: int = 12  # Nombre de couches\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T37bh_l56K9"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbVqjotX56K9"
      },
      "source": [
        "\n",
        "**Test naïf:** Générez des entrées aléatoires de la bonne forme, entrez-les dans votre modèle, vérifiez s'il y a une erreur et affichez la sortie correcte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ4s2DoO56K-"
      },
      "outputs": [],
      "source": [
        "def rand_float_test(cls, shape):\n",
        "    cfg = Config(debug=True)  # Crée une configuration avec le mode de débogage activé\n",
        "    layer = cls(cfg).cuda()  # Crée une couche avec la configuration et la déplace sur le GPU\n",
        "    random_input = torch.randn(shape).cuda()  # Crée une entrée aléatoire de forme donnée sur le GPU\n",
        "    print(\"Input shape:\", random_input.shape)  # Affiche la forme de l'entrée\n",
        "    output = layer(random_input)  # Passe l'entrée à la couche pour obtenir la sortie\n",
        "    print(\"Output shape:\", output.shape)  # Affiche la forme de la sortie\n",
        "    print()  # Ligne vide pour la lisibilité\n",
        "    return output  # Retourne la sortie\n",
        "\n",
        "def rand_int_test(cls, shape):\n",
        "    cfg = Config(debug=True)  # Crée une configuration avec le mode de débogage activé\n",
        "    layer = cls(cfg).cuda()  # Crée une couche avec la configuration et la déplace sur le GPU\n",
        "    random_input = torch.randint(100, 1000, shape).cuda()  # Crée une entrée aléatoire d'entiers sur le GPU\n",
        "    print(\"Input shape:\", random_input.shape)  # Affiche la forme de l'entrée\n",
        "    output = layer(random_input)  # Passe l'entrée à la couche pour obtenir la sortie\n",
        "    print(\"Output shape:\", output.shape)  # Affiche la forme de la sortie\n",
        "    print()  # Ligne vide pour la lisibilité\n",
        "    return output  # Retourne la sortie\n",
        "\n",
        "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
        "    cfg = Config(debug=True)  # Crée une configuration avec le mode de débogage activé\n",
        "    layer = cls(cfg).cuda()  # Crée une couche avec la configuration et la déplace sur le GPU\n",
        "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)  # Charge les poids d'une couche GPT-2\n",
        "    # Permet d'accepter des entrées sous forme de chaînes de caractères ou de tenseurs\n",
        "    if isinstance(input_name, str):\n",
        "        reference_input = cache_dict[input_name]\n",
        "    else:\n",
        "        reference_input = input_name\n",
        "    print(\"Input shape:\", reference_input.shape)  # Affiche la forme de l'entrée de référence\n",
        "    output = layer(reference_input)  # Passe l'entrée de référence à la couche pour obtenir la sortie\n",
        "    print(\"Output shape:\", output.shape)  # Affiche la forme de la sortie\n",
        "    reference_output = gpt2_layer(reference_input)  # Obtiens la sortie de la couche GPT-2 pour l'entrée de référence\n",
        "    print(\"Reference output shape:\", reference_output.shape)  # Affiche la forme de la sortie de référence\n",
        "\n",
        "    # Compare les sorties pour vérifier l'exactitude\n",
        "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
        "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")  # Affiche le pourcentage de valeurs correctes\n",
        "    return output  # Retourne la sortie\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWJglfvo56K-"
      },
      "source": [
        "## LayerNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ebc22T56K-"
      },
      "source": [
        "Effectuez la moyenne à 0\n",
        "Normalisez pour avoir une variance de 1\n",
        "Échelle avec des poids appris\n",
        "Traduisez avec un biais appris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S2gJA5c56K-"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg  # Initialise la configuration\n",
        "        self.w = nn.Parameter(torch.ones(cfg.d_model))  # Initialise le paramètre w avec des uns\n",
        "        self.b = nn.Parameter(torch.zeros(cfg.d_model))  # Initialise le paramètre b avec des zéros\n",
        "\n",
        "    def forward(self, residual):\n",
        "        # residual: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Residual:\", residual.shape)  # Affiche la forme du résidu s'il est en mode débogage\n",
        "        # Soustrait la moyenne du résidu dans chaque position de la séquence\n",
        "        residual = residual - einops.reduce(residual, \"batch position d_model -> batch position 1\", \"mean\")\n",
        "        # Calcule la variance, en prend la racine carrée, ajoute un epsilon pour éviter la division par zéro.\n",
        "        scale = (einops.reduce(residual.pow(2), \"batch position d_model -> batch position 1\", \"mean\") + self.cfg.layer_norm_eps).sqrt()\n",
        "        normalized = residual / scale  # Normalise le résidu\n",
        "        normalized = normalized * self.w + self.b  # Applique le scaling et la translation\n",
        "        if self.cfg.debug: print(\"Normalized:\", residual.shape)  # Affiche la forme du résidu normalisé s'il est en mode débogage\n",
        "        return normalized  # Retourne le résidu normalisé\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udA2xqUk56K-",
        "outputId": "4cc4b32b-3fba-4f87-cf4c-b58b673fc2f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        }
      ],
      "source": [
        "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
        "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJkhmcjM56K_"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul81SYrp56K_"
      },
      "source": [
        "\n",
        "Essentiellement une table de recherche des tokens aux vecteurs de flux résiduel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EXzEANg56K_",
        "outputId": "9069dec9-739e-4e8b-bc19-0871d2f1b6b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "Embeddings: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Tokens: torch.Size([1, 35])\n",
            "Embeddings: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
              "         [ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
              "         [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
              "         ...,\n",
              "         [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
              "         [-0.1488,  0.1519,  0.0056,  ..., -0.3107,  0.2073,  0.0377],\n",
              "         [-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453]]],\n",
              "       device='cuda:0', grad_fn=<IndexBackward0>)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))  # Crée une matrice de poids pour l'embedding\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)  # Initialise les poids de l'embedding avec une distribution normale\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)  # Affiche la forme des tokens s'ils sont en mode débogage\n",
        "        embed = self.W_E[tokens, :]  # Effectue l'opération d'embedding\n",
        "        if self.cfg.debug: print(\"Embeddings:\", embed.shape)  # Affiche la forme des embeddings s'ils sont en mode débogage\n",
        "        return embed  # Retourne les embeddings calculés\n",
        "\n",
        "rand_int_test(Embed, [2, 4])  # Teste la création d'embeddings avec des entiers aléatoires\n",
        "load_gpt2_test(Embed, reference_gpt2.embed, tokens)  # Teste le chargement d'un modèle GPT-2 avec la classe Embed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucPFyxcY56K_"
      },
      "source": [
        "## Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V1iCNr356LA",
        "outputId": "c1f2f056-75b7-47dd-a3e5-0a5b16f80407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "pos_embed: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Tokens: torch.Size([1, 35])\n",
            "pos_embed: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
              "           2.8267e-02,  5.4490e-02],\n",
              "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
              "           1.0172e-02, -1.5573e-04],\n",
              "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
              "           1.9325e-02, -2.1424e-02],\n",
              "         ...,\n",
              "         [ 4.6277e-04,  2.3037e-02,  4.1227e-02,  ..., -1.9287e-03,\n",
              "          -2.3037e-03, -4.3189e-03],\n",
              "         [-2.7136e-03,  2.1724e-02,  3.9675e-02,  ...,  4.2048e-04,\n",
              "          -4.8160e-03, -9.2252e-04],\n",
              "         [ 6.6815e-03,  2.0595e-02,  3.6596e-02,  ..., -9.5090e-04,\n",
              "          -3.2512e-03, -9.6509e-04]]], device='cuda:0',\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))  # Crée une matrice de poids pour l'embedding de position\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)  # Initialise les poids de l'embedding de position avec une distribution normale\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)  # Affiche la forme des tokens s'ils sont en mode débogage\n",
        "        pos_embed = self.W_pos[:tokens.size(1), :]  # Sélectionne les embeddings de position correspondant aux tokens\n",
        "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))  # Répète les embeddings pour chaque position dans chaque batch\n",
        "        if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)  # Affiche la forme des embeddings de position s'ils sont en mode débogage\n",
        "        return pos_embed  # Retourne les embeddings de position\n",
        "\n",
        "rand_int_test(PosEmbed, [2, 4])  # Teste la création d'embeddings de position avec des entiers aléatoires\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)  # Teste le chargement d'un modèle GPT-2 avec la classe PosEmbed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VzqCaj556LB"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KcV4ZLX56LB"
      },
      "source": [
        "* **Étape 1:** Produire un motif d'attention - pour chaque token de destination, une distribution de probabilité sur les tokens précédents (y compris le token actuel)\n",
        "    * Linear map de input -> query, de forme  [batch, position, head_index, d_head]\n",
        "    * Produire le produit scalaire de chaque paire de requêtes et de clés pour obtenir les scores d'attention [batch, head_index, query_pos, key_pos] (query = dest, key = source)\n",
        "    * Appliquer une fonction softmax par ligne pour obtenir une distribution de probabilité le long de la key_pos dimension - c'est notre motif d'attention !\n",
        "* **Étape  2:** Déplacer les informations des tokens source vers le token de destination en utilisant le motif d'attention(move = apply linear map)\n",
        "    * Linear map de input -> valeur [batch, key_pos, head_index, d_head]\n",
        "    * Mix Mélanger le long de la position_clé avec le motif d'attention pour obtenir z, une valeur mixte [batch, query_pos, head_index, d_head]\n",
        "    * Mapper vers la sortie, [batch, position, d_model] (position = query_pos, we've  nous avons sommé sur toutes les têtes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfU5F7JH56LB"
      },
      "source": [
        "Tout d'abord, il est utile de visualiser et d'expérimenter avec les motifs d'attention - que regardons-nous exactement ici ? (Cliquez sur une tête pour verrouiller l'affichage du motif de cette tête uniquement, cela facilitera l'interprétation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lWpaBgv56LB",
        "outputId": "caf702cb-a131-4d35-a759-8e8bc2b0b869"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <script>var AttentionMulti;AttentionMulti=(()=>{\"use strict\";var __webpack_modules__={143:(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{function noop(){}__webpack_require__.d(__webpack_exports__,{default:()=>AttentionMulti_svelte});function run(fn){return fn()}function blank_object(){return Object.create(null)}function run_all(fns){fns.forEach(run)}function is_function(thing){return\"function\"==typeof thing}function safe_not_equal(a,b){return a!=a?b==b:a!==b||a&&\"object\"==typeof a||\"function\"==typeof a}function is_empty(obj){return 0===Object.keys(obj).length}function get_slot_context(definition,ctx,$$scope,fn){return definition[1]&&fn?function internal_assign(tar,src){for(const k in src)tar[k]=src[k];return tar}($$scope.ctx.slice(),definition[1](fn(ctx))):$$scope.ctx}function get_slot_changes(definition,$$scope,dirty,fn){if(definition[2]&&fn){const lets=definition[2](fn(dirty));if(void 0===$$scope.dirty)return lets;if(\"object\"==typeof lets){const merged=[],len=Math.max($$scope.dirty.length,lets.length);for(let i=0;i<len;i+=1)merged[i]=$$scope.dirty[i]|lets[i];return merged}return $$scope.dirty|lets}return $$scope.dirty}new Set;function append(target,node){target.appendChild(node)}function insert(target,node,anchor){target.insertBefore(node,anchor||null)}function detach(node){node.parentNode.removeChild(node)}function destroy_each(iterations,detaching){for(let i=0;i<iterations.length;i+=1)iterations[i]&&iterations[i].d(detaching)}function internal_element(name){return document.createElement(name)}function internal_text(data){return document.createTextNode(data)}function space(){return internal_text(\" \")}function listen(node,event,handler,options){return node.addEventListener(event,handler,options),()=>node.removeEventListener(event,handler,options)}function attr(node,attribute,value){null==value?node.removeAttribute(attribute):node.getAttribute(attribute)!==value&&node.setAttribute(attribute,value)}function set_data(text,data){data=\"\"+data,text.wholeText!==data&&(text.data=data)}function set_style(node,key,value,important){node.style.setProperty(key,value,important?\"important\":\"\")}new Set;let current_component;function set_current_component(component){current_component=component}function get_current_component(){if(!current_component)throw new Error(\"Function called outside component initialization\");return current_component}const dirty_components=[],binding_callbacks=[],render_callbacks=[],flush_callbacks=[],resolved_promise=Promise.resolve();let update_scheduled=!1;function schedule_update(){update_scheduled||(update_scheduled=!0,resolved_promise.then(flush))}function add_render_callback(fn){render_callbacks.push(fn)}function add_flush_callback(fn){flush_callbacks.push(fn)}let flushing=!1;const seen_callbacks=new Set;function flush(){if(!flushing){flushing=!0;do{for(let i=0;i<dirty_components.length;i+=1){const component=dirty_components[i];set_current_component(component),update(component.$$)}for(set_current_component(null),dirty_components.length=0;binding_callbacks.length;)binding_callbacks.pop()();for(let i=0;i<render_callbacks.length;i+=1){const callback=render_callbacks[i];seen_callbacks.has(callback)||(seen_callbacks.add(callback),callback())}render_callbacks.length=0}while(dirty_components.length);for(;flush_callbacks.length;)flush_callbacks.pop()();update_scheduled=!1,flushing=!1,seen_callbacks.clear()}}function update($$){if(null!==$$.fragment){$$.update(),run_all($$.before_update);const dirty=$$.dirty;$$.dirty=[-1],$$.fragment&&$$.fragment.p($$.ctx,dirty),$$.after_update.forEach(add_render_callback)}}const outroing=new Set;let outros;function group_outros(){outros={r:0,c:[],p:outros}}function check_outros(){outros.r||run_all(outros.c),outros=outros.p}function transition_in(block,local){block&&block.i&&(outroing.delete(block),block.i(local))}function transition_out(block,local,detach,callback){if(block&&block.o){if(outroing.has(block))return;outroing.add(block),outros.c.push((()=>{outroing.delete(block),callback&&(detach&&block.d(1),callback())})),block.o(local)}}\"undefined\"!=typeof window?window:\"undefined\"!=typeof globalThis?globalThis:global;new Set([\"allowfullscreen\",\"allowpaymentrequest\",\"async\",\"autofocus\",\"autoplay\",\"checked\",\"controls\",\"default\",\"defer\",\"disabled\",\"formnovalidate\",\"hidden\",\"ismap\",\"loop\",\"multiple\",\"muted\",\"nomodule\",\"novalidate\",\"open\",\"playsinline\",\"readonly\",\"required\",\"reversed\",\"selected\"]);let SvelteElement;function bind(component,name,callback){const index=component.$$.props[name];void 0!==index&&(component.$$.bound[index]=callback,callback(component.$$.ctx[index]))}function create_component(block){block&&block.c()}function mount_component(component,target,anchor){const{fragment,on_mount,on_destroy,after_update}=component.$$;fragment&&fragment.m(target,anchor),add_render_callback((()=>{const new_on_destroy=on_mount.map(run).filter(is_function);on_destroy?on_destroy.push(...new_on_destroy):run_all(new_on_destroy),component.$$.on_mount=[]})),after_update.forEach(add_render_callback)}function destroy_component(component,detaching){const $$=component.$$;null!==$$.fragment&&(run_all($$.on_destroy),$$.fragment&&$$.fragment.d(detaching),$$.on_destroy=$$.fragment=null,$$.ctx=[])}function init(component,options,instance,create_fragment,not_equal,props,dirty=[-1]){const parent_component=current_component;set_current_component(component);const prop_values=options.props||{},$$=component.$$={fragment:null,ctx:null,props,update:noop,not_equal,bound:blank_object(),on_mount:[],on_destroy:[],before_update:[],after_update:[],context:new Map(parent_component?parent_component.$$.context:[]),callbacks:blank_object(),dirty,skip_bound:!1};let ready=!1;if($$.ctx=instance?instance(component,prop_values,((i,ret,...rest)=>{const value=rest.length?rest[0]:ret;return $$.ctx&&not_equal($$.ctx[i],$$.ctx[i]=value)&&(!$$.skip_bound&&$$.bound[i]&&$$.bound[i](value),ready&&function make_dirty(component,i){-1===component.$$.dirty[0]&&(dirty_components.push(component),schedule_update(),component.$$.dirty.fill(0)),component.$$.dirty[i/31|0]|=1<<i%31}(component,i)),ret})):[],$$.update(),ready=!0,run_all($$.before_update),$$.fragment=!!create_fragment&&create_fragment($$.ctx),options.target){if(options.hydrate){const nodes=function children(element){return Array.from(element.childNodes)}(options.target);$$.fragment&&$$.fragment.l(nodes),nodes.forEach(detach)}else $$.fragment&&$$.fragment.c();options.intro&&transition_in(component.$$.fragment),mount_component(component,options.target,options.anchor),flush()}set_current_component(parent_component)}\"function\"==typeof HTMLElement&&(SvelteElement=class extends HTMLElement{constructor(){super(),this.attachShadow({mode:\"open\"})}connectedCallback(){for(const key in this.$$.slotted)this.appendChild(this.$$.slotted[key])}attributeChangedCallback(attr,_oldValue,newValue){this[attr]=newValue}$destroy(){destroy_component(this,1),this.$destroy=noop}$on(type,callback){const callbacks=this.$$.callbacks[type]||(this.$$.callbacks[type]=[]);return callbacks.push(callback),()=>{const index=callbacks.indexOf(callback);-1!==index&&callbacks.splice(index,1)}}$set($$props){this.$$set&&!is_empty($$props)&&(this.$$.skip_bound=!0,this.$$set($$props),this.$$.skip_bound=!1)}});class SvelteComponent{$destroy(){destroy_component(this,1),this.$destroy=noop}$on(type,callback){const callbacks=this.$$.callbacks[type]||(this.$$.callbacks[type]=[]);return callbacks.push(callback),()=>{const index=callbacks.indexOf(callback);-1!==index&&callbacks.splice(index,1)}}$set($$props){this.$$set&&!is_empty($$props)&&(this.$$.skip_bound=!0,this.$$set($$props),this.$$.skip_bound=!1)}}function norm(x,ord=2){if(!(\"length\"in x))return function norm_nd(x,ord=2){for(var S=0,i=0;i<x.shape[0];i++)S+=Math.pow(Math.abs(x.get(i)),ord);return Math.pow(S,1/ord)}(x,ord);for(var S=0,i=0;i<x.length;i++)S+=Math.pow(Math.abs(x[i]),ord);return Math.pow(S,1/ord)}function normalize(v,ord=2){var v_norm=norm(v,ord);return v.map((x=>x/(1e-4+v_norm)))}function hue_to_rgb(theta){for(var colors=[[1,0,0],[1,1,0],[0,1,0],[0,1,1],[0,0,1],[1,0,1]].map((c=>normalize(c,1)));theta<0;)theta+=360;theta%=360;var d_theta=360/colors.length,n=Math.floor(theta/d_theta),mix_coef=(theta-n*d_theta)/d_theta,v=function interp(a,b,s){return a.map(((x,i)=>(1-s)*x+s*b[i]))}(colors[n],colors[(n+1)%colors.length],mix_coef);return v=normalize(v,1)}const __rgb_hue_vector_cache=[];function rgb_to_css(color){return`rgb(${255*color[0]}, ${255*color[1]}, ${255*color[2]})`}function sparse_color_map(v,zero_c=[.98,.98,.98],isolate_channel,hues){const v_len=\"length\"in v?v.length:v.shape[0],elem=\"length\"in v?i=>v[i]:i=>v.get(i);if(null==hues&&(hues=function rgb_hue_vector(n){if(n in __rgb_hue_vector_cache)return __rgb_hue_vector_cache[n];let out=[];for(let i=0;i<n;i++){const hue=360*i/n;out.push(hue_to_rgb(hue))}return __rgb_hue_vector_cache[n]=out,out}(v_len)),console.log(\"Hues\",hues),null==isolate_channel){for(var S=[0,0,0],i=0;i<v_len;i++){const ei=elem(i);if(0!=ei)for(var rgb=hues[i],j=0;j<3;j++)S[j]+=ei*rgb[j]}S=normalize(S,1);var mag=norm(v,2);for(mag=Math.max(0,Math.min(1,mag)),j=0;j<3;j++)S[j]=mag*S[j]+(1-mag)*zero_c[j];return S}var Ci=hues[i=isolate_channel];for(S=[0,0,0],j=0;j<3;j++)S[j]=elem(i)*Ci[j]+(1-elem(i))*zero_c[j];return S}function sparse_color_map_css(v,zero_c=[.98,.98,.98],isolate_channel,hues){return rgb_to_css(sparse_color_map(v,zero_c,isolate_channel,hues))}function create_if_block(ctx){let div0,t,div1;return{c(){div0=internal_element(\"div\"),t=space(),div1=internal_element(\"div\"),attr(div0,\"class\",\"focus-top svelte-1vzuzhc\"),set_style(div0,\"height\",ctx[2]*ctx[3]/ctx[0].shape[0]+\"px\"),attr(div1,\"class\",\"focus-bottom svelte-1vzuzhc\"),set_style(div1,\"height\",ctx[2]*(1-(ctx[3]+1)/ctx[0].shape[0])+\"px\")},m(target,anchor){insert(target,div0,anchor),insert(target,t,anchor),insert(target,div1,anchor)},p(ctx,dirty){13&dirty&&set_style(div0,\"height\",ctx[2]*ctx[3]/ctx[0].shape[0]+\"px\"),13&dirty&&set_style(div1,\"height\",ctx[2]*(1-(ctx[3]+1)/ctx[0].shape[0])+\"px\")},d(detaching){detaching&&detach(div0),detaching&&detach(t),detaching&&detach(div1)}}}function create_fragment(ctx){let div,canvas_1,t,if_block=null!=ctx[3]&&create_if_block(ctx);return{c(){div=internal_element(\"div\"),canvas_1=internal_element(\"canvas\"),t=space(),if_block&&if_block.c(),set_style(canvas_1,\"width\",ctx[1]+\"px\"),set_style(canvas_1,\"height\",ctx[2]+\"px\"),attr(canvas_1,\"class\",\"svelte-1vzuzhc\"),attr(div,\"class\",\"container svelte-1vzuzhc\"),set_style(div,\"width\",ctx[1]+\"px\"),set_style(div,\"height\",ctx[2]+\"px\")},m(target,anchor){insert(target,div,anchor),append(div,canvas_1),ctx[8](canvas_1),append(div,t),if_block&&if_block.m(div,null)},p(ctx,[dirty]){2&dirty&&set_style(canvas_1,\"width\",ctx[1]+\"px\"),4&dirty&&set_style(canvas_1,\"height\",ctx[2]+\"px\"),null!=ctx[3]?if_block?if_block.p(ctx,dirty):(if_block=create_if_block(ctx),if_block.c(),if_block.m(div,null)):if_block&&(if_block.d(1),if_block=null),2&dirty&&set_style(div,\"width\",ctx[1]+\"px\"),4&dirty&&set_style(div,\"height\",ctx[2]+\"px\")},i:noop,o:noop,d(detaching){detaching&&detach(div),ctx[8](null),if_block&&if_block.d()}}}function instance($$self,$$props,$$invalidate){let canvas,{array}=$$props,{width}=$$props,{height}=$$props,{hues}=$$props,{focus_token}=$$props,{isolate_channel}=$$props,{color_map=sparse_color_map}=$$props;function get_color(array,x,y,isolate_channel,hues){if(x<y)return[255,255,255];var v=array.pick(x,y,null);return color_map(v,void 0,isolate_channel,hues).map((c=>255*c))}function draw(canvas,array,isolate_channel,hues){if(null!=canvas&&null!=array){canvas.width=array.shape[0],canvas.height=array.shape[1];for(var ctx=canvas.getContext(\"2d\"),imgData=ctx.getImageData(0,0,canvas.width,canvas.height),x=0;x<canvas.width;x++)for(var y=0;y<canvas.height;y++){for(var ind=x*canvas.width+y,color=get_color(array,x,y,isolate_channel,hues=hues),channel=0;channel<3;channel++)imgData.data[4*ind+channel]=color[channel];imgData.data[4*ind+3]=255}ctx.putImageData(imgData,0,0)}}return function onMount(fn){get_current_component().$$.on_mount.push(fn)}((()=>draw(canvas,array,isolate_channel))),$$self.$$set=$$props=>{\"array\"in $$props&&$$invalidate(0,array=$$props.array),\"width\"in $$props&&$$invalidate(1,width=$$props.width),\"height\"in $$props&&$$invalidate(2,height=$$props.height),\"hues\"in $$props&&$$invalidate(5,hues=$$props.hues),\"focus_token\"in $$props&&$$invalidate(3,focus_token=$$props.focus_token),\"isolate_channel\"in $$props&&$$invalidate(6,isolate_channel=$$props.isolate_channel),\"color_map\"in $$props&&$$invalidate(7,color_map=$$props.color_map)},$$self.$$.update=()=>{113&$$self.$$.dirty&&draw(canvas,array,isolate_channel,hues)},[array,width,height,focus_token,canvas,hues,isolate_channel,color_map,function canvas_1_binding($$value){binding_callbacks[$$value?\"unshift\":\"push\"]((()=>{canvas=$$value,$$invalidate(4,canvas)}))}]}const ArrayImage_svelte=class ArrayImage extends SvelteComponent{constructor(options){super(),document.getElementById(\"svelte-1vzuzhc-style\")||function add_css(){var style=internal_element(\"style\");style.id=\"svelte-1vzuzhc-style\",style.textContent=\".container.svelte-1vzuzhc.svelte-1vzuzhc{position:relative;border:1px solid #aaa}.container.svelte-1vzuzhc>.svelte-1vzuzhc{position:absolute;width:100%;left:0px}.container.svelte-1vzuzhc canvas.svelte-1vzuzhc{top:0px;height:100%;image-rendering:pixelated}.container.svelte-1vzuzhc .focus-top.svelte-1vzuzhc,.container.svelte-1vzuzhc .focus-bottom.svelte-1vzuzhc{background:#aaa;opacity:0.3}.container.svelte-1vzuzhc .focus-top.svelte-1vzuzhc{top:0px}.container.svelte-1vzuzhc .focus-bottom.svelte-1vzuzhc{bottom:0px}\",append(document.head,style)}(),init(this,options,instance,create_fragment,safe_not_equal,{array:0,width:1,height:2,hues:5,focus_token:3,isolate_channel:6,color_map:7})}};function soft_update(v,val){return\"soft\"==v.mode&&(v.value=val),v}function hard_toggle_update(v,val){if(\"soft\"==v.mode)v.value=val,v.mode=\"hard\";else{if(\"hard\"!=v.mode||v.value==val)return function unset(v){return v.value=void 0,v.mode=\"soft\",v}(v);v.value=val}return v}function LockableValueToggle_svelte_create_fragment(ctx){let div,current,mounted,dispose;const default_slot_template=ctx[4].default,default_slot=function create_slot(definition,ctx,$$scope,fn){if(definition){const slot_ctx=get_slot_context(definition,ctx,$$scope,fn);return definition[0](slot_ctx)}}(default_slot_template,ctx,ctx[3],null);return{c(){div=internal_element(\"div\"),default_slot&&default_slot.c(),attr(div,\"style\",ctx[2])},m(target,anchor){insert(target,div,anchor),default_slot&&default_slot.m(div,null),current=!0,mounted||(dispose=[listen(div,\"mouseover\",ctx[5]),listen(div,\"click\",ctx[6]),listen(div,\"mouseout\",ctx[7])],mounted=!0)},p(ctx,[dirty]){default_slot&&default_slot.p&&8&dirty&&function update_slot(slot,slot_definition,ctx,$$scope,dirty,get_slot_changes_fn,get_slot_context_fn){const slot_changes=get_slot_changes(slot_definition,$$scope,dirty,get_slot_changes_fn);if(slot_changes){const slot_context=get_slot_context(slot_definition,ctx,$$scope,get_slot_context_fn);slot.p(slot_context,slot_changes)}}(default_slot,default_slot_template,ctx,ctx[3],dirty,null,null),(!current||4&dirty)&&attr(div,\"style\",ctx[2])},i(local){current||(transition_in(default_slot,local),current=!0)},o(local){transition_out(default_slot,local),current=!1},d(detaching){detaching&&detach(div),default_slot&&default_slot.d(detaching),mounted=!1,run_all(dispose)}}}function LockableValueToggle_svelte_instance($$self,$$props,$$invalidate){let{$$slots:slots={},$$scope}=$$props,{lock}=$$props,{set_value}=$$props,{style=\"\"}=$$props;return $$self.$$set=$$props=>{\"lock\"in $$props&&$$invalidate(0,lock=$$props.lock),\"set_value\"in $$props&&$$invalidate(1,set_value=$$props.set_value),\"style\"in $$props&&$$invalidate(2,style=$$props.style),\"$$scope\"in $$props&&$$invalidate(3,$$scope=$$props.$$scope)},[lock,set_value,style,$$scope,slots,()=>{$$invalidate(0,lock=soft_update(lock,set_value))},()=>{$$invalidate(0,lock=hard_toggle_update(lock,set_value))},()=>{$$invalidate(0,lock=soft_update(lock,void 0))}]}const LockableValueToggle_svelte=class LockableValueToggle extends SvelteComponent{constructor(options){super(),init(this,options,LockableValueToggle_svelte_instance,LockableValueToggle_svelte_create_fragment,safe_not_equal,{lock:0,set_value:1,style:2})}};function get_each_context(ctx,list,i){const child_ctx=ctx.slice();return child_ctx[32]=list[i],child_ctx[34]=i,child_ctx}function get_each_context_1(ctx,list,i){const child_ctx=ctx.slice();return child_ctx[35]=list[i],child_ctx}function create_if_block_4(ctx){let t0,t1,t2,t1_value=ctx[15][ctx[10]]+\"\";return{c(){t0=internal_text(\"(\"),t1=internal_text(t1_value),t2=internal_text(\")\")},m(target,anchor){insert(target,t0,anchor),insert(target,t1,anchor),insert(target,t2,anchor)},p(ctx,dirty){33792&dirty[0]&&t1_value!==(t1_value=ctx[15][ctx[10]]+\"\")&&set_data(t1,t1_value)},d(detaching){detaching&&detach(t0),detaching&&detach(t1),detaching&&detach(t2)}}}function create_if_block_3(ctx){let div,arrayimage,div_style_value,current;return arrayimage=new ArrayImage_svelte({props:{array:ctx[7],width:\"200\",height:\"200\",focus_token:ctx[9],isolate_channel:ctx[10]}}),{c(){div=internal_element(\"div\"),create_component(arrayimage.$$.fragment),attr(div,\"style\",div_style_value=\"grid-column: big-attn; grid-row: main; \"+(ctx[11]?\"\":\"display:none;\"))},m(target,anchor){insert(target,div,anchor),mount_component(arrayimage,div,null),current=!0},p(ctx,dirty){const arrayimage_changes={};128&dirty[0]&&(arrayimage_changes.array=ctx[7]),512&dirty[0]&&(arrayimage_changes.focus_token=ctx[9]),1024&dirty[0]&&(arrayimage_changes.isolate_channel=ctx[10]),arrayimage.$set(arrayimage_changes),(!current||2048&dirty[0]&&div_style_value!==(div_style_value=\"grid-column: big-attn; grid-row: main; \"+(ctx[11]?\"\":\"display:none;\")))&&attr(div,\"style\",div_style_value)},i(local){current||(transition_in(arrayimage.$$.fragment,local),current=!0)},o(local){transition_out(arrayimage.$$.fragment,local),current=!1},d(detaching){detaching&&detach(div),destroy_component(arrayimage)}}}function create_if_block_2(ctx){let div0,t1,div1,current,each_value_1=range(ctx[12].shape[2]),each_blocks=[];for(let i=0;i<each_value_1.length;i+=1)each_blocks[i]=create_each_block_1(get_each_context_1(ctx,each_value_1,i));const out=i=>transition_out(each_blocks[i],1,1,(()=>{each_blocks[i]=null}));return{c(){div0=internal_element(\"div\"),div0.textContent=\"Attention Heads (hover to focus, click to lock)\",t1=space(),div1=internal_element(\"div\");for(let i=0;i<each_blocks.length;i+=1)each_blocks[i].c();attr(div0,\"class\",\"figcaption svelte-1rpu49t\"),set_style(div0,\"grid-column\",\"heads\"),attr(div1,\"class\",\"heads svelte-1rpu49t\")},m(target,anchor){insert(target,div0,anchor),insert(target,t1,anchor),insert(target,div1,anchor);for(let i=0;i<each_blocks.length;i+=1)each_blocks[i].m(div1,null);current=!0},p(ctx,dirty){if(122566&dirty[0]){let i;for(each_value_1=range(ctx[12].shape[2]),i=0;i<each_value_1.length;i+=1){const child_ctx=get_each_context_1(ctx,each_value_1,i);each_blocks[i]?(each_blocks[i].p(child_ctx,dirty),transition_in(each_blocks[i],1)):(each_blocks[i]=create_each_block_1(child_ctx),each_blocks[i].c(),transition_in(each_blocks[i],1),each_blocks[i].m(div1,null))}for(group_outros(),i=each_value_1.length;i<each_blocks.length;i+=1)out(i);check_outros()}},i(local){if(!current){for(let i=0;i<each_value_1.length;i+=1)transition_in(each_blocks[i]);current=!0}},o(local){each_blocks=each_blocks.filter(Boolean);for(let i=0;i<each_blocks.length;i+=1)transition_out(each_blocks[i]);current=!1},d(detaching){detaching&&detach(div0),detaching&&detach(t1),detaching&&detach(div1),destroy_each(each_blocks,detaching)}}}function create_default_slot_1(ctx){let div1,arrayimage0,t0,div0,div1_style_value,t1,div3,arrayimage1,t2,div2,div3_style_value,t3,current,raw0_value=(null!=ctx[15][ctx[35]]?ctx[15][ctx[35]]:\"&nbsp\")+\"\",raw1_value=(null!=ctx[15][ctx[35]]?ctx[15][ctx[35]]:\"&nbsp\")+\"\";return arrayimage0=new ArrayImage_svelte({props:{array:ctx[7],width:\"60\",height:\"60\",isolate_channel:ctx[35]}}),arrayimage1=new ArrayImage_svelte({props:{array:ctx[6],width:\"60\",height:\"60\",isolate_channel:ctx[35]}}),{c(){div1=internal_element(\"div\"),create_component(arrayimage0.$$.fragment),t0=space(),div0=internal_element(\"div\"),t1=space(),div3=internal_element(\"div\"),create_component(arrayimage1.$$.fragment),t2=space(),div2=internal_element(\"div\"),t3=space(),attr(div0,\"class\",\"head-label svelte-1rpu49t\"),set_style(div0,\"background\",ctx[14][ctx[35]]),attr(div1,\"class\",\"head-icon svelte-1rpu49t\"),attr(div1,\"style\",div1_style_value=\"opacity: \"+(null!=ctx[10]&&ctx[10]!=ctx[35]?\"0.2\":ctx[16](ctx[35],ctx[9],ctx[2]))+\";\\n                        \"+(ctx[11]?\"\":\"display:none;\")),attr(div2,\"class\",\"head-label svelte-1rpu49t\"),set_style(div2,\"background\",ctx[14][ctx[35]]),attr(div3,\"class\",\"head-icon svelte-1rpu49t\"),attr(div3,\"style\",div3_style_value=\"opacity: \"+(null!=ctx[10]&&ctx[10]!=ctx[35]?\"0.2\":ctx[16](ctx[35],ctx[9],ctx[2]))+\";\\n                        \"+(ctx[11]?\"display:none;\":\"\"))},m(target,anchor){insert(target,div1,anchor),mount_component(arrayimage0,div1,null),append(div1,t0),append(div1,div0),div0.innerHTML=raw0_value,insert(target,t1,anchor),insert(target,div3,anchor),mount_component(arrayimage1,div3,null),append(div3,t2),append(div3,div2),div2.innerHTML=raw1_value,insert(target,t3,anchor),current=!0},p(ctx,dirty){const arrayimage0_changes={};128&dirty[0]&&(arrayimage0_changes.array=ctx[7]),4096&dirty[0]&&(arrayimage0_changes.isolate_channel=ctx[35]),arrayimage0.$set(arrayimage0_changes),(!current||36864&dirty[0])&&raw0_value!==(raw0_value=(null!=ctx[15][ctx[35]]?ctx[15][ctx[35]]:\"&nbsp\")+\"\")&&(div0.innerHTML=raw0_value),(!current||20480&dirty[0])&&set_style(div0,\"background\",ctx[14][ctx[35]]),(!current||7684&dirty[0]&&div1_style_value!==(div1_style_value=\"opacity: \"+(null!=ctx[10]&&ctx[10]!=ctx[35]?\"0.2\":ctx[16](ctx[35],ctx[9],ctx[2]))+\";\\n                        \"+(ctx[11]?\"\":\"display:none;\")))&&attr(div1,\"style\",div1_style_value);const arrayimage1_changes={};64&dirty[0]&&(arrayimage1_changes.array=ctx[6]),4096&dirty[0]&&(arrayimage1_changes.isolate_channel=ctx[35]),arrayimage1.$set(arrayimage1_changes),(!current||36864&dirty[0])&&raw1_value!==(raw1_value=(null!=ctx[15][ctx[35]]?ctx[15][ctx[35]]:\"&nbsp\")+\"\")&&(div2.innerHTML=raw1_value),(!current||20480&dirty[0])&&set_style(div2,\"background\",ctx[14][ctx[35]]),(!current||7684&dirty[0]&&div3_style_value!==(div3_style_value=\"opacity: \"+(null!=ctx[10]&&ctx[10]!=ctx[35]?\"0.2\":ctx[16](ctx[35],ctx[9],ctx[2]))+\";\\n                        \"+(ctx[11]?\"display:none;\":\"\")))&&attr(div3,\"style\",div3_style_value)},i(local){current||(transition_in(arrayimage0.$$.fragment,local),transition_in(arrayimage1.$$.fragment,local),current=!0)},o(local){transition_out(arrayimage0.$$.fragment,local),transition_out(arrayimage1.$$.fragment,local),current=!1},d(detaching){detaching&&detach(div1),destroy_component(arrayimage0),detaching&&detach(t1),detaching&&detach(div3),destroy_component(arrayimage1),detaching&&detach(t3)}}}function create_each_block_1(ctx){let lockablevaluetoggle,updating_lock,current;function lockablevaluetoggle_lock_binding(value){ctx[22].call(null,value)}let lockablevaluetoggle_props={set_value:ctx[35],$$slots:{default:[create_default_slot_1]},$$scope:{ctx}};return void 0!==ctx[1]&&(lockablevaluetoggle_props.lock=ctx[1]),lockablevaluetoggle=new LockableValueToggle_svelte({props:lockablevaluetoggle_props}),binding_callbacks.push((()=>bind(lockablevaluetoggle,\"lock\",lockablevaluetoggle_lock_binding))),{c(){create_component(lockablevaluetoggle.$$.fragment)},m(target,anchor){mount_component(lockablevaluetoggle,target,anchor),current=!0},p(ctx,dirty){const lockablevaluetoggle_changes={};4096&dirty[0]&&(lockablevaluetoggle_changes.set_value=ctx[35]),57028&dirty[0]|128&dirty[1]&&(lockablevaluetoggle_changes.$$scope={dirty,ctx}),!updating_lock&&2&dirty[0]&&(updating_lock=!0,lockablevaluetoggle_changes.lock=ctx[1],add_flush_callback((()=>updating_lock=!1))),lockablevaluetoggle.$set(lockablevaluetoggle_changes)},i(local){current||(transition_in(lockablevaluetoggle.$$.fragment,local),current=!0)},o(local){transition_out(lockablevaluetoggle.$$.fragment,local),current=!1},d(detaching){destroy_component(lockablevaluetoggle,detaching)}}}function AttentionMulti_svelte_create_if_block(ctx){let div3,div0,t1,div1,t2,div2,nobr,input,t3,span,t4,b,t5,t6,current,mounted,dispose,t5_value=ctx[2]?\"target\":\"source\",each_value=ctx[5],each_blocks=[];for(let i=0;i<each_value.length;i+=1)each_blocks[i]=create_each_block(get_each_context(ctx,each_value,i));const out=i=>transition_out(each_blocks[i],1,1,(()=>{each_blocks[i]=null}));let if_block=void 0!==ctx[7]&&create_if_block_1(ctx);return{c(){div3=internal_element(\"div\"),div0=internal_element(\"div\"),div0.textContent=\"Tokens (hover to focus, click to lock)\",t1=space(),div1=internal_element(\"div\");for(let i=0;i<each_blocks.length;i+=1)each_blocks[i].c();t2=space(),div2=internal_element(\"div\"),nobr=internal_element(\"nobr\"),input=internal_element(\"input\"),t3=space(),span=internal_element(\"span\"),t4=internal_text(\"Selected is\\n            \"),b=internal_element(\"b\"),t5=internal_text(t5_value),t6=space(),if_block&&if_block.c(),attr(div0,\"class\",\"figcaption svelte-1rpu49t\"),set_style(div0,\"grid-column\",\"left\"),attr(div1,\"class\",\"tokens svelte-1rpu49t\"),attr(input,\"class\",\"hover-mode svelte-1rpu49t\"),attr(input,\"type\",\"checkbox\"),attr(span,\"class\",\"hover-mode-text svelte-1rpu49t\"),set_style(span,\"white-space\",\"nowrap\"),attr(div2,\"class\",\"toggle\"),attr(div3,\"class\",\"tokens-container svelte-1rpu49t\")},m(target,anchor){insert(target,div3,anchor),append(div3,div0),append(div3,t1),append(div3,div1);for(let i=0;i<each_blocks.length;i+=1)each_blocks[i].m(div1,null);append(div3,t2),append(div3,div2),append(div2,nobr),append(nobr,input),input.checked=ctx[2],append(nobr,t3),append(nobr,span),append(span,t4),append(span,b),append(b,t5),append(nobr,t6),if_block&&if_block.m(nobr,null),current=!0,mounted||(dispose=[listen(input,\"change\",ctx[24]),listen(span,\"click\",ctx[25])],mounted=!0)},p(ctx,dirty){if(561&dirty[0]){let i;for(each_value=ctx[5],i=0;i<each_value.length;i+=1){const child_ctx=get_each_context(ctx,each_value,i);each_blocks[i]?(each_blocks[i].p(child_ctx,dirty),transition_in(each_blocks[i],1)):(each_blocks[i]=create_each_block(child_ctx),each_blocks[i].c(),transition_in(each_blocks[i],1),each_blocks[i].m(div1,null))}for(group_outros(),i=each_value.length;i<each_blocks.length;i+=1)out(i);check_outros()}4&dirty[0]&&(input.checked=ctx[2]),(!current||4&dirty[0])&&t5_value!==(t5_value=ctx[2]?\"target\":\"source\")&&set_data(t5,t5_value),void 0!==ctx[7]?if_block?if_block.p(ctx,dirty):(if_block=create_if_block_1(ctx),if_block.c(),if_block.m(nobr,null)):if_block&&(if_block.d(1),if_block=null)},i(local){if(!current){for(let i=0;i<each_value.length;i+=1)transition_in(each_blocks[i]);current=!0}},o(local){each_blocks=each_blocks.filter(Boolean);for(let i=0;i<each_blocks.length;i+=1)transition_out(each_blocks[i]);current=!1},d(detaching){detaching&&detach(div3),destroy_each(each_blocks,detaching),if_block&&if_block.d(),mounted=!1,run_all(dispose)}}}function create_default_slot(ctx){let span,t,span_class_value,t_value=ctx[32]+\"\";return{c(){span=internal_element(\"span\"),t=internal_text(t_value),attr(span,\"class\",span_class_value=\"token \"+(ctx[34]==ctx[9]?\"selected\":\"\")+\" svelte-1rpu49t\"),set_style(span,\"background\",ctx[4][ctx[34]])},m(target,anchor){insert(target,span,anchor),append(span,t)},p(ctx,dirty){32&dirty[0]&&t_value!==(t_value=ctx[32]+\"\")&&set_data(t,t_value),512&dirty[0]&&span_class_value!==(span_class_value=\"token \"+(ctx[34]==ctx[9]?\"selected\":\"\")+\" svelte-1rpu49t\")&&attr(span,\"class\",span_class_value),16&dirty[0]&&set_style(span,\"background\",ctx[4][ctx[34]])},d(detaching){detaching&&detach(span)}}}function create_each_block(ctx){let lockablevaluetoggle,updating_lock,current;function lockablevaluetoggle_lock_binding_1(value){ctx[23].call(null,value)}let lockablevaluetoggle_props={set_value:ctx[34],style:\"display: inline\",$$slots:{default:[create_default_slot]},$$scope:{ctx}};return void 0!==ctx[0]&&(lockablevaluetoggle_props.lock=ctx[0]),lockablevaluetoggle=new LockableValueToggle_svelte({props:lockablevaluetoggle_props}),binding_callbacks.push((()=>bind(lockablevaluetoggle,\"lock\",lockablevaluetoggle_lock_binding_1))),{c(){create_component(lockablevaluetoggle.$$.fragment)},m(target,anchor){mount_component(lockablevaluetoggle,target,anchor),current=!0},p(ctx,dirty){const lockablevaluetoggle_changes={};560&dirty[0]|128&dirty[1]&&(lockablevaluetoggle_changes.$$scope={dirty,ctx}),!updating_lock&&1&dirty[0]&&(updating_lock=!0,lockablevaluetoggle_changes.lock=ctx[0],add_flush_callback((()=>updating_lock=!1))),lockablevaluetoggle.$set(lockablevaluetoggle_changes)},i(local){current||(transition_in(lockablevaluetoggle.$$.fragment,local),current=!0)},o(local){transition_out(lockablevaluetoggle.$$.fragment,local),current=!1},d(detaching){destroy_component(lockablevaluetoggle,detaching)}}}function create_if_block_1(ctx){let input,t0,span,t1,b,t2,mounted,dispose,t2_value=ctx[3]?\"info-weighted\":\"unmodified\";return{c(){input=internal_element(\"input\"),t0=space(),span=internal_element(\"span\"),t1=internal_text(\"Attention is\\n            \"),b=internal_element(\"b\"),t2=internal_text(t2_value),attr(input,\"class\",\"info-mode svelte-1rpu49t\"),attr(input,\"type\",\"checkbox\"),attr(span,\"class\",\"info-mode-text svelte-1rpu49t\"),set_style(span,\"white-space\",\"nowrap\")},m(target,anchor){insert(target,input,anchor),input.checked=ctx[3],insert(target,t0,anchor),insert(target,span,anchor),append(span,t1),append(span,b),append(b,t2),mounted||(dispose=[listen(input,\"change\",ctx[26]),listen(span,\"click\",ctx[27])],mounted=!0)},p(ctx,dirty){8&dirty[0]&&(input.checked=ctx[3]),8&dirty[0]&&t2_value!==(t2_value=ctx[3]?\"info-weighted\":\"unmodified\")&&set_data(t2,t2_value)},d(detaching){detaching&&detach(input),detaching&&detach(t0),detaching&&detach(span),mounted=!1,run_all(dispose)}}}function AttentionMulti_svelte_create_fragment(ctx){let div2,div0,t0,t1,t2,div1,arrayimage,div1_style_value,t3,t4,if_block3_anchor,current,if_block0=null!=ctx[10]&&create_if_block_4(ctx),if_block1=void 0!==ctx[7]&&create_if_block_3(ctx);arrayimage=new ArrayImage_svelte({props:{array:ctx[6],width:\"200\",height:\"200\",focus_token:ctx[9],isolate_channel:ctx[10]}});let if_block2=ctx[13]>1&&create_if_block_2(ctx),if_block3=ctx[8]&&AttentionMulti_svelte_create_if_block(ctx);return{c(){div2=internal_element(\"div\"),div0=internal_element(\"div\"),t0=internal_text(\"Attention Pattern\\n        \"),if_block0&&if_block0.c(),t1=space(),if_block1&&if_block1.c(),t2=space(),div1=internal_element(\"div\"),create_component(arrayimage.$$.fragment),t3=space(),if_block2&&if_block2.c(),t4=space(),if_block3&&if_block3.c(),if_block3_anchor=function empty(){return internal_text(\"\")}(),attr(div0,\"class\",\"figcaption svelte-1rpu49t\"),set_style(div0,\"grid-column\",\"big-attn\"),attr(div1,\"style\",div1_style_value=\"grid-column: big-attn; grid-row: main; \"+(ctx[11]?\"display:none\":\"\")),attr(div2,\"class\",\"attn-container svelte-1rpu49t\")},m(target,anchor){insert(target,div2,anchor),append(div2,div0),append(div0,t0),if_block0&&if_block0.m(div0,null),append(div2,t1),if_block1&&if_block1.m(div2,null),append(div2,t2),append(div2,div1),mount_component(arrayimage,div1,null),append(div2,t3),if_block2&&if_block2.m(div2,null),insert(target,t4,anchor),if_block3&&if_block3.m(target,anchor),insert(target,if_block3_anchor,anchor),current=!0},p(ctx,dirty){null!=ctx[10]?if_block0?if_block0.p(ctx,dirty):(if_block0=create_if_block_4(ctx),if_block0.c(),if_block0.m(div0,null)):if_block0&&(if_block0.d(1),if_block0=null),void 0!==ctx[7]?if_block1?(if_block1.p(ctx,dirty),128&dirty[0]&&transition_in(if_block1,1)):(if_block1=create_if_block_3(ctx),if_block1.c(),transition_in(if_block1,1),if_block1.m(div2,t2)):if_block1&&(group_outros(),transition_out(if_block1,1,1,(()=>{if_block1=null})),check_outros());const arrayimage_changes={};64&dirty[0]&&(arrayimage_changes.array=ctx[6]),512&dirty[0]&&(arrayimage_changes.focus_token=ctx[9]),1024&dirty[0]&&(arrayimage_changes.isolate_channel=ctx[10]),arrayimage.$set(arrayimage_changes),(!current||2048&dirty[0]&&div1_style_value!==(div1_style_value=\"grid-column: big-attn; grid-row: main; \"+(ctx[11]?\"display:none\":\"\")))&&attr(div1,\"style\",div1_style_value),ctx[13]>1?if_block2?(if_block2.p(ctx,dirty),8192&dirty[0]&&transition_in(if_block2,1)):(if_block2=create_if_block_2(ctx),if_block2.c(),transition_in(if_block2,1),if_block2.m(div2,null)):if_block2&&(group_outros(),transition_out(if_block2,1,1,(()=>{if_block2=null})),check_outros()),ctx[8]?if_block3?(if_block3.p(ctx,dirty),256&dirty[0]&&transition_in(if_block3,1)):(if_block3=AttentionMulti_svelte_create_if_block(ctx),if_block3.c(),transition_in(if_block3,1),if_block3.m(if_block3_anchor.parentNode,if_block3_anchor)):if_block3&&(group_outros(),transition_out(if_block3,1,1,(()=>{if_block3=null})),check_outros())},i(local){current||(transition_in(if_block1),transition_in(arrayimage.$$.fragment,local),transition_in(if_block2),transition_in(if_block3),current=!0)},o(local){transition_out(if_block1),transition_out(arrayimage.$$.fragment,local),transition_out(if_block2),transition_out(if_block3),current=!1},d(detaching){detaching&&detach(div2),if_block0&&if_block0.d(),if_block1&&if_block1.d(),destroy_component(arrayimage),if_block2&&if_block2.d(),detaching&&detach(t4),if_block3&&if_block3.d(detaching),detaching&&detach(if_block3_anchor)}}}function range(n){return[...Array(n).keys()]}function reduce_Y(arr){if(void 0!==arr){for(var arr_=[],x=0;x<arr.shape[0];x++){arr_.push([]);for(var c=0;c<arr.shape[2];c++){for(var temp=0,y=0;y<arr.shape[1];y++)temp=Math.max(temp,arr.pick(x,y,c));arr_[x].push(temp)}}return arr_}}function reduce_X(arr){if(void 0!==arr){for(var arr_=[],y=0;y<arr.shape[0];y++){arr_.push([]);for(var c=0;c<arr.shape[2];c++){for(var temp=0,x=0;x<arr.shape[1];x++)temp=Math.max(temp,arr.pick(x,y,c));arr_[y].push(temp)}}return arr_}}function AttentionMulti_svelte_instance($$self,$$props,$$invalidate){let focus_token,focus_head,show_info_weighted,attention_show,attention_reduce_dst_unmodified,attention_reduce_src_unmodified,attention_reduce_dst_info_weighted,attention_reduce_src_info_weighted,attention_reduce_dst,attention_reduce_src,N_heads,colors,head_labels_,{tokens}=$$props,{attention}=$$props,{info_weighted}=$$props,{head_labels}=$$props,{show_tokens=!0}=$$props,{focus_token_lock={value:void 0,mode:\"soft\"}}=$$props,{focus_head_lock={value:void 0,mode:\"soft\"}}=$$props,{hover_token_is_target=!1}=$$props,{_show_info_weighted=!1}=$$props;function token_color(attention,focus_token_value,tok_i,isolate_channel,hover_token_is_target){if(null==focus_token_value)return sparse_color_map_css((hover_token_is_target?attention_reduce_src:attention_reduce_dst)[tok_i],void 0,isolate_channel);let tok_from,tok_to;return hover_token_is_target?(tok_from=tok_i,tok_to=focus_token_value):(tok_from=focus_token_value,tok_to=tok_i),function get_color(array,x,y,isolate_channel){return x<y?\"#FFF\":sparse_color_map_css(array.pick(x,y,null),void 0,isolate_channel)}(attention,tok_from,tok_to,isolate_channel)}let{all_token_colors}=$$props;return $$self.$$set=$$props=>{\"tokens\"in $$props&&$$invalidate(5,tokens=$$props.tokens),\"attention\"in $$props&&$$invalidate(6,attention=$$props.attention),\"info_weighted\"in $$props&&$$invalidate(7,info_weighted=$$props.info_weighted),\"head_labels\"in $$props&&$$invalidate(17,head_labels=$$props.head_labels),\"show_tokens\"in $$props&&$$invalidate(8,show_tokens=$$props.show_tokens),\"focus_token_lock\"in $$props&&$$invalidate(0,focus_token_lock=$$props.focus_token_lock),\"focus_head_lock\"in $$props&&$$invalidate(1,focus_head_lock=$$props.focus_head_lock),\"hover_token_is_target\"in $$props&&$$invalidate(2,hover_token_is_target=$$props.hover_token_is_target),\"_show_info_weighted\"in $$props&&$$invalidate(3,_show_info_weighted=$$props._show_info_weighted),\"all_token_colors\"in $$props&&$$invalidate(4,all_token_colors=$$props.all_token_colors)},$$self.$$.update=()=>{1&$$self.$$.dirty[0]&&$$invalidate(9,focus_token=focus_token_lock.value),2&$$self.$$.dirty[0]&&$$invalidate(10,focus_head=focus_head_lock.value),136&$$self.$$.dirty[0]&&$$invalidate(11,show_info_weighted=_show_info_weighted&&void 0!==info_weighted),2240&$$self.$$.dirty[0]&&$$invalidate(12,attention_show=show_info_weighted?info_weighted:attention),4096&$$self.$$.dirty[0]&&(window.attention_show=attention_show),64&$$self.$$.dirty[0]&&$$invalidate(18,attention_reduce_dst_unmodified=reduce_Y(attention)),64&$$self.$$.dirty[0]&&$$invalidate(19,attention_reduce_src_unmodified=reduce_X(attention)),128&$$self.$$.dirty[0]&&$$invalidate(20,attention_reduce_dst_info_weighted=reduce_Y(info_weighted)),128&$$self.$$.dirty[0]&&$$invalidate(21,attention_reduce_src_info_weighted=reduce_X(info_weighted)),1312768&$$self.$$.dirty[0]&&(attention_reduce_dst=show_info_weighted?attention_reduce_dst_info_weighted:attention_reduce_dst_unmodified),2623488&$$self.$$.dirty[0]&&(attention_reduce_src=show_info_weighted?attention_reduce_src_info_weighted:attention_reduce_src_unmodified),64&$$self.$$.dirty[0]&&$$invalidate(13,N_heads=attention.shape[2]),8192&$$self.$$.dirty[0]&&$$invalidate(14,colors=range(N_heads).map((i=>sparse_color_map_css(range(N_heads).map((x=>1)),void 0,i)))),139264&$$self.$$.dirty[0]&&$$invalidate(15,head_labels_=null!=head_labels?head_labels:range(N_heads)),5668&$$self.$$.dirty[0]&&$$invalidate(4,all_token_colors=range(tokens.length).map((i=>token_color(attention_show,focus_token,i,focus_head,hover_token_is_target))))},[focus_token_lock,focus_head_lock,hover_token_is_target,_show_info_weighted,all_token_colors,tokens,attention,info_weighted,show_tokens,focus_token,focus_head,show_info_weighted,attention_show,N_heads,colors,head_labels_,function head_intensity(head_i,focus_token_value,hover_token_is_target){if(null==focus_token_value)var v=1;else{var reduced_attn=hover_token_is_target?attention_reduce_src:attention_reduce_dst;v=Math.max(0,Math.min(1,reduced_attn[focus_token_value][head_i]))}return\"\"+v},head_labels,attention_reduce_dst_unmodified,attention_reduce_src_unmodified,attention_reduce_dst_info_weighted,attention_reduce_src_info_weighted,function lockablevaluetoggle_lock_binding(value){focus_head_lock=value,$$invalidate(1,focus_head_lock)},function lockablevaluetoggle_lock_binding_1(value){focus_token_lock=value,$$invalidate(0,focus_token_lock)},function input_change_handler(){hover_token_is_target=this.checked,$$invalidate(2,hover_token_is_target)},()=>$$invalidate(2,hover_token_is_target^=!0),function input_change_handler_1(){_show_info_weighted=this.checked,$$invalidate(3,_show_info_weighted)},()=>$$invalidate(3,_show_info_weighted^=!0)]}const AttentionMulti_svelte=class AttentionMulti extends SvelteComponent{constructor(options){super(),document.getElementById(\"svelte-1rpu49t-style\")||function AttentionMulti_svelte_add_css(){var style=internal_element(\"style\");style.id=\"svelte-1rpu49t-style\",style.textContent=\".attn-container.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t{display:grid;grid-template-rows:[title] min-content [main] min-content;grid-template-columns:[big-attn] min-content [heads] minmax(min-content, 624px);gap:12px}.figcaption.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t{color:#888;grid-row:title;white-space:nowrap}.tokens-container.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t{display:grid;grid-template-rows:[title] min-content [main] min-content;grid-template-columns:[left] min-content [right] minmax(min-content, 800px) [end];gap:12px;margin-top:24px}.tokens.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t{grid-row:main;grid-column-start:left;grid-column-end:end;cursor:pointer;height:min-content;line-height:110%}.tokens.svelte-1rpu49t .token.svelte-1rpu49t.svelte-1rpu49t{white-space:pre-wrap}.tokens.svelte-1rpu49t .selected.svelte-1rpu49t.svelte-1rpu49t{border:1px solid #999;z-index:10}.tokens.svelte-1rpu49t .token.svelte-1rpu49t.svelte-1rpu49t:not(.selected){z-index:0;padding:1px}.hover-mode.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t,.hover-mode-text.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t,.info-mode.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t,.info-mode-text.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t{color:#888;grid-row:title;grid-column:settings;cursor:pointer}.hover-mode-text.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t,.info-mode-text.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t{margin-right:8px}.heads.svelte-1rpu49t.svelte-1rpu49t.svelte-1rpu49t{grid-column:heads;grid-row:main;display:flex;flex-direction:row;flex-wrap:wrap;gap:6px;height:min-content}.heads.svelte-1rpu49t .head-icon.svelte-1rpu49t.svelte-1rpu49t{position:relative;width:62px;height:62px}.heads.svelte-1rpu49t .head-icon.svelte-1rpu49t>.svelte-1rpu49t{position:absolute;right:0px;top:0px}.heads.svelte-1rpu49t .head-icon .head-label.svelte-1rpu49t.svelte-1rpu49t{background:#333;color:#eee;font-size:65%;padding:1px;border-bottom-left-radius:2px;padding-left:4px;padding-right:2px;min-width:14px;opacity:0.75}\",append(document.head,style)}(),init(this,options,AttentionMulti_svelte_instance,AttentionMulti_svelte_create_fragment,safe_not_equal,{tokens:5,attention:6,info_weighted:7,head_labels:17,show_tokens:8,focus_token_lock:0,focus_head_lock:1,hover_token_is_target:2,_show_info_weighted:3,all_token_colors:4},[-1,-1])}}}},__webpack_module_cache__={};function __webpack_require__(moduleId){if(__webpack_module_cache__[moduleId])return __webpack_module_cache__[moduleId].exports;var module=__webpack_module_cache__[moduleId]={exports:{}};return __webpack_modules__[moduleId](module,module.exports,__webpack_require__),module.exports}return __webpack_require__.d=(exports,definition)=>{for(var key in definition)__webpack_require__.o(definition,key)&&!__webpack_require__.o(exports,key)&&Object.defineProperty(exports,key,{enumerable:!0,get:definition[key]})},__webpack_require__.o=(obj,prop)=>Object.prototype.hasOwnProperty.call(obj,prop),__webpack_require__(143)})().default;</script>\n",
              "<script>/*! For license information please see loader.js.LICENSE.txt */\n",
              "var loader;loader=(()=>{var __webpack_modules__={907:module=>{\"use strict\";module.exports=function iota(n){for(var result=new Array(n),i=0;i<n;++i)result[i]=i;return result}},738:module=>{function isBuffer(obj){return!!obj.constructor&&\"function\"==typeof obj.constructor.isBuffer&&obj.constructor.isBuffer(obj)}module.exports=function(obj){return null!=obj&&(isBuffer(obj)||function isSlowBuffer(obj){return\"function\"==typeof obj.readFloatLE&&\"function\"==typeof obj.slice&&isBuffer(obj.slice(0,0))}(obj)||!!obj._isBuffer)}},861:(module,__unused_webpack_exports,__webpack_require__)=>{var iota=__webpack_require__(907),isBuffer=__webpack_require__(738),hasTypedArrays=\"undefined\"!=typeof Float64Array;function compare1st(a,b){return a[0]-b[0]}function order(){var i,stride=this.stride,terms=new Array(stride.length);for(i=0;i<terms.length;++i)terms[i]=[Math.abs(stride[i]),i];terms.sort(compare1st);var result=new Array(terms.length);for(i=0;i<result.length;++i)result[i]=terms[i][1];return result}function compileConstructor(dtype,dimension){var className=[\"View\",dimension,\"d\",dtype].join(\"\");dimension<0&&(className=\"View_Nil\"+dtype);var useGetters=\"generic\"===dtype;if(-1===dimension){var code=\"function \"+className+\"(a){this.data=a;};var proto=\"+className+\".prototype;proto.dtype='\"+dtype+\"';proto.index=function(){return -1};proto.size=0;proto.dimension=-1;proto.shape=proto.stride=proto.order=[];proto.lo=proto.hi=proto.transpose=proto.step=function(){return new \"+className+\"(this.data);};proto.get=proto.set=function(){};proto.pick=function(){return null};return function construct_\"+className+\"(a){return new \"+className+\"(a);}\";return new Function(code)()}if(0===dimension){code=\"function \"+className+\"(a,d) {this.data = a;this.offset = d};var proto=\"+className+\".prototype;proto.dtype='\"+dtype+\"';proto.index=function(){return this.offset};proto.dimension=0;proto.size=1;proto.shape=proto.stride=proto.order=[];proto.lo=proto.hi=proto.transpose=proto.step=function \"+className+\"_copy() {return new \"+className+\"(this.data,this.offset)};proto.pick=function \"+className+\"_pick(){return TrivialArray(this.data);};proto.valueOf=proto.get=function \"+className+\"_get(){return \"+(useGetters?\"this.data.get(this.offset)\":\"this.data[this.offset]\")+\"};proto.set=function \"+className+\"_set(v){return \"+(useGetters?\"this.data.set(this.offset,v)\":\"this.data[this.offset]=v\")+\"};return function construct_\"+className+\"(a,b,c,d){return new \"+className+\"(a,d)}\";return new Function(\"TrivialArray\",code)(CACHED_CONSTRUCTORS[dtype][0])}code=[\"'use strict'\"];var indices=iota(dimension),args=indices.map((function(i){return\"i\"+i})),index_str=\"this.offset+\"+indices.map((function(i){return\"this.stride[\"+i+\"]*i\"+i})).join(\"+\"),shapeArg=indices.map((function(i){return\"b\"+i})).join(\",\"),strideArg=indices.map((function(i){return\"c\"+i})).join(\",\");code.push(\"function \"+className+\"(a,\"+shapeArg+\",\"+strideArg+\",d){this.data=a\",\"this.shape=[\"+shapeArg+\"]\",\"this.stride=[\"+strideArg+\"]\",\"this.offset=d|0}\",\"var proto=\"+className+\".prototype\",\"proto.dtype='\"+dtype+\"'\",\"proto.dimension=\"+dimension),code.push(\"Object.defineProperty(proto,'size',{get:function \"+className+\"_size(){return \"+indices.map((function(i){return\"this.shape[\"+i+\"]\"})).join(\"*\"),\"}})\"),1===dimension?code.push(\"proto.order=[0]\"):(code.push(\"Object.defineProperty(proto,'order',{get:\"),dimension<4?(code.push(\"function \"+className+\"_order(){\"),2===dimension?code.push(\"return (Math.abs(this.stride[0])>Math.abs(this.stride[1]))?[1,0]:[0,1]}})\"):3===dimension&&code.push(\"var s0=Math.abs(this.stride[0]),s1=Math.abs(this.stride[1]),s2=Math.abs(this.stride[2]);if(s0>s1){if(s1>s2){return [2,1,0];}else if(s0>s2){return [1,2,0];}else{return [1,0,2];}}else if(s0>s2){return [2,0,1];}else if(s2>s1){return [0,1,2];}else{return [0,2,1];}}})\")):code.push(\"ORDER})\")),code.push(\"proto.set=function \"+className+\"_set(\"+args.join(\",\")+\",v){\"),useGetters?code.push(\"return this.data.set(\"+index_str+\",v)}\"):code.push(\"return this.data[\"+index_str+\"]=v}\"),code.push(\"proto.get=function \"+className+\"_get(\"+args.join(\",\")+\"){\"),useGetters?code.push(\"return this.data.get(\"+index_str+\")}\"):code.push(\"return this.data[\"+index_str+\"]}\"),code.push(\"proto.index=function \"+className+\"_index(\",args.join(),\"){return \"+index_str+\"}\"),code.push(\"proto.hi=function \"+className+\"_hi(\"+args.join(\",\")+\"){return new \"+className+\"(this.data,\"+indices.map((function(i){return[\"(typeof i\",i,\"!=='number'||i\",i,\"<0)?this.shape[\",i,\"]:i\",i,\"|0\"].join(\"\")})).join(\",\")+\",\"+indices.map((function(i){return\"this.stride[\"+i+\"]\"})).join(\",\")+\",this.offset)}\");var a_vars=indices.map((function(i){return\"a\"+i+\"=this.shape[\"+i+\"]\"})),c_vars=indices.map((function(i){return\"c\"+i+\"=this.stride[\"+i+\"]\"}));code.push(\"proto.lo=function \"+className+\"_lo(\"+args.join(\",\")+\"){var b=this.offset,d=0,\"+a_vars.join(\",\")+\",\"+c_vars.join(\",\"));for(var i=0;i<dimension;++i)code.push(\"if(typeof i\"+i+\"==='number'&&i\"+i+\">=0){d=i\"+i+\"|0;b+=c\"+i+\"*d;a\"+i+\"-=d}\");code.push(\"return new \"+className+\"(this.data,\"+indices.map((function(i){return\"a\"+i})).join(\",\")+\",\"+indices.map((function(i){return\"c\"+i})).join(\",\")+\",b)}\"),code.push(\"proto.step=function \"+className+\"_step(\"+args.join(\",\")+\"){var \"+indices.map((function(i){return\"a\"+i+\"=this.shape[\"+i+\"]\"})).join(\",\")+\",\"+indices.map((function(i){return\"b\"+i+\"=this.stride[\"+i+\"]\"})).join(\",\")+\",c=this.offset,d=0,ceil=Math.ceil\");for(i=0;i<dimension;++i)code.push(\"if(typeof i\"+i+\"==='number'){d=i\"+i+\"|0;if(d<0){c+=b\"+i+\"*(a\"+i+\"-1);a\"+i+\"=ceil(-a\"+i+\"/d)}else{a\"+i+\"=ceil(a\"+i+\"/d)}b\"+i+\"*=d}\");code.push(\"return new \"+className+\"(this.data,\"+indices.map((function(i){return\"a\"+i})).join(\",\")+\",\"+indices.map((function(i){return\"b\"+i})).join(\",\")+\",c)}\");var tShape=new Array(dimension),tStride=new Array(dimension);for(i=0;i<dimension;++i)tShape[i]=\"a[i\"+i+\"]\",tStride[i]=\"b[i\"+i+\"]\";code.push(\"proto.transpose=function \"+className+\"_transpose(\"+args+\"){\"+args.map((function(n,idx){return n+\"=(\"+n+\"===undefined?\"+idx+\":\"+n+\"|0)\"})).join(\";\"),\"var a=this.shape,b=this.stride;return new \"+className+\"(this.data,\"+tShape.join(\",\")+\",\"+tStride.join(\",\")+\",this.offset)}\"),code.push(\"proto.pick=function \"+className+\"_pick(\"+args+\"){var a=[],b=[],c=this.offset\");for(i=0;i<dimension;++i)code.push(\"if(typeof i\"+i+\"==='number'&&i\"+i+\">=0){c=(c+this.stride[\"+i+\"]*i\"+i+\")|0}else{a.push(this.shape[\"+i+\"]);b.push(this.stride[\"+i+\"])}\");return code.push(\"var ctor=CTOR_LIST[a.length+1];return ctor(this.data,a,b,c)}\"),code.push(\"return function construct_\"+className+\"(data,shape,stride,offset){return new \"+className+\"(data,\"+indices.map((function(i){return\"shape[\"+i+\"]\"})).join(\",\")+\",\"+indices.map((function(i){return\"stride[\"+i+\"]\"})).join(\",\")+\",offset)}\"),new Function(\"CTOR_LIST\",\"ORDER\",code.join(\"\\n\"))(CACHED_CONSTRUCTORS[dtype],order)}var CACHED_CONSTRUCTORS={float32:[],float64:[],int8:[],int16:[],int32:[],uint8:[],uint16:[],uint32:[],array:[],uint8_clamped:[],bigint64:[],biguint64:[],buffer:[],generic:[]};module.exports=function wrappedNDArrayCtor(data,shape,stride,offset){if(void 0===data)return(0,CACHED_CONSTRUCTORS.array[0])([]);\"number\"==typeof data&&(data=[data]),void 0===shape&&(shape=[data.length]);var d=shape.length;if(void 0===stride){stride=new Array(d);for(var i=d-1,sz=1;i>=0;--i)stride[i]=sz,sz*=shape[i]}if(void 0===offset){offset=0;for(i=0;i<d;++i)stride[i]<0&&(offset-=(shape[i]-1)*stride[i])}for(var dtype=function arrayDType(data){if(isBuffer(data))return\"buffer\";if(hasTypedArrays)switch(Object.prototype.toString.call(data)){case\"[object Float64Array]\":return\"float64\";case\"[object Float32Array]\":return\"float32\";case\"[object Int8Array]\":return\"int8\";case\"[object Int16Array]\":return\"int16\";case\"[object Int32Array]\":return\"int32\";case\"[object Uint8Array]\":return\"uint8\";case\"[object Uint16Array]\":return\"uint16\";case\"[object Uint32Array]\":return\"uint32\";case\"[object Uint8ClampedArray]\":return\"uint8_clamped\";case\"[object BigInt64Array]\":return\"bigint64\";case\"[object BigUint64Array]\":return\"biguint64\"}return Array.isArray(data)?\"array\":\"generic\"}(data),ctor_list=CACHED_CONSTRUCTORS[dtype];ctor_list.length<=d+1;)ctor_list.push(compileConstructor(dtype,ctor_list.length-1));return(0,ctor_list[d+1])(data,shape,stride,offset)}},829:(__unused_webpack_module,exports)=>{\"use strict\";function _defineProperties(a,b){for(var c,d=0;d<b.length;d++)(c=b[d]).enumerable=c.enumerable||!1,c.configurable=!0,\"value\"in c&&(c.writable=!0),Object.defineProperty(a,c.key,c)}exports.g=function fromArrayBuffer(a){if(!a instanceof ArrayBuffer)throw new Error(\"Argument must be an ArrayBuffer.\");var b=new DataViewReader(a),c=b.readUint8(),d=b.readAndASCIIDecodeBytes(5);if(147!=c||\"NUMPY\"!=d)throw new Error('unknown file type: \"'.concat(c).concat(d,'\"'));var e,f=b.readUint8(),h=(b.readUint8(),10+(e=1>=f?b.readUint16(!0):b.readUint32(!0)));0!=h%16&&console.warn(\"NPY file header is incorrectly padded. (\".concat(h,\" is not evenly divisible by 16.)\"));var j=function parseHeaderStr(a){var b=a.toLowerCase().replace(\"(\",\"[\").replace(\"),\",\"]\").replace(\"[,\",\"[1,]\").replace(\",]\",\",1]\").replace(/'/g,'\"');return JSON.parse(b)}(b.readAndASCIIDecodeBytes(e));if(j.fortran_order)throw new Error(\"NPY file is written in Fortran byte order, support for this byte order is not yet implemented.\");return{data:new(typedArrayConstructorForDescription(j.descr))(a,b.offset),shape:j.shape}};var DataViewReader=function(){function a(b){(function _classCallCheck(a,b){if(!(a instanceof b))throw new TypeError(\"Cannot call a class as a function\")})(this,a),b instanceof DataView?this.dataView=b:b instanceof ArrayBuffer&&(this.dataView=new DataView(b)),this.offset=0}return function _createClass(a,b,c){return b&&_defineProperties(a.prototype,b),c&&_defineProperties(a,c),a}(a,[{key:\"readBytes\",value:function c(a){var b=new DataView(this.dataView.buffer,this.offset,a);return this.offset+=a,b}},{key:\"readAndASCIIDecodeBytes\",value:function c(a){var b=new Uint8Array(this.dataView.buffer,this.offset,a);return this.offset+=a,this._decodeASCIIByteArray(b)}},{key:\"readUint8\",value:function c(){var a=!!(0<arguments.length&&void 0!==arguments[0])&&arguments[0],b=this.dataView.getUint8(this.offset,a);return this.offset+=Uint8Array.BYTES_PER_ELEMENT,b}},{key:\"readUint16\",value:function c(){var a=!!(0<arguments.length&&void 0!==arguments[0])&&arguments[0],b=this.dataView.getUint16(this.offset,a);return this.offset+=Uint16Array.BYTES_PER_ELEMENT,b}},{key:\"readUint32\",value:function c(){var a=!!(0<arguments.length&&void 0!==arguments[0])&&arguments[0],b=this.dataView.getUint32(this.offset,a);return this.offset+=Uint32Array.BYTES_PER_ELEMENT,b}},{key:\"_decodeASCIIByteArray\",value:function k(a){var b=String.fromCharCode,c=[],d=!0,e=!1,f=void 0;try{for(var g,h=a[Symbol.iterator]();!(d=(g=h.next()).done);d=!0){var j=b(g.value);c.push(j)}}catch(a){e=!0,f=a}finally{try{d||null==h.return||h.return()}finally{if(e)throw f}}return c.join(\"\")}}]),a}();function typedArrayConstructorForDescription(a){switch(a){case\"|u1\":return Uint8Array;case\"<u2\":return Uint16Array;case\"<u4\":return Uint32Array;case\"<u8\":throw new Error(\"Because JavaScript doesn't currently include standard support for 64-bit unsigned integer values, support for this dtype is not yet implemented.\");case\"|i1\":return Int8Array;case\"<i2\":return Int16Array;case\"<i4\":return Int32Array;case\"<i8\":throw new Error(\"Because JavaScript doesn't currently include standard support for 64-bit integer values, support for this dtype is not yet implemented.\");case\"<f2\":throw new Error(\"Because JavaScript doesn't currently include standard support for 16-bit floating point values, support for this dtype is not yet implemented.\");case\"<f4\":return Float32Array;case\"<f8\":return Float64Array;default:throw new Error(\"Unknown or not yet implemented numpy dtype description: \"+dtype)}}},843:(module,__unused_webpack_exports,__webpack_require__)=>{\"use strict\";const zlib_inflate=__webpack_require__(948),utils=__webpack_require__(236),strings=__webpack_require__(373),msg=__webpack_require__(898),ZStream=__webpack_require__(292),GZheader=__webpack_require__(401),toString=Object.prototype.toString,{Z_NO_FLUSH,Z_FINISH,Z_OK,Z_STREAM_END,Z_NEED_DICT,Z_STREAM_ERROR,Z_DATA_ERROR,Z_MEM_ERROR}=__webpack_require__(619);function Inflate(options){this.options=utils.assign({chunkSize:65536,windowBits:15,to:\"\"},options||{});const opt=this.options;opt.raw&&opt.windowBits>=0&&opt.windowBits<16&&(opt.windowBits=-opt.windowBits,0===opt.windowBits&&(opt.windowBits=-15)),!(opt.windowBits>=0&&opt.windowBits<16)||options&&options.windowBits||(opt.windowBits+=32),opt.windowBits>15&&opt.windowBits<48&&0==(15&opt.windowBits)&&(opt.windowBits|=15),this.err=0,this.msg=\"\",this.ended=!1,this.chunks=[],this.strm=new ZStream,this.strm.avail_out=0;let status=zlib_inflate.inflateInit2(this.strm,opt.windowBits);if(status!==Z_OK)throw new Error(msg[status]);if(this.header=new GZheader,zlib_inflate.inflateGetHeader(this.strm,this.header),opt.dictionary&&(\"string\"==typeof opt.dictionary?opt.dictionary=strings.string2buf(opt.dictionary):\"[object ArrayBuffer]\"===toString.call(opt.dictionary)&&(opt.dictionary=new Uint8Array(opt.dictionary)),opt.raw&&(status=zlib_inflate.inflateSetDictionary(this.strm,opt.dictionary),status!==Z_OK)))throw new Error(msg[status])}function inflate(input,options){const inflator=new Inflate(options);if(inflator.push(input),inflator.err)throw inflator.msg||msg[inflator.err];return inflator.result}Inflate.prototype.push=function(data,flush_mode){const strm=this.strm,chunkSize=this.options.chunkSize,dictionary=this.options.dictionary;let status,_flush_mode,last_avail_out;if(this.ended)return!1;for(_flush_mode=flush_mode===~~flush_mode?flush_mode:!0===flush_mode?Z_FINISH:Z_NO_FLUSH,\"[object ArrayBuffer]\"===toString.call(data)?strm.input=new Uint8Array(data):strm.input=data,strm.next_in=0,strm.avail_in=strm.input.length;;){for(0===strm.avail_out&&(strm.output=new Uint8Array(chunkSize),strm.next_out=0,strm.avail_out=chunkSize),status=zlib_inflate.inflate(strm,_flush_mode),status===Z_NEED_DICT&&dictionary&&(status=zlib_inflate.inflateSetDictionary(strm,dictionary),status===Z_OK?status=zlib_inflate.inflate(strm,_flush_mode):status===Z_DATA_ERROR&&(status=Z_NEED_DICT));strm.avail_in>0&&status===Z_STREAM_END&&strm.state.wrap>0&&0!==data[strm.next_in];)zlib_inflate.inflateReset(strm),status=zlib_inflate.inflate(strm,_flush_mode);switch(status){case Z_STREAM_ERROR:case Z_DATA_ERROR:case Z_NEED_DICT:case Z_MEM_ERROR:return this.onEnd(status),this.ended=!0,!1}if(last_avail_out=strm.avail_out,strm.next_out&&(0===strm.avail_out||status===Z_STREAM_END))if(\"string\"===this.options.to){let next_out_utf8=strings.utf8border(strm.output,strm.next_out),tail=strm.next_out-next_out_utf8,utf8str=strings.buf2string(strm.output,next_out_utf8);strm.next_out=tail,strm.avail_out=chunkSize-tail,tail&&strm.output.set(strm.output.subarray(next_out_utf8,next_out_utf8+tail),0),this.onData(utf8str)}else this.onData(strm.output.length===strm.next_out?strm.output:strm.output.subarray(0,strm.next_out));if(status!==Z_OK||0!==last_avail_out){if(status===Z_STREAM_END)return status=zlib_inflate.inflateEnd(this.strm),this.onEnd(status),this.ended=!0,!0;if(0===strm.avail_in)break}}return!0},Inflate.prototype.onData=function(chunk){this.chunks.push(chunk)},Inflate.prototype.onEnd=function(status){status===Z_OK&&(\"string\"===this.options.to?this.result=this.chunks.join(\"\"):this.result=utils.flattenChunks(this.chunks)),this.chunks=[],this.err=status,this.msg=this.strm.msg},module.exports.rr=inflate,__webpack_require__(619)},236:module=>{\"use strict\";const _has=(obj,key)=>Object.prototype.hasOwnProperty.call(obj,key);module.exports.assign=function(obj){const sources=Array.prototype.slice.call(arguments,1);for(;sources.length;){const source=sources.shift();if(source){if(\"object\"!=typeof source)throw new TypeError(source+\"must be non-object\");for(const p in source)_has(source,p)&&(obj[p]=source[p])}}return obj},module.exports.flattenChunks=chunks=>{let len=0;for(let i=0,l=chunks.length;i<l;i++)len+=chunks[i].length;const result=new Uint8Array(len);for(let i=0,pos=0,l=chunks.length;i<l;i++){let chunk=chunks[i];result.set(chunk,pos),pos+=chunk.length}return result}},373:module=>{\"use strict\";let STR_APPLY_UIA_OK=!0;try{String.fromCharCode.apply(null,new Uint8Array(1))}catch(__){STR_APPLY_UIA_OK=!1}const _utf8len=new Uint8Array(256);for(let q=0;q<256;q++)_utf8len[q]=q>=252?6:q>=248?5:q>=240?4:q>=224?3:q>=192?2:1;_utf8len[254]=_utf8len[254]=1,module.exports.string2buf=str=>{let buf,c,c2,m_pos,i,str_len=str.length,buf_len=0;for(m_pos=0;m_pos<str_len;m_pos++)c=str.charCodeAt(m_pos),55296==(64512&c)&&m_pos+1<str_len&&(c2=str.charCodeAt(m_pos+1),56320==(64512&c2)&&(c=65536+(c-55296<<10)+(c2-56320),m_pos++)),buf_len+=c<128?1:c<2048?2:c<65536?3:4;for(buf=new Uint8Array(buf_len),i=0,m_pos=0;i<buf_len;m_pos++)c=str.charCodeAt(m_pos),55296==(64512&c)&&m_pos+1<str_len&&(c2=str.charCodeAt(m_pos+1),56320==(64512&c2)&&(c=65536+(c-55296<<10)+(c2-56320),m_pos++)),c<128?buf[i++]=c:c<2048?(buf[i++]=192|c>>>6,buf[i++]=128|63&c):c<65536?(buf[i++]=224|c>>>12,buf[i++]=128|c>>>6&63,buf[i++]=128|63&c):(buf[i++]=240|c>>>18,buf[i++]=128|c>>>12&63,buf[i++]=128|c>>>6&63,buf[i++]=128|63&c);return buf};module.exports.buf2string=(buf,max)=>{let i,out;const len=max||buf.length,utf16buf=new Array(2*len);for(out=0,i=0;i<len;){let c=buf[i++];if(c<128){utf16buf[out++]=c;continue}let c_len=_utf8len[c];if(c_len>4)utf16buf[out++]=65533,i+=c_len-1;else{for(c&=2===c_len?31:3===c_len?15:7;c_len>1&&i<len;)c=c<<6|63&buf[i++],c_len--;c_len>1?utf16buf[out++]=65533:c<65536?utf16buf[out++]=c:(c-=65536,utf16buf[out++]=55296|c>>10&1023,utf16buf[out++]=56320|1023&c)}}return((buf,len)=>{if(len<65534&&buf.subarray&&STR_APPLY_UIA_OK)return String.fromCharCode.apply(null,buf.length===len?buf:buf.subarray(0,len));let result=\"\";for(let i=0;i<len;i++)result+=String.fromCharCode(buf[i]);return result})(utf16buf,out)},module.exports.utf8border=(buf,max)=>{(max=max||buf.length)>buf.length&&(max=buf.length);let pos=max-1;for(;pos>=0&&128==(192&buf[pos]);)pos--;return pos<0||0===pos?max:pos+_utf8len[buf[pos]]>max?pos:max}},69:module=>{\"use strict\";module.exports=(adler,buf,len,pos)=>{let s1=65535&adler|0,s2=adler>>>16&65535|0,n=0;for(;0!==len;){n=len>2e3?2e3:len,len-=n;do{s1=s1+buf[pos++]|0,s2=s2+s1|0}while(--n);s1%=65521,s2%=65521}return s1|s2<<16|0}},619:module=>{\"use strict\";module.exports={Z_NO_FLUSH:0,Z_PARTIAL_FLUSH:1,Z_SYNC_FLUSH:2,Z_FULL_FLUSH:3,Z_FINISH:4,Z_BLOCK:5,Z_TREES:6,Z_OK:0,Z_STREAM_END:1,Z_NEED_DICT:2,Z_ERRNO:-1,Z_STREAM_ERROR:-2,Z_DATA_ERROR:-3,Z_MEM_ERROR:-4,Z_BUF_ERROR:-5,Z_NO_COMPRESSION:0,Z_BEST_SPEED:1,Z_BEST_COMPRESSION:9,Z_DEFAULT_COMPRESSION:-1,Z_FILTERED:1,Z_HUFFMAN_ONLY:2,Z_RLE:3,Z_FIXED:4,Z_DEFAULT_STRATEGY:0,Z_BINARY:0,Z_TEXT:1,Z_UNKNOWN:2,Z_DEFLATED:8}},869:module=>{\"use strict\";const crcTable=new Uint32Array((()=>{let c,table=[];for(var n=0;n<256;n++){c=n;for(var k=0;k<8;k++)c=1&c?3988292384^c>>>1:c>>>1;table[n]=c}return table})());module.exports=(crc,buf,len,pos)=>{const t=crcTable,end=pos+len;crc^=-1;for(let i=pos;i<end;i++)crc=crc>>>8^t[255&(crc^buf[i])];return-1^crc}},401:module=>{\"use strict\";module.exports=function GZheader(){this.text=0,this.time=0,this.xflags=0,this.os=0,this.extra=null,this.extra_len=0,this.name=\"\",this.comment=\"\",this.hcrc=0,this.done=!1}},264:module=>{\"use strict\";module.exports=function inflate_fast(strm,start){let _in,last,_out,beg,end,dmax,wsize,whave,wnext,s_window,hold,bits,lcode,dcode,lmask,dmask,here,op,len,dist,from,from_source,input,output;const state=strm.state;_in=strm.next_in,input=strm.input,last=_in+(strm.avail_in-5),_out=strm.next_out,output=strm.output,beg=_out-(start-strm.avail_out),end=_out+(strm.avail_out-257),dmax=state.dmax,wsize=state.wsize,whave=state.whave,wnext=state.wnext,s_window=state.window,hold=state.hold,bits=state.bits,lcode=state.lencode,dcode=state.distcode,lmask=(1<<state.lenbits)-1,dmask=(1<<state.distbits)-1;top:do{bits<15&&(hold+=input[_in++]<<bits,bits+=8,hold+=input[_in++]<<bits,bits+=8),here=lcode[hold&lmask];dolen:for(;;){if(op=here>>>24,hold>>>=op,bits-=op,op=here>>>16&255,0===op)output[_out++]=65535&here;else{if(!(16&op)){if(0==(64&op)){here=lcode[(65535&here)+(hold&(1<<op)-1)];continue dolen}if(32&op){state.mode=12;break top}strm.msg=\"invalid literal/length code\",state.mode=30;break top}len=65535&here,op&=15,op&&(bits<op&&(hold+=input[_in++]<<bits,bits+=8),len+=hold&(1<<op)-1,hold>>>=op,bits-=op),bits<15&&(hold+=input[_in++]<<bits,bits+=8,hold+=input[_in++]<<bits,bits+=8),here=dcode[hold&dmask];dodist:for(;;){if(op=here>>>24,hold>>>=op,bits-=op,op=here>>>16&255,!(16&op)){if(0==(64&op)){here=dcode[(65535&here)+(hold&(1<<op)-1)];continue dodist}strm.msg=\"invalid distance code\",state.mode=30;break top}if(dist=65535&here,op&=15,bits<op&&(hold+=input[_in++]<<bits,bits+=8,bits<op&&(hold+=input[_in++]<<bits,bits+=8)),dist+=hold&(1<<op)-1,dist>dmax){strm.msg=\"invalid distance too far back\",state.mode=30;break top}if(hold>>>=op,bits-=op,op=_out-beg,dist>op){if(op=dist-op,op>whave&&state.sane){strm.msg=\"invalid distance too far back\",state.mode=30;break top}if(from=0,from_source=s_window,0===wnext){if(from+=wsize-op,op<len){len-=op;do{output[_out++]=s_window[from++]}while(--op);from=_out-dist,from_source=output}}else if(wnext<op){if(from+=wsize+wnext-op,op-=wnext,op<len){len-=op;do{output[_out++]=s_window[from++]}while(--op);if(from=0,wnext<len){op=wnext,len-=op;do{output[_out++]=s_window[from++]}while(--op);from=_out-dist,from_source=output}}}else if(from+=wnext-op,op<len){len-=op;do{output[_out++]=s_window[from++]}while(--op);from=_out-dist,from_source=output}for(;len>2;)output[_out++]=from_source[from++],output[_out++]=from_source[from++],output[_out++]=from_source[from++],len-=3;len&&(output[_out++]=from_source[from++],len>1&&(output[_out++]=from_source[from++]))}else{from=_out-dist;do{output[_out++]=output[from++],output[_out++]=output[from++],output[_out++]=output[from++],len-=3}while(len>2);len&&(output[_out++]=output[from++],len>1&&(output[_out++]=output[from++]))}break}}break}}while(_in<last&&_out<end);len=bits>>3,_in-=len,bits-=len<<3,hold&=(1<<bits)-1,strm.next_in=_in,strm.next_out=_out,strm.avail_in=_in<last?last-_in+5:5-(_in-last),strm.avail_out=_out<end?end-_out+257:257-(_out-end),state.hold=hold,state.bits=bits}},948:(module,__unused_webpack_exports,__webpack_require__)=>{\"use strict\";const adler32=__webpack_require__(69),crc32=__webpack_require__(869),inflate_fast=__webpack_require__(264),inflate_table=__webpack_require__(241),{Z_FINISH,Z_BLOCK,Z_TREES,Z_OK,Z_STREAM_END,Z_NEED_DICT,Z_STREAM_ERROR,Z_DATA_ERROR,Z_MEM_ERROR,Z_BUF_ERROR,Z_DEFLATED}=__webpack_require__(619),zswap32=q=>(q>>>24&255)+(q>>>8&65280)+((65280&q)<<8)+((255&q)<<24);function InflateState(){this.mode=0,this.last=!1,this.wrap=0,this.havedict=!1,this.flags=0,this.dmax=0,this.check=0,this.total=0,this.head=null,this.wbits=0,this.wsize=0,this.whave=0,this.wnext=0,this.window=null,this.hold=0,this.bits=0,this.length=0,this.offset=0,this.extra=0,this.lencode=null,this.distcode=null,this.lenbits=0,this.distbits=0,this.ncode=0,this.nlen=0,this.ndist=0,this.have=0,this.next=null,this.lens=new Uint16Array(320),this.work=new Uint16Array(288),this.lendyn=null,this.distdyn=null,this.sane=0,this.back=0,this.was=0}const inflateResetKeep=strm=>{if(!strm||!strm.state)return Z_STREAM_ERROR;const state=strm.state;return strm.total_in=strm.total_out=state.total=0,strm.msg=\"\",state.wrap&&(strm.adler=1&state.wrap),state.mode=1,state.last=0,state.havedict=0,state.dmax=32768,state.head=null,state.hold=0,state.bits=0,state.lencode=state.lendyn=new Int32Array(852),state.distcode=state.distdyn=new Int32Array(592),state.sane=1,state.back=-1,Z_OK},inflateReset=strm=>{if(!strm||!strm.state)return Z_STREAM_ERROR;const state=strm.state;return state.wsize=0,state.whave=0,state.wnext=0,inflateResetKeep(strm)},inflateReset2=(strm,windowBits)=>{let wrap;if(!strm||!strm.state)return Z_STREAM_ERROR;const state=strm.state;return windowBits<0?(wrap=0,windowBits=-windowBits):(wrap=1+(windowBits>>4),windowBits<48&&(windowBits&=15)),windowBits&&(windowBits<8||windowBits>15)?Z_STREAM_ERROR:(null!==state.window&&state.wbits!==windowBits&&(state.window=null),state.wrap=wrap,state.wbits=windowBits,inflateReset(strm))},inflateInit2=(strm,windowBits)=>{if(!strm)return Z_STREAM_ERROR;const state=new InflateState;strm.state=state,state.window=null;const ret=inflateReset2(strm,windowBits);return ret!==Z_OK&&(strm.state=null),ret};let lenfix,distfix,virgin=!0;const fixedtables=state=>{if(virgin){lenfix=new Int32Array(512),distfix=new Int32Array(32);let sym=0;for(;sym<144;)state.lens[sym++]=8;for(;sym<256;)state.lens[sym++]=9;for(;sym<280;)state.lens[sym++]=7;for(;sym<288;)state.lens[sym++]=8;for(inflate_table(1,state.lens,0,288,lenfix,0,state.work,{bits:9}),sym=0;sym<32;)state.lens[sym++]=5;inflate_table(2,state.lens,0,32,distfix,0,state.work,{bits:5}),virgin=!1}state.lencode=lenfix,state.lenbits=9,state.distcode=distfix,state.distbits=5},updatewindow=(strm,src,end,copy)=>{let dist;const state=strm.state;return null===state.window&&(state.wsize=1<<state.wbits,state.wnext=0,state.whave=0,state.window=new Uint8Array(state.wsize)),copy>=state.wsize?(state.window.set(src.subarray(end-state.wsize,end),0),state.wnext=0,state.whave=state.wsize):(dist=state.wsize-state.wnext,dist>copy&&(dist=copy),state.window.set(src.subarray(end-copy,end-copy+dist),state.wnext),(copy-=dist)?(state.window.set(src.subarray(end-copy,end),0),state.wnext=copy,state.whave=state.wsize):(state.wnext+=dist,state.wnext===state.wsize&&(state.wnext=0),state.whave<state.wsize&&(state.whave+=dist))),0};module.exports.inflateReset=inflateReset,module.exports.inflateReset2=inflateReset2,module.exports.inflateResetKeep=inflateResetKeep,module.exports.inflateInit=strm=>inflateInit2(strm,15),module.exports.inflateInit2=inflateInit2,module.exports.inflate=(strm,flush)=>{let state,input,output,next,put,have,left,hold,bits,_in,_out,copy,from,from_source,here_bits,here_op,here_val,last_bits,last_op,last_val,len,ret,here=0;const hbuf=new Uint8Array(4);let opts,n;const order=new Uint8Array([16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15]);if(!strm||!strm.state||!strm.output||!strm.input&&0!==strm.avail_in)return Z_STREAM_ERROR;state=strm.state,12===state.mode&&(state.mode=13),put=strm.next_out,output=strm.output,left=strm.avail_out,next=strm.next_in,input=strm.input,have=strm.avail_in,hold=state.hold,bits=state.bits,_in=have,_out=left,ret=Z_OK;inf_leave:for(;;)switch(state.mode){case 1:if(0===state.wrap){state.mode=13;break}for(;bits<16;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(2&state.wrap&&35615===hold){state.check=0,hbuf[0]=255&hold,hbuf[1]=hold>>>8&255,state.check=crc32(state.check,hbuf,2,0),hold=0,bits=0,state.mode=2;break}if(state.flags=0,state.head&&(state.head.done=!1),!(1&state.wrap)||(((255&hold)<<8)+(hold>>8))%31){strm.msg=\"incorrect header check\",state.mode=30;break}if((15&hold)!==Z_DEFLATED){strm.msg=\"unknown compression method\",state.mode=30;break}if(hold>>>=4,bits-=4,len=8+(15&hold),0===state.wbits)state.wbits=len;else if(len>state.wbits){strm.msg=\"invalid window size\",state.mode=30;break}state.dmax=1<<state.wbits,strm.adler=state.check=1,state.mode=512&hold?10:12,hold=0,bits=0;break;case 2:for(;bits<16;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(state.flags=hold,(255&state.flags)!==Z_DEFLATED){strm.msg=\"unknown compression method\",state.mode=30;break}if(57344&state.flags){strm.msg=\"unknown header flags set\",state.mode=30;break}state.head&&(state.head.text=hold>>8&1),512&state.flags&&(hbuf[0]=255&hold,hbuf[1]=hold>>>8&255,state.check=crc32(state.check,hbuf,2,0)),hold=0,bits=0,state.mode=3;case 3:for(;bits<32;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}state.head&&(state.head.time=hold),512&state.flags&&(hbuf[0]=255&hold,hbuf[1]=hold>>>8&255,hbuf[2]=hold>>>16&255,hbuf[3]=hold>>>24&255,state.check=crc32(state.check,hbuf,4,0)),hold=0,bits=0,state.mode=4;case 4:for(;bits<16;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}state.head&&(state.head.xflags=255&hold,state.head.os=hold>>8),512&state.flags&&(hbuf[0]=255&hold,hbuf[1]=hold>>>8&255,state.check=crc32(state.check,hbuf,2,0)),hold=0,bits=0,state.mode=5;case 5:if(1024&state.flags){for(;bits<16;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}state.length=hold,state.head&&(state.head.extra_len=hold),512&state.flags&&(hbuf[0]=255&hold,hbuf[1]=hold>>>8&255,state.check=crc32(state.check,hbuf,2,0)),hold=0,bits=0}else state.head&&(state.head.extra=null);state.mode=6;case 6:if(1024&state.flags&&(copy=state.length,copy>have&&(copy=have),copy&&(state.head&&(len=state.head.extra_len-state.length,state.head.extra||(state.head.extra=new Uint8Array(state.head.extra_len)),state.head.extra.set(input.subarray(next,next+copy),len)),512&state.flags&&(state.check=crc32(state.check,input,copy,next)),have-=copy,next+=copy,state.length-=copy),state.length))break inf_leave;state.length=0,state.mode=7;case 7:if(2048&state.flags){if(0===have)break inf_leave;copy=0;do{len=input[next+copy++],state.head&&len&&state.length<65536&&(state.head.name+=String.fromCharCode(len))}while(len&&copy<have);if(512&state.flags&&(state.check=crc32(state.check,input,copy,next)),have-=copy,next+=copy,len)break inf_leave}else state.head&&(state.head.name=null);state.length=0,state.mode=8;case 8:if(4096&state.flags){if(0===have)break inf_leave;copy=0;do{len=input[next+copy++],state.head&&len&&state.length<65536&&(state.head.comment+=String.fromCharCode(len))}while(len&&copy<have);if(512&state.flags&&(state.check=crc32(state.check,input,copy,next)),have-=copy,next+=copy,len)break inf_leave}else state.head&&(state.head.comment=null);state.mode=9;case 9:if(512&state.flags){for(;bits<16;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(hold!==(65535&state.check)){strm.msg=\"header crc mismatch\",state.mode=30;break}hold=0,bits=0}state.head&&(state.head.hcrc=state.flags>>9&1,state.head.done=!0),strm.adler=state.check=0,state.mode=12;break;case 10:for(;bits<32;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}strm.adler=state.check=zswap32(hold),hold=0,bits=0,state.mode=11;case 11:if(0===state.havedict)return strm.next_out=put,strm.avail_out=left,strm.next_in=next,strm.avail_in=have,state.hold=hold,state.bits=bits,Z_NEED_DICT;strm.adler=state.check=1,state.mode=12;case 12:if(flush===Z_BLOCK||flush===Z_TREES)break inf_leave;case 13:if(state.last){hold>>>=7&bits,bits-=7&bits,state.mode=27;break}for(;bits<3;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}switch(state.last=1&hold,hold>>>=1,bits-=1,3&hold){case 0:state.mode=14;break;case 1:if(fixedtables(state),state.mode=20,flush===Z_TREES){hold>>>=2,bits-=2;break inf_leave}break;case 2:state.mode=17;break;case 3:strm.msg=\"invalid block type\",state.mode=30}hold>>>=2,bits-=2;break;case 14:for(hold>>>=7&bits,bits-=7&bits;bits<32;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if((65535&hold)!=(hold>>>16^65535)){strm.msg=\"invalid stored block lengths\",state.mode=30;break}if(state.length=65535&hold,hold=0,bits=0,state.mode=15,flush===Z_TREES)break inf_leave;case 15:state.mode=16;case 16:if(copy=state.length,copy){if(copy>have&&(copy=have),copy>left&&(copy=left),0===copy)break inf_leave;output.set(input.subarray(next,next+copy),put),have-=copy,next+=copy,left-=copy,put+=copy,state.length-=copy;break}state.mode=12;break;case 17:for(;bits<14;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(state.nlen=257+(31&hold),hold>>>=5,bits-=5,state.ndist=1+(31&hold),hold>>>=5,bits-=5,state.ncode=4+(15&hold),hold>>>=4,bits-=4,state.nlen>286||state.ndist>30){strm.msg=\"too many length or distance symbols\",state.mode=30;break}state.have=0,state.mode=18;case 18:for(;state.have<state.ncode;){for(;bits<3;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}state.lens[order[state.have++]]=7&hold,hold>>>=3,bits-=3}for(;state.have<19;)state.lens[order[state.have++]]=0;if(state.lencode=state.lendyn,state.lenbits=7,opts={bits:state.lenbits},ret=inflate_table(0,state.lens,0,19,state.lencode,0,state.work,opts),state.lenbits=opts.bits,ret){strm.msg=\"invalid code lengths set\",state.mode=30;break}state.have=0,state.mode=19;case 19:for(;state.have<state.nlen+state.ndist;){for(;here=state.lencode[hold&(1<<state.lenbits)-1],here_bits=here>>>24,here_op=here>>>16&255,here_val=65535&here,!(here_bits<=bits);){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(here_val<16)hold>>>=here_bits,bits-=here_bits,state.lens[state.have++]=here_val;else{if(16===here_val){for(n=here_bits+2;bits<n;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(hold>>>=here_bits,bits-=here_bits,0===state.have){strm.msg=\"invalid bit length repeat\",state.mode=30;break}len=state.lens[state.have-1],copy=3+(3&hold),hold>>>=2,bits-=2}else if(17===here_val){for(n=here_bits+3;bits<n;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}hold>>>=here_bits,bits-=here_bits,len=0,copy=3+(7&hold),hold>>>=3,bits-=3}else{for(n=here_bits+7;bits<n;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}hold>>>=here_bits,bits-=here_bits,len=0,copy=11+(127&hold),hold>>>=7,bits-=7}if(state.have+copy>state.nlen+state.ndist){strm.msg=\"invalid bit length repeat\",state.mode=30;break}for(;copy--;)state.lens[state.have++]=len}}if(30===state.mode)break;if(0===state.lens[256]){strm.msg=\"invalid code -- missing end-of-block\",state.mode=30;break}if(state.lenbits=9,opts={bits:state.lenbits},ret=inflate_table(1,state.lens,0,state.nlen,state.lencode,0,state.work,opts),state.lenbits=opts.bits,ret){strm.msg=\"invalid literal/lengths set\",state.mode=30;break}if(state.distbits=6,state.distcode=state.distdyn,opts={bits:state.distbits},ret=inflate_table(2,state.lens,state.nlen,state.ndist,state.distcode,0,state.work,opts),state.distbits=opts.bits,ret){strm.msg=\"invalid distances set\",state.mode=30;break}if(state.mode=20,flush===Z_TREES)break inf_leave;case 20:state.mode=21;case 21:if(have>=6&&left>=258){strm.next_out=put,strm.avail_out=left,strm.next_in=next,strm.avail_in=have,state.hold=hold,state.bits=bits,inflate_fast(strm,_out),put=strm.next_out,output=strm.output,left=strm.avail_out,next=strm.next_in,input=strm.input,have=strm.avail_in,hold=state.hold,bits=state.bits,12===state.mode&&(state.back=-1);break}for(state.back=0;here=state.lencode[hold&(1<<state.lenbits)-1],here_bits=here>>>24,here_op=here>>>16&255,here_val=65535&here,!(here_bits<=bits);){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(here_op&&0==(240&here_op)){for(last_bits=here_bits,last_op=here_op,last_val=here_val;here=state.lencode[last_val+((hold&(1<<last_bits+last_op)-1)>>last_bits)],here_bits=here>>>24,here_op=here>>>16&255,here_val=65535&here,!(last_bits+here_bits<=bits);){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}hold>>>=last_bits,bits-=last_bits,state.back+=last_bits}if(hold>>>=here_bits,bits-=here_bits,state.back+=here_bits,state.length=here_val,0===here_op){state.mode=26;break}if(32&here_op){state.back=-1,state.mode=12;break}if(64&here_op){strm.msg=\"invalid literal/length code\",state.mode=30;break}state.extra=15&here_op,state.mode=22;case 22:if(state.extra){for(n=state.extra;bits<n;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}state.length+=hold&(1<<state.extra)-1,hold>>>=state.extra,bits-=state.extra,state.back+=state.extra}state.was=state.length,state.mode=23;case 23:for(;here=state.distcode[hold&(1<<state.distbits)-1],here_bits=here>>>24,here_op=here>>>16&255,here_val=65535&here,!(here_bits<=bits);){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(0==(240&here_op)){for(last_bits=here_bits,last_op=here_op,last_val=here_val;here=state.distcode[last_val+((hold&(1<<last_bits+last_op)-1)>>last_bits)],here_bits=here>>>24,here_op=here>>>16&255,here_val=65535&here,!(last_bits+here_bits<=bits);){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}hold>>>=last_bits,bits-=last_bits,state.back+=last_bits}if(hold>>>=here_bits,bits-=here_bits,state.back+=here_bits,64&here_op){strm.msg=\"invalid distance code\",state.mode=30;break}state.offset=here_val,state.extra=15&here_op,state.mode=24;case 24:if(state.extra){for(n=state.extra;bits<n;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}state.offset+=hold&(1<<state.extra)-1,hold>>>=state.extra,bits-=state.extra,state.back+=state.extra}if(state.offset>state.dmax){strm.msg=\"invalid distance too far back\",state.mode=30;break}state.mode=25;case 25:if(0===left)break inf_leave;if(copy=_out-left,state.offset>copy){if(copy=state.offset-copy,copy>state.whave&&state.sane){strm.msg=\"invalid distance too far back\",state.mode=30;break}copy>state.wnext?(copy-=state.wnext,from=state.wsize-copy):from=state.wnext-copy,copy>state.length&&(copy=state.length),from_source=state.window}else from_source=output,from=put-state.offset,copy=state.length;copy>left&&(copy=left),left-=copy,state.length-=copy;do{output[put++]=from_source[from++]}while(--copy);0===state.length&&(state.mode=21);break;case 26:if(0===left)break inf_leave;output[put++]=state.length,left--,state.mode=21;break;case 27:if(state.wrap){for(;bits<32;){if(0===have)break inf_leave;have--,hold|=input[next++]<<bits,bits+=8}if(_out-=left,strm.total_out+=_out,state.total+=_out,_out&&(strm.adler=state.check=state.flags?crc32(state.check,output,_out,put-_out):adler32(state.check,output,_out,put-_out)),_out=left,(state.flags?hold:zswap32(hold))!==state.check){strm.msg=\"incorrect data check\",state.mode=30;break}hold=0,bits=0}state.mode=28;case 28:if(state.wrap&&state.flags){for(;bits<32;){if(0===have)break inf_leave;have--,hold+=input[next++]<<bits,bits+=8}if(hold!==(4294967295&state.total)){strm.msg=\"incorrect length check\",state.mode=30;break}hold=0,bits=0}state.mode=29;case 29:ret=Z_STREAM_END;break inf_leave;case 30:ret=Z_DATA_ERROR;break inf_leave;case 31:return Z_MEM_ERROR;case 32:default:return Z_STREAM_ERROR}return strm.next_out=put,strm.avail_out=left,strm.next_in=next,strm.avail_in=have,state.hold=hold,state.bits=bits,(state.wsize||_out!==strm.avail_out&&state.mode<30&&(state.mode<27||flush!==Z_FINISH))&&updatewindow(strm,strm.output,strm.next_out,_out-strm.avail_out)?(state.mode=31,Z_MEM_ERROR):(_in-=strm.avail_in,_out-=strm.avail_out,strm.total_in+=_in,strm.total_out+=_out,state.total+=_out,state.wrap&&_out&&(strm.adler=state.check=state.flags?crc32(state.check,output,_out,strm.next_out-_out):adler32(state.check,output,_out,strm.next_out-_out)),strm.data_type=state.bits+(state.last?64:0)+(12===state.mode?128:0)+(20===state.mode||15===state.mode?256:0),(0===_in&&0===_out||flush===Z_FINISH)&&ret===Z_OK&&(ret=Z_BUF_ERROR),ret)},module.exports.inflateEnd=strm=>{if(!strm||!strm.state)return Z_STREAM_ERROR;let state=strm.state;return state.window&&(state.window=null),strm.state=null,Z_OK},module.exports.inflateGetHeader=(strm,head)=>{if(!strm||!strm.state)return Z_STREAM_ERROR;const state=strm.state;return 0==(2&state.wrap)?Z_STREAM_ERROR:(state.head=head,head.done=!1,Z_OK)},module.exports.inflateSetDictionary=(strm,dictionary)=>{const dictLength=dictionary.length;let state,dictid,ret;return strm&&strm.state?(state=strm.state,0!==state.wrap&&11!==state.mode?Z_STREAM_ERROR:11===state.mode&&(dictid=1,dictid=adler32(dictid,dictionary,dictLength,0),dictid!==state.check)?Z_DATA_ERROR:(ret=updatewindow(strm,dictionary,dictLength,dictLength),ret?(state.mode=31,Z_MEM_ERROR):(state.havedict=1,Z_OK))):Z_STREAM_ERROR},module.exports.inflateInfo=\"pako inflate (from Nodeca project)\"},241:module=>{\"use strict\";const lbase=new Uint16Array([3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,0,0]),lext=new Uint8Array([16,16,16,16,16,16,16,16,17,17,17,17,18,18,18,18,19,19,19,19,20,20,20,20,21,21,21,21,16,72,78]),dbase=new Uint16Array([1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577,0,0]),dext=new Uint8Array([16,16,16,16,17,17,18,18,19,19,20,20,21,21,22,22,23,23,24,24,25,25,26,26,27,27,28,28,29,29,64,64]);module.exports=(type,lens,lens_index,codes,table,table_index,work,opts)=>{const bits=opts.bits;let incr,fill,low,mask,next,end,len=0,sym=0,min=0,max=0,root=0,curr=0,drop=0,left=0,used=0,huff=0,base=null,base_index=0;const count=new Uint16Array(16),offs=new Uint16Array(16);let here_bits,here_op,here_val,extra=null,extra_index=0;for(len=0;len<=15;len++)count[len]=0;for(sym=0;sym<codes;sym++)count[lens[lens_index+sym]]++;for(root=bits,max=15;max>=1&&0===count[max];max--);if(root>max&&(root=max),0===max)return table[table_index++]=20971520,table[table_index++]=20971520,opts.bits=1,0;for(min=1;min<max&&0===count[min];min++);for(root<min&&(root=min),left=1,len=1;len<=15;len++)if(left<<=1,left-=count[len],left<0)return-1;if(left>0&&(0===type||1!==max))return-1;for(offs[1]=0,len=1;len<15;len++)offs[len+1]=offs[len]+count[len];for(sym=0;sym<codes;sym++)0!==lens[lens_index+sym]&&(work[offs[lens[lens_index+sym]]++]=sym);if(0===type?(base=extra=work,end=19):1===type?(base=lbase,base_index-=257,extra=lext,extra_index-=257,end=256):(base=dbase,extra=dext,end=-1),huff=0,sym=0,len=min,next=table_index,curr=root,drop=0,low=-1,used=1<<root,mask=used-1,1===type&&used>852||2===type&&used>592)return 1;for(;;){here_bits=len-drop,work[sym]<end?(here_op=0,here_val=work[sym]):work[sym]>end?(here_op=extra[extra_index+work[sym]],here_val=base[base_index+work[sym]]):(here_op=96,here_val=0),incr=1<<len-drop,fill=1<<curr,min=fill;do{fill-=incr,table[next+(huff>>drop)+fill]=here_bits<<24|here_op<<16|here_val|0}while(0!==fill);for(incr=1<<len-1;huff&incr;)incr>>=1;if(0!==incr?(huff&=incr-1,huff+=incr):huff=0,sym++,0==--count[len]){if(len===max)break;len=lens[lens_index+work[sym]]}if(len>root&&(huff&mask)!==low){for(0===drop&&(drop=root),next+=min,curr=len-drop,left=1<<curr;curr+drop<max&&(left-=count[curr+drop],!(left<=0));)curr++,left<<=1;if(used+=1<<curr,1===type&&used>852||2===type&&used>592)return 1;low=huff&mask,table[low]=root<<24|curr<<16|next-table_index|0}}return 0!==huff&&(table[next+huff]=len-drop<<24|64<<16|0),opts.bits=root,0}},898:module=>{\"use strict\";module.exports={2:\"need dictionary\",1:\"stream end\",0:\"\",\"-1\":\"file error\",\"-2\":\"stream error\",\"-3\":\"data error\",\"-4\":\"insufficient memory\",\"-5\":\"buffer error\",\"-6\":\"incompatible version\"}},292:module=>{\"use strict\";module.exports=function ZStream(){this.input=null,this.next_in=0,this.avail_in=0,this.total_in=0,this.output=null,this.next_out=0,this.avail_out=0,this.total_out=0,this.msg=\"\",this.state=null,this.data_type=2,this.adler=0}},330:(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{\"use strict\";__webpack_require__.d(__webpack_exports__,{default:()=>__WEBPACK_DEFAULT_EXPORT__});var numpy_parser__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__(829),ndarray__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__(861),pako_lib_inflate__WEBPACK_IMPORTED_MODULE_2__=__webpack_require__(843);const __WEBPACK_DEFAULT_EXPORT__=loader={unpack_obj:function unpack_obj(obj){if(Array.isArray(obj)){var ret=[];for(var v of obj)ret.push(unpack_obj(v));return ret}if(obj instanceof Object){if(obj.hasOwnProperty(\"__type__\"))return function unpack_custom_data(obj){if(\"npy\"==obj.__type__){var uint8arr;if(window.obj=obj,obj.hasOwnProperty(\"zdata\")){const compressed=Uint8Array.from(window.atob(obj.zdata),(c=>c.charCodeAt(0)));uint8arr=(0,pako_lib_inflate__WEBPACK_IMPORTED_MODULE_2__.rr)(compressed)}else uint8arr=Uint8Array.from(window.atob(obj.data),(c=>c.charCodeAt(0)));var arr=(0,numpy_parser__WEBPACK_IMPORTED_MODULE_0__.g)(uint8arr.buffer);if(arr=ndarray__WEBPACK_IMPORTED_MODULE_1__(arr.data,arr.shape),obj.hasOwnProperty(\"min\")){let scale=\"uint8\"===arr.dtype?255:65535;for(var size=1,i=0;i<arr.shape.length;i++)size*=arr.shape[i];var arr_=ndarray__WEBPACK_IMPORTED_MODULE_1__(new Float32Array(size),arr.shape);for(i=0;i<arr.data.length;i++)arr_.data[i]=obj.min+(obj.max-obj.min)*arr.data[i]/scale;return arr_}return arr}return{}}(obj);ret={};for(var k of Object.keys(obj))ret[k]=unpack_obj(obj[k]);return ret}return obj}}}},__webpack_module_cache__={};function __webpack_require__(moduleId){if(__webpack_module_cache__[moduleId])return __webpack_module_cache__[moduleId].exports;var module=__webpack_module_cache__[moduleId]={exports:{}};return __webpack_modules__[moduleId](module,module.exports,__webpack_require__),module.exports}return __webpack_require__.n=module=>{var getter=module&&module.__esModule?()=>module.default:()=>module;return __webpack_require__.d(getter,{a:getter}),getter},__webpack_require__.d=(exports,definition)=>{for(var key in definition)__webpack_require__.o(definition,key)&&!__webpack_require__.o(exports,key)&&Object.defineProperty(exports,key,{enumerable:!0,get:definition[key]})},__webpack_require__.o=(obj,prop)=>Object.prototype.hasOwnProperty.call(obj,prop),__webpack_require__(330)})().default;</script>\n",
              "        \n",
              "        <div id=\"AttentionMulti_3ea3db3\"></div>\n",
              "        <script>\n",
              "        ( () => {\n",
              "            var data = {\n",
              "\"tokens\": [\n",
              "\"<|endoftext|>\",\n",
              "\"I\",\n",
              "\" am\",\n",
              "\" an\",\n",
              "\" amazing\",\n",
              "\" aut\",\n",
              "\"ore\",\n",
              "\"gressive\",\n",
              "\",\",\n",
              "\" dec\",\n",
              "\"oder\",\n",
              "\"-\",\n",
              "\"only\",\n",
              "\",\",\n",
              "\" G\",\n",
              "\"PT\",\n",
              "\"-\",\n",
              "\"2\",\n",
              "\" style\",\n",
              "\" transformer\",\n",
              "\".\",\n",
              "\" One\",\n",
              "\" day\",\n",
              "\" I\",\n",
              "\" will\",\n",
              "\" exceed\",\n",
              "\" human\",\n",
              "\" level\",\n",
              "\" intelligence\",\n",
              "\" and\",\n",
              "\" take\",\n",
              "\" over\",\n",
              "\" the\",\n",
              "\" world\",\n",
              "\"!\"\n",
              "],\n",
              "\"attention\": {\n",
              "\"__type__\": \"npy\",\n",
              "\"zdata\": \"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\",\n",
              "\"min\": 0.0,\n",
              "\"max\": 1.0\n",
              "}\n",
              "};\n",
              "            data = loader.unpack_obj(data);\n",
              "            window.AttentionMulti_data = data;\n",
              "            var AttentionMulti_inst = new AttentionMulti({\n",
              "                \"target\": document.getElementById(\"AttentionMulti_3ea3db3\"),\n",
              "                \"props\": data\n",
              "                });\n",
              "        })();\n",
              "        </script>\n",
              "        \n",
              "        "
            ],
            "text/plain": [
              "<pysvelte.html.Html at 0x7f9503f29a90>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pysvelte\n",
        "# Affiche la visualisation de l'attention multi-heads avec les tokens et les données d'attention\n",
        "pysvelte.AttentionMulti(tokens=reference_gpt2.to_str_tokens(reference_text), attention=cache['blocks.0.attn.hook_attn'][0].permute(1, 2, 0)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDvroI1A56LB",
        "outputId": "186dcf72-72c4-454a-a049-7e231632f8ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 7.9663e-01,  1.6986e-02,  3.4781e-02,  ...,  3.3120e-02,\n",
              "          -2.3129e-02,  1.8103e-01],\n",
              "         [ 1.3167e-03,  1.5750e-01, -1.4059e-01,  ..., -8.1997e-03,\n",
              "           5.3076e-03,  1.3511e-01],\n",
              "         [ 8.9738e-02, -7.2411e-01, -6.9866e-01,  ...,  5.5321e-02,\n",
              "           2.7959e-03,  9.0785e-02],\n",
              "         ...,\n",
              "         [-3.0286e-01,  4.9638e-02, -6.0990e-01,  ..., -3.7084e-02,\n",
              "          -4.9522e-04, -8.6008e-03],\n",
              "         [-1.0844e+00, -6.1457e-02,  2.2966e-01,  ..., -2.6688e-02,\n",
              "          -1.4368e-02,  3.3245e-02],\n",
              "         [ 3.7947e-01, -4.9886e-01,  2.6434e-01,  ..., -2.7894e-02,\n",
              "          -8.9028e-03,  4.8796e-02]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # Initialisation des paramètres de la couche d'attention\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "        # Initialisation du masque ignore\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32, device=\"cuda\"))\n",
        "\n",
        "    def forward(self, normalized_resid_pre):\n",
        "        # normalized_resid_pre: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_pre:\", normalized_resid_pre.shape)\n",
        "\n",
        "        # Calcul des requêtes, clés et valeurs\n",
        "        q = einsum(\"batch query_pos d_model, n_heads d_model d_head -> batch query_pos n_heads d_head\", normalized_resid_pre, self.W_Q) + self.b_Q\n",
        "        k = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\", normalized_resid_pre, self.W_K) + self.b_K\n",
        "\n",
        "        # Calcul des scores d'attention et application du masque causal\n",
        "        attn_scores = einsum(\"batch query_pos n_heads d_head, batch key_pos n_heads d_head -> batch n_heads query_pos key_pos\", q, k)\n",
        "        attn_scores = attn_scores / math.sqrt(self.cfg.d_head)\n",
        "        attn_scores = self.apply_causal_mask(attn_scores)\n",
        "\n",
        "        # Calcul de l'attention pondérée et sortie de l'attention\n",
        "        pattern = attn_scores.softmax(dim=-1) # [batch, n_head, query_pos, key_pos]\n",
        "        v = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\", normalized_resid_pre, self.W_V) + self.b_V\n",
        "        z = einsum(\"batch n_heads query_pos key_pos, batch key_pos n_heads d_head -> batch query_pos n_heads d_head\", pattern, v)\n",
        "        attn_out = einsum(\"batch query_pos n_heads d_head, n_heads d_head d_model -> batch query_pos d_model\", z, self.W_O) + self.b_O\n",
        "        return attn_out\n",
        "\n",
        "    def apply_causal_mask(self, attn_scores):\n",
        "        # Applique un masque causal aux scores d'attention\n",
        "        mask = torch.triu(torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device), diagonal=1).bool()\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmX5OkcB56LC"
      },
      "source": [
        "## MLP (Multilayer Perceptron)\n",
        "Généralisation: Une fois entraîné sur un ensemble de données, le MLP peut généraliser ses connaissances pour faire des prédictions précises sur de nouvelles données qui n'ont pas été vues pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv2xTXu756LC",
        "outputId": "d1ff70fb-fd8d-4cad-f1c6-76a1784b0784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.4380,  0.3624,  0.5117,  ...,  1.7227,  1.5761,  0.0368],\n",
              "         [-1.0766, -0.0438,  0.3276,  ..., -0.5437,  0.4033,  0.3717],\n",
              "         [-1.2182, -1.5481, -0.9702,  ...,  1.0737,  0.7199,  0.5080],\n",
              "         ...,\n",
              "         [-0.4004,  0.8475,  0.2047,  ...,  0.3789,  0.0455, -0.4744],\n",
              "         [-0.0862,  0.7839,  0.9046,  ..., -0.2175, -0.5953,  0.8555],\n",
              "         [ 0.8448, -0.3743,  1.0397,  ...,  0.0296,  0.3405,  0.3585]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # Initialisation des paramètres du MLP\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "    def forward(self, normalized_resid_mid):\n",
        "        # normalized_resid_mid: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_mid:\", normalized_resid_mid.shape)\n",
        "\n",
        "        # Calcul de la couche MLP\n",
        "        pre = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", normalized_resid_mid, self.W_in) + self.b_in\n",
        "        post = gelu_new(pre)\n",
        "        mlp_out = einsum(\"batch position d_mlp, d_mlp d_model -> batch position d_model\", post, self.W_out) + self.b_out\n",
        "        return mlp_out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly6uR0Qb56LC"
      },
      "source": [
        "## Transformer Block\n",
        "Voici le bloc de transformation dans un réseau de neurones Transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiQD4dHB56LC",
        "outputId": "eb20467e-262e-453b-b350-9367854cd43a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.3911,  0.1543,  0.6005,  ...,  1.7198,  1.7365,  0.3930],\n",
              "         [-0.9039, -0.0360,  0.2351,  ..., -0.4148,  0.3562,  0.3936],\n",
              "         [-0.9647, -2.4819, -1.4995,  ...,  1.4046,  0.7616,  0.5918],\n",
              "         ...,\n",
              "         [-0.7421,  0.9251, -0.3218,  ...,  0.2921,  0.1097, -0.5344],\n",
              "         [-1.3221,  0.8960,  1.1795,  ..., -0.5544, -0.4071,  0.9255],\n",
              "         [ 1.1209, -0.8919,  1.3737,  ..., -0.1356,  0.3434,  0.4517]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # Initialisation des couches du bloc Transformer\n",
        "        self.cfg = cfg\n",
        "\n",
        "        # Couche de normalisation 1\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        # Couche d'attention\n",
        "        self.attn = Attention(cfg)\n",
        "        # Couche de normalisation 2\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        # Couche MLP\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(self, resid_pre):\n",
        "        # resid_pre [batch, position, d_model]\n",
        "\n",
        "        # Normalisation de la résiduelle avant l'attention\n",
        "        normalized_resid_pre = self.ln1(resid_pre)\n",
        "        # Calcul de la sortie de l'attention\n",
        "        attn_out = self.attn(normalized_resid_pre)\n",
        "        # Ajout de la sortie de l'attention à la résiduelle avant\n",
        "        resid_mid = resid_pre + attn_out\n",
        "\n",
        "        # Normalisation de la résiduelle après l'attention\n",
        "        normalized_resid_mid = self.ln2(resid_mid)\n",
        "        # Calcul de la sortie du MLP\n",
        "        mlp_out = self.mlp(normalized_resid_mid)\n",
        "        # Ajout de la sortie du MLP à la résiduelle après\n",
        "        resid_post = resid_mid + mlp_out\n",
        "\n",
        "        return resid_post\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rliRVlCC56LC"
      },
      "source": [
        "## Unembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAxdhbVn56LD",
        "outputId": "7e1b571d-949a-4f00-f506-32a39de7dd29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_final: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ -43.4317,  -39.8364,  -43.0660,  ...,  -54.0878,  -54.3452,\n",
              "           -42.3645],\n",
              "         [-128.0392, -127.9936, -130.7010,  ..., -136.7121, -129.9261,\n",
              "          -129.3965],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6027,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9815, -112.7749, -117.0633,  ..., -121.2914, -117.6574,\n",
              "          -114.5005],\n",
              "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
              "          -106.3604],\n",
              "         [-126.8285, -128.9596, -128.3941,  ..., -140.1970, -138.5883,\n",
              "          -122.3697]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # Initialisation des paramètres pour l'unembedding\n",
        "        self.cfg = cfg\n",
        "        # Matrice de poids pour l'unembedding\n",
        "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        # Initialisation des poids avec une distribution normale\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        # Biais pour l'unembedding (sans nécessité de calcul de gradient)\n",
        "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(self, normalized_resid_final):\n",
        "        # normalized_resid_final [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_final:\", normalized_resid_final.shape)\n",
        "        # Calcul des logits pour l'unembedding\n",
        "        logits = einsum(\"batch position d_model, d_model d_vocab -> batch position d_vocab\", normalized_resid_final, self.W_U) + self.b_U\n",
        "        return logits\n",
        "rand_float_test(Unembed, [2, 4, 768])\n",
        "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCBWNis456LD"
      },
      "source": [
        "## Full Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ld8_vGt56LD",
        "outputId": "e64cf323-d52c-4ace-adbd-c95aec66a3e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "Embeddings: torch.Size([2, 4, 768])\n",
            "Tokens: torch.Size([2, 4])\n",
            "pos_embed: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Tokens: torch.Size([1, 35])\n",
            "Embeddings: torch.Size([1, 35, 768])\n",
            "Tokens: torch.Size([1, 35])\n",
            "pos_embed: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_final: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ -43.4317,  -39.8364,  -43.0660,  ...,  -54.0878,  -54.3452,\n",
              "           -42.3645],\n",
              "         [-128.0392, -127.9936, -130.7010,  ..., -136.7121, -129.9261,\n",
              "          -129.3965],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6027,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9815, -112.7749, -117.0633,  ..., -121.2914, -117.6574,\n",
              "          -114.5005],\n",
              "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
              "          -106.3604],\n",
              "         [-126.8285, -128.9596, -128.3941,  ..., -140.1970, -138.5883,\n",
              "          -122.3697]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # Configuration du modèle\n",
        "        self.cfg = cfg\n",
        "        # Initialisation des modules nécessaires\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens [batch, position]\n",
        "        # Embedding des tokens\n",
        "        embed = self.embed(tokens)\n",
        "        # Ajout de l'embedding de position\n",
        "        pos_embed = self.pos_embed(tokens)\n",
        "        residual = embed + pos_embed\n",
        "        # Application des blocs du transformer\n",
        "        for block in self.blocks:\n",
        "            residual = block(residual)\n",
        "        # Normalisation de la résiduelle finale\n",
        "        normalized_resid_final = self.ln_final(residual)\n",
        "        # Décodage des logits avec l'unembedding\n",
        "        logits = self.unembed(normalized_resid_final)\n",
        "        # logits ont une forme [batch, position, logits]\n",
        "        return logits\n",
        "\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjObcAJR56LD"
      },
      "source": [
        "#Essayer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogltd-qF56LD",
        "outputId": "558d327f-5eef-4f64-b14d-c71f5e8b9789"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instancier le modèle DemoTransformer avec debug=False\n",
        "demo_gpt2 = DemoTransformer(Config(debug=False))\n",
        "# Charger le dictionnaire d'état du modèle GPT-2 de référence sans strict\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "# Déplacer le modèle sur GPU\n",
        "demo_gpt2.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpnxQtgU56LD"
      },
      "source": [
        "\n",
        "Prenons une chaîne de test - le paragraphe d'introduction de l'article vedette de Wikipédia aujourd'hui. Calculons la perte !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcfGNYrm56LE"
      },
      "outputs": [],
      "source": [
        "test_string = \"\"\"Mini scule is a species of microhylid frog endemic to Madagascar that was described in 2019. The scientific name of the species refers to its size, being a pun on the word minuscule. It is very small, measuring only 8.4 to 10.8 mm (0.33 to 0.43 in) in snout–vent length. It has bronze underparts with a brown groin and back of the thigh, cream upperparts with brown flecking, a dark brown side of the head, and a red iris. On the hind feet, the first toe is absent and the second and fifth toes are strongly reduced. The frog is known only from the Sainte Luce Reserve, where it inhabits areas with deep leaf litter near semi-permanent water bodies. Specimens of frogs from Mandena, the Vohimena mountains, the southern Anosy Mountains, and Tsitongambarika may also be of this species. Along with Mini mum and Mini ature, the other two species in its genus, it received media attention when first described due to the wordplay in its scientific name. (Full article...)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4a_cP1d56LE"
      },
      "outputs": [],
      "source": [
        "# Convertir la chaîne de test en tokens et les déplacer sur GPU\n",
        "test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "# Obtenir les logits du modèle DemoTransformer pour les tokens de test\n",
        "demo_logits = demo_gpt2(test_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_JfLNbX56LE",
        "outputId": "aaf1bae2-667e-4717-8789-48374c1f2645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.7186, device='cuda:0', grad_fn=<NegBackward0>)\n",
            "Loss as average prob tensor(0.0243, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss as 'uniform over this many variables' tensor(41.2079, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Uniform loss over the vocab 10.82490511970208\n"
          ]
        }
      ],
      "source": [
        "def lm_cross_entropy_loss(logits, tokens):\n",
        "    # Mesurer la perte du token suivant\n",
        "    # Les logits ont une forme [batch, position, d_vocab]\n",
        "    # Les tokens ont une forme [batch, position]\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    pred_log_probs = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
        "    return -pred_log_probs.mean()\n",
        "\n",
        "# Calculer la perte de la cross-entropy pour les logits de démonstration et les tokens de test\n",
        "loss = lm_cross_entropy_loss(demo_logits, test_tokens)\n",
        "print(loss)\n",
        "print(\"Loss as average prob \", (-loss).exp())\n",
        "print(\"Loss as 'uniform over this many variables'\", (loss).exp())\n",
        "print(\"Uniform loss over the vocab\", math.log(demo_gpt2.cfg.d_vocab))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YlgZBe556LE"
      },
      "source": [
        "Nous pouvons également générer du texte de manière cupide :\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU_HltrN56LE",
        "outputId": "66cc09c6-251d-417d-f45d-12c62c50e19e",
        "colab": {
          "referenced_widgets": [
            "9138cee7c11e44b9abc13edbdc2543ea"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9138cee7c11e44b9abc13edbdc2543ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the\n"
          ]
        }
      ],
      "source": [
        "# Initialisation de la chaîne de texte avec une actualité\n",
        "test_string = \"Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on\"\n",
        "\n",
        "# Boucle pour générer la suite du texte\n",
        "for i in tqdm.tqdm(range(100)):\n",
        "    # Conversion de la chaîne en tokens et envoi sur GPU\n",
        "    test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "    # Génération de logits pour la suite du texte\n",
        "    demo_logits = demo_gpt2(test_tokens)\n",
        "    # Décodage et ajout du token prédit à la chaîne de texte\n",
        "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
        "\n",
        "# Impression du texte final généré\n",
        "print(test_string)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4GZoxgz56LE"
      },
      "source": [
        "# Entraînement d'un modèle !\n",
        "\n",
        "Il s'agit d'une démonstration légère de la façon dont vous pouvez réellement entraîner votre propre GPT-2 avec ce code ! Ici, nous entraînons un petit modèle sur un petit ensemble de données, mais c'est fondamentalement le même code pour entraîner un modèle plus grand ou plus réel (bien que vous ayez besoin de GPU plus puissants et de parallélisme de données pour le faire de manière relativement efficace, et d'un parallélisme plus sophistiqué pour des modèles beaucoup plus grands)..\n",
        "\n",
        "Pour nos besoins, nous allons entraîner un modèle de 2 couches avec 4 têtes par couche, avec une longueur de contexte de 256, pendant 1000 étapes avec une taille de lot de 32, juste pour montrer à quoi cela ressemble (et pour que le notebook ne fasse pas fondre votre colab lol)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcZjfC1K56LE"
      },
      "outputs": [],
      "source": [
        "# Vérification si l'environnement est Google Colab\n",
        "if IN_COLAB:\n",
        "    # Installation des bibliothèques datasets et transformers\n",
        "    %pip install datasets\n",
        "    %pip install transformers\n",
        "\n",
        "# Import des bibliothèques nécessaires\n",
        "import datasets\n",
        "import transformers\n",
        "import plotly.express as px\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAsJE2NU56LF"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkK1dt9d56LF"
      },
      "outputs": [],
      "source": [
        "# Définition des paramètres d'entraînement\n",
        "batch_size = 32  # Taille du lot\n",
        "num_epochs = 10  # Nombre d'époques\n",
        "max_steps = 1000  # Nombre maximum d'étapes\n",
        "log_every = 10  # Fréquence de journalisation\n",
        "lr = 1e-3  # Taux d'apprentissage\n",
        "weight_decay = 1e-2  # Facteur de régularisation\n",
        "\n",
        "# Configuration du modèle\n",
        "model_cfg = Config(\n",
        "    debug=False,            # Mode de débogage\n",
        "    d_model=256,            # Dimension du modèle\n",
        "    n_heads=4,              # Nombre de têtes d'attention\n",
        "    d_head=64,              # Dimension des têtes d'attention\n",
        "    d_mlp=1024,             # Dimension de la couche cachée\n",
        "    n_layers=2,             # Nombre de couches\n",
        "    n_ctx=256,              # Contexte maximum\n",
        "    d_vocab=reference_gpt2.cfg.d_vocab  # Dimension du vocabulaire\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dWSQhp956LF"
      },
      "source": [
        "\n",
        "## Créer des données\n",
        "\n",
        "Nous chargeons un petit ensemble de données que j'ai créé, avec les 10 000 premières entrées dans le Pile (inspiré par la version de Stas pour OpenWebText !)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf1Pikxj56LF",
        "outputId": "33b6550c-f0f7-4506-f11a-0ca3966e20ad",
        "colab": {
          "referenced_widgets": [
            "82a537e82cad4e9e8e10670f4fd26589",
            "1459556a636548c3a26b3c38c4643a81",
            "74e7f51ec91041be8a153686c8413cb6",
            "589f6c90d6b44d0c957f9553d43e3e04"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration NeelNanda--pile-10k-30e9c14cdcda6c5c\n",
            "Found cached dataset parquet (/workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'meta'],\n",
            "    num_rows: 10000\n",
            "})\n",
            "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playi\n",
            "     "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82a537e82cad4e9e8e10670f4fd26589",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "#0:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1459556a636548c3a26b3c38c4643a81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "#1:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74e7f51ec91041be8a153686c8413cb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "#2:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "589f6c90d6b44d0c957f9553d43e3e04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "#3:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (80023 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (101051 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (155995 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (229134 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "# Chargement du jeu de données à partir du dataset Pile-10k\n",
        "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\")\n",
        "print(dataset)  # Affichage du dataset\n",
        "print(dataset[0]['text'][:100])  # Affichage des premiers 100 caractères du texte du premier exemple\n",
        "\n",
        "# Tokenisation et concaténation des données\n",
        "tokens_dataset = tokenize_and_concatenate(dataset, reference_gpt2.tokenizer, streaming=False, max_length=model_cfg.n_ctx, column_name=\"text\", add_bos_token=True, num_proc=4)\n",
        "\n",
        "# Création d'un DataLoader pour charger les données en batches\n",
        "data_loader = torch.utils.data.DataLoader(tokens_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "57Mp64G3EYSP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eavz_Ghj56LF"
      },
      "source": [
        "## Créer le Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLiKHjVb56LF",
        "outputId": "aa208c97-7784-478c-a5c2-e21ef45fca01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Création d'une instance du modèle DemoTransformer avec la configuration spécifiée\n",
        "model = DemoTransformer(model_cfg)\n",
        "# Transfert du modèle sur le GPU pour accélérer le traitement\n",
        "model.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Da9bS8_56LF"
      },
      "source": [
        "## Creer l'Optimizer\n",
        "Nous utilisons AdamW - c'est un optimiseur assez standard.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Riyhzxnn56LF"
      },
      "outputs": [],
      "source": [
        "# Définition de l'optimiseur AdamW pour entraîner le modèle\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY_L-gb-56LG"
      },
      "source": [
        "## Exécuter la boucle d'entraînement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOdfpwaY56LG",
        "outputId": "10c58fe3-e74a-4e8d-8e2b-194ae5d407b6",
        "colab": {
          "referenced_widgets": [
            "7725a91ac6684e2bb022fdc02d5eec12"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches: 8506\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7725a91ac6684e2bb022fdc02d5eec12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 0, Loss: 10.8938\n",
            "Step: 10, Loss: 8.6160\n",
            "Step: 20, Loss: 7.4170\n",
            "Step: 30, Loss: 7.4342\n",
            "Step: 40, Loss: 7.1660\n",
            "Step: 50, Loss: 5.9145\n",
            "Step: 60, Loss: 7.3014\n",
            "Step: 70, Loss: 7.7666\n",
            "Step: 80, Loss: 7.5511\n",
            "Step: 90, Loss: 6.2643\n",
            "Step: 100, Loss: 7.1839\n",
            "Step: 110, Loss: 5.3938\n",
            "Step: 120, Loss: 7.3348\n",
            "Step: 130, Loss: 5.9235\n",
            "Step: 140, Loss: 6.0241\n",
            "Step: 150, Loss: 6.5177\n",
            "Step: 160, Loss: 7.0355\n",
            "Step: 170, Loss: 6.0351\n",
            "Step: 180, Loss: 6.7511\n",
            "Step: 190, Loss: 5.9056\n",
            "Step: 200, Loss: 6.2145\n",
            "Step: 210, Loss: 5.7370\n",
            "Step: 220, Loss: 6.9411\n",
            "Step: 230, Loss: 6.4263\n",
            "Step: 240, Loss: 6.4935\n",
            "Step: 250, Loss: 6.3181\n",
            "Step: 260, Loss: 6.4933\n",
            "Step: 270, Loss: 5.8911\n",
            "Step: 280, Loss: 6.8380\n",
            "Step: 290, Loss: 7.1255\n",
            "Step: 300, Loss: 6.5911\n",
            "Step: 310, Loss: 5.8859\n",
            "Step: 320, Loss: 6.9126\n",
            "Step: 330, Loss: 6.5967\n",
            "Step: 340, Loss: 6.7064\n",
            "Step: 350, Loss: 6.1962\n",
            "Step: 360, Loss: 5.7562\n",
            "Step: 370, Loss: 5.9538\n",
            "Step: 380, Loss: 6.9621\n",
            "Step: 390, Loss: 7.1926\n",
            "Step: 400, Loss: 6.2406\n",
            "Step: 410, Loss: 6.8793\n",
            "Step: 420, Loss: 6.7920\n",
            "Step: 430, Loss: 5.6676\n",
            "Step: 440, Loss: 6.4836\n",
            "Step: 450, Loss: 5.8379\n",
            "Step: 460, Loss: 5.0805\n",
            "Step: 470, Loss: 5.3195\n",
            "Step: 480, Loss: 5.8577\n",
            "Step: 490, Loss: 6.0510\n",
            "Step: 500, Loss: 5.3045\n",
            "Step: 510, Loss: 5.6220\n",
            "Step: 520, Loss: 5.6595\n",
            "Step: 530, Loss: 5.1026\n",
            "Step: 540, Loss: 6.2747\n",
            "Step: 550, Loss: 6.5637\n",
            "Step: 560, Loss: 5.9919\n",
            "Step: 570, Loss: 4.4590\n",
            "Step: 580, Loss: 5.7116\n",
            "Step: 590, Loss: 6.4498\n",
            "Step: 600, Loss: 6.2833\n",
            "Step: 610, Loss: 6.0663\n",
            "Step: 620, Loss: 6.1303\n",
            "Step: 630, Loss: 6.0391\n",
            "Step: 640, Loss: 5.9534\n",
            "Step: 650, Loss: 5.8069\n",
            "Step: 660, Loss: 5.7637\n",
            "Step: 670, Loss: 6.2510\n",
            "Step: 680, Loss: 6.7757\n",
            "Step: 690, Loss: 5.8833\n",
            "Step: 700, Loss: 5.6237\n",
            "Step: 710, Loss: 5.9463\n",
            "Step: 720, Loss: 5.9818\n",
            "Step: 730, Loss: 3.7111\n",
            "Step: 740, Loss: 6.2097\n",
            "Step: 750, Loss: 6.3188\n",
            "Step: 760, Loss: 5.4198\n",
            "Step: 770, Loss: 3.9056\n",
            "Step: 780, Loss: 5.8297\n",
            "Step: 790, Loss: 6.2319\n",
            "Step: 800, Loss: 5.4723\n",
            "Step: 810, Loss: 5.5568\n",
            "Step: 820, Loss: 6.2107\n",
            "Step: 830, Loss: 6.5033\n",
            "Step: 840, Loss: 5.5697\n",
            "Step: 850, Loss: 5.6075\n",
            "Step: 860, Loss: 5.4451\n",
            "Step: 870, Loss: 6.1277\n",
            "Step: 880, Loss: 6.1290\n",
            "Step: 890, Loss: 5.2920\n",
            "Step: 900, Loss: 3.9140\n",
            "Step: 910, Loss: 6.3699\n",
            "Step: 920, Loss: 4.8495\n",
            "Step: 930, Loss: 5.8845\n",
            "Step: 940, Loss: 3.8847\n",
            "Step: 950, Loss: 6.1746\n",
            "Step: 960, Loss: 6.6594\n",
            "Step: 970, Loss: 4.5531\n",
            "Step: 980, Loss: 5.2382\n",
            "Step: 990, Loss: 6.6860\n",
            "Step: 1000, Loss: 5.7797\n"
          ]
        }
      ],
      "source": [
        "# Liste pour stocker les valeurs de perte\n",
        "# Liste pour stocker les valeurs de perte\n",
        "losses = []\n",
        "\n",
        "# Affichage du nombre de lots de données\n",
        "print(\"Nombre de lots de données:\", len(data_loader))\n",
        "\n",
        "# Boucle sur le nombre d'époques\n",
        "for epoch in range(num_epochs):\n",
        "    # Boucle sur les lots de données\n",
        "    for c, batch in tqdm.tqdm(enumerate(data_loader)):\n",
        "        tokens = batch['tokens'].cuda()  # Transférer les tokens sur GPU\n",
        "        logits = model(tokens)  # Obtenir les prédictions du modèle\n",
        "        loss = lm_cross_entropy_loss(logits, tokens)  # Calcul de la perte\n",
        "        loss.backward()  # Calcul du gradient\n",
        "        optimizer.step()  # Mise à jour des poids du modèle\n",
        "        optimizer.zero_grad()  # Réinitialisation du gradient\n",
        "        losses.append(loss.item())  # Ajout de la perte à la liste\n",
        "        # Affichage de la perte à intervalles réguliers\n",
        "        if c % log_every == 0:\n",
        "            print(f\"Étape: {c}, Perte: {loss.item():.4f}\")\n",
        "        # Sortir de la boucle si le nombre maximum d'étapes est atteint\n",
        "        if c > max_steps:\n",
        "            break\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqtzVPTz56LG"
      },
      "source": [
        "Maintenant, nous pouvons tracer une courbe de loss curve !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP3AKiEb0DJ8",
        "outputId": "9e2d0904-6ecd-41f7-fa53-fd1e20133e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"fe6d38d1-f141-46a1-a9d6-2c7063fbd468\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fe6d38d1-f141-46a1-a9d6-2c7063fbd468\")) {                    Plotly.newPlot(                        \"fe6d38d1-f141-46a1-a9d6-2c7063fbd468\",                        [{\"hovertemplate\":\"Tokens=%{x}\\u003cbr\\u003eLoss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[0,2048,4096,6144,8192,10240,12288,14336,16384,18432,20480,22528,24576,26624,28672,30720,32768,34816,36864,38912,40960,43008,45056,47104,49152,51200,53248,55296,57344,59392,61440,63488,65536,67584,69632,71680,73728,75776,77824,79872,81920,83968,86016,88064,90112,92160,94208,96256,98304,100352,102400,104448,106496,108544,110592,112640,114688,116736,118784,120832,122880,124928,126976,129024,131072,133120,135168,137216,139264,141312,143360,145408,147456,149504,151552,153600,155648,157696,159744,161792,163840,165888,167936,169984,172032,174080,176128,178176,180224,182272,184320,186368,188416,190464,192512,194560,196608,198656,200704,202752,204800,206848,208896,210944,212992,215040,217088,219136,221184,223232,225280,227328,229376,231424,233472,235520,237568,239616,241664,243712,245760,247808,249856,251904,253952,256000,258048,260096,262144,264192,266240,268288,270336,272384,274432,276480,278528,280576,282624,284672,286720,288768,290816,292864,294912,296960,299008,301056,303104,305152,307200,309248,311296,313344,315392,317440,319488,321536,323584,325632,327680,329728,331776,333824,335872,337920,339968,342016,344064,346112,348160,350208,352256,354304,356352,358400,360448,362496,364544,366592,368640,370688,372736,374784,376832,378880,380928,382976,385024,387072,389120,391168,393216,395264,397312,399360,401408,403456,405504,407552,409600,411648,413696,415744,417792,419840,421888,423936,425984,428032,430080,432128,434176,436224,438272,440320,442368,444416,446464,448512,450560,452608,454656,456704,458752,460800,462848,464896,466944,468992,471040,473088,475136,477184,479232,481280,483328,485376,487424,489472,491520,493568,495616,497664,499712,501760,503808,505856,507904,509952,512000,514048,516096,518144,520192,522240,524288,526336,528384,530432,532480,534528,536576,538624,540672,542720,544768,546816,548864,550912,552960,555008,557056,559104,561152,563200,565248,567296,569344,571392,573440,575488,577536,579584,581632,583680,585728,587776,589824,591872,593920,595968,598016,600064,602112,604160,606208,608256,610304,612352,614400,616448,618496,620544,622592,624640,626688,628736,630784,632832,634880,636928,638976,641024,643072,645120,647168,649216,651264,653312,655360,657408,659456,661504,663552,665600,667648,669696,671744,673792,675840,677888,679936,681984,684032,686080,688128,690176,692224,694272,696320,698368,700416,702464,704512,706560,708608,710656,712704,714752,716800,718848,720896,722944,724992,727040,729088,731136,733184,735232,737280,739328,741376,743424,745472,747520,749568,751616,753664,755712,757760,759808,761856,763904,765952,768000,770048,772096,774144,776192,778240,780288,782336,784384,786432,788480,790528,792576,794624,796672,798720,800768,802816,804864,806912,808960,811008,813056,815104,817152,819200,821248,823296,825344,827392,829440,831488,833536,835584,837632,839680,841728,843776,845824,847872,849920,851968,854016,856064,858112,860160,862208,864256,866304,868352,870400,872448,874496,876544,878592,880640,882688,884736,886784,888832,890880,892928,894976,897024,899072,901120,903168,905216,907264,909312,911360,913408,915456,917504,919552,921600,923648,925696,927744,929792,931840,933888,935936,937984,940032,942080,944128,946176,948224,950272,952320,954368,956416,958464,960512,962560,964608,966656,968704,970752,972800,974848,976896,978944,980992,983040,985088,987136,989184,991232,993280,995328,997376,999424,1001472,1003520,1005568,1007616,1009664,1011712,1013760,1015808,1017856,1019904,1021952,1024000,1026048,1028096,1030144,1032192,1034240,1036288,1038336,1040384,1042432,1044480,1046528,1048576,1050624,1052672,1054720,1056768,1058816,1060864,1062912,1064960,1067008,1069056,1071104,1073152,1075200,1077248,1079296,1081344,1083392,1085440,1087488,1089536,1091584,1093632,1095680,1097728,1099776,1101824,1103872,1105920,1107968,1110016,1112064,1114112,1116160,1118208,1120256,1122304,1124352,1126400,1128448,1130496,1132544,1134592,1136640,1138688,1140736,1142784,1144832,1146880,1148928,1150976,1153024,1155072,1157120,1159168,1161216,1163264,1165312,1167360,1169408,1171456,1173504,1175552,1177600,1179648,1181696,1183744,1185792,1187840,1189888,1191936,1193984,1196032,1198080,1200128,1202176,1204224,1206272,1208320,1210368,1212416,1214464,1216512,1218560,1220608,1222656,1224704,1226752,1228800,1230848,1232896,1234944,1236992,1239040,1241088,1243136,1245184,1247232,1249280,1251328,1253376,1255424,1257472,1259520,1261568,1263616,1265664,1267712,1269760,1271808,1273856,1275904,1277952,1280000,1282048,1284096,1286144,1288192,1290240,1292288,1294336,1296384,1298432,1300480,1302528,1304576,1306624,1308672,1310720,1312768,1314816,1316864,1318912,1320960,1323008,1325056,1327104,1329152,1331200,1333248,1335296,1337344,1339392,1341440,1343488,1345536,1347584,1349632,1351680,1353728,1355776,1357824,1359872,1361920,1363968,1366016,1368064,1370112,1372160,1374208,1376256,1378304,1380352,1382400,1384448,1386496,1388544,1390592,1392640,1394688,1396736,1398784,1400832,1402880,1404928,1406976,1409024,1411072,1413120,1415168,1417216,1419264,1421312,1423360,1425408,1427456,1429504,1431552,1433600,1435648,1437696,1439744,1441792,1443840,1445888,1447936,1449984,1452032,1454080,1456128,1458176,1460224,1462272,1464320,1466368,1468416,1470464,1472512,1474560,1476608,1478656,1480704,1482752,1484800,1486848,1488896,1490944,1492992,1495040,1497088,1499136,1501184,1503232,1505280,1507328,1509376,1511424,1513472,1515520,1517568,1519616,1521664,1523712,1525760,1527808,1529856,1531904,1533952,1536000,1538048,1540096,1542144,1544192,1546240,1548288,1550336,1552384,1554432,1556480,1558528,1560576,1562624,1564672,1566720,1568768,1570816,1572864,1574912,1576960,1579008,1581056,1583104,1585152,1587200,1589248,1591296,1593344,1595392,1597440,1599488,1601536,1603584,1605632,1607680,1609728,1611776,1613824,1615872,1617920,1619968,1622016,1624064,1626112,1628160,1630208,1632256,1634304,1636352,1638400,1640448,1642496,1644544,1646592,1648640,1650688,1652736,1654784,1656832,1658880,1660928,1662976,1665024,1667072,1669120,1671168,1673216,1675264,1677312,1679360,1681408,1683456,1685504,1687552,1689600,1691648,1693696,1695744,1697792,1699840,1701888,1703936,1705984,1708032,1710080,1712128,1714176,1716224,1718272,1720320,1722368,1724416,1726464,1728512,1730560,1732608,1734656,1736704,1738752,1740800,1742848,1744896,1746944,1748992,1751040,1753088,1755136,1757184,1759232,1761280,1763328,1765376,1767424,1769472,1771520,1773568,1775616,1777664,1779712,1781760,1783808,1785856,1787904,1789952,1792000,1794048,1796096,1798144,1800192,1802240,1804288,1806336,1808384,1810432,1812480,1814528,1816576,1818624,1820672,1822720,1824768,1826816,1828864,1830912,1832960,1835008,1837056,1839104,1841152,1843200,1845248,1847296,1849344,1851392,1853440,1855488,1857536,1859584,1861632,1863680,1865728,1867776,1869824,1871872,1873920,1875968,1878016,1880064,1882112,1884160,1886208,1888256,1890304,1892352,1894400,1896448,1898496,1900544,1902592,1904640,1906688,1908736,1910784,1912832,1914880,1916928,1918976,1921024,1923072,1925120,1927168,1929216,1931264,1933312,1935360,1937408,1939456,1941504,1943552,1945600,1947648,1949696,1951744,1953792,1955840,1957888,1959936,1961984,1964032,1966080,1968128,1970176,1972224,1974272,1976320,1978368,1980416,1982464,1984512,1986560,1988608,1990656,1992704,1994752,1996800,1998848,2000896,2002944,2004992,2007040,2009088,2011136,2013184,2015232,2017280,2019328,2021376,2023424,2025472,2027520,2029568,2031616,2033664,2035712,2037760,2039808,2041856,2043904,2045952,2048000,2050048],\"xaxis\":\"x\",\"y\":[10.860301971435547,10.558669090270996,10.010625839233398,9.534117698669434,9.935297012329102,9.461849212646484,9.223172187805176,9.01360034942627,9.353340148925781,8.726322174072266,8.742284774780273,8.265664100646973,7.641320705413818,8.317676544189453,8.043746948242188,7.3299241065979,7.991220951080322,8.186636924743652,8.105855941772461,7.410560607910156,7.619266033172607,6.796214580535889,7.92996072769165,8.789250373840332,8.232284545898438,6.752226829528809,8.03692626953125,7.9820942878723145,7.02343225479126,7.26455545425415,7.60939359664917,6.361095428466797,7.810241222381592,7.519859313964844,6.359506607055664,6.690969944000244,7.03947639465332,8.642582893371582,7.3083882331848145,7.482540130615234,6.478151321411133,7.993393898010254,7.567636013031006,7.338930130004883,7.634160041809082,8.182567596435547,6.806530952453613,7.18835973739624,7.605836868286133,7.617521286010742,6.814747333526611,7.263164043426514,5.993180274963379,6.814472675323486,7.154027462005615,7.57787561416626,7.258118152618408,8.047391891479492,7.3452677726745605,5.755764484405518,7.515865325927734,7.198221683502197,6.419601917266846,7.3796916007995605,6.20729398727417,6.62772798538208,6.792105674743652,6.915416717529297,5.511806488037109,7.040285587310791,7.55073881149292,6.673848628997803,7.403979301452637,6.554353713989258,7.663980484008789,7.857184886932373,7.563797473907471,6.097377777099609,6.897757053375244,7.10666561126709,6.9759321212768555,6.473450183868408,6.9658942222595215,7.593484401702881,6.542275428771973,6.94868278503418,7.119614124298096,7.657328128814697,7.649937152862549,6.946231842041016,6.392210960388184,6.920166969299316,7.600008964538574,7.790980339050293,7.752291679382324,7.486147403717041,6.808527946472168,7.477141380310059,6.997023582458496,7.368753433227539,6.667194843292236,7.425207614898682,6.024899005889893,7.543452739715576,6.040322780609131,7.209690570831299,7.42641544342041,7.578118801116943,6.788506984710693,7.114970684051514,6.295576095581055,5.697904586791992,7.258980751037598,7.663369178771973,7.16348934173584,6.151810646057129,7.674416542053223,6.92622184753418,7.450777530670166,7.03510856628418,6.9767374992370605,7.488529205322266,7.215691089630127,7.121776103973389,7.297525405883789,7.455190181732178,6.585402011871338,6.388620853424072,6.44156551361084,6.685781955718994,7.143704414367676,7.417787551879883,5.733641147613525,6.878188610076904,6.927681922912598,6.437458038330078,6.107898712158203,7.1959123611450195,6.0115647315979,6.034859657287598,7.580105304718018,7.283094882965088,7.297804355621338,6.243110179901123,5.626992702484131,6.73784065246582,6.441674709320068,8.122906684875488,5.905703067779541,6.8497419357299805,7.289770603179932,7.268426895141602,7.2746992111206055,7.312319278717041,7.124835968017578,6.69378662109375,6.362903594970703,7.270887851715088,6.553894996643066,7.182300567626953,7.533312797546387,6.790870189666748,6.964409828186035,6.441807746887207,7.115615367889404,7.03117036819458,5.2996063232421875,7.153467178344727,5.722298622131348,7.080970764160156,5.631701469421387,7.599348545074463,6.38706636428833,7.203117847442627,7.245578289031982,6.65630578994751,7.051126956939697,7.546610355377197,6.608680248260498,6.853823661804199,6.754458904266357,6.720300674438477,6.748582363128662,4.896650314331055,7.547114849090576,6.558620929718018,6.920501708984375,6.661357402801514,7.295090198516846,7.212646007537842,7.684619426727295,5.162270545959473,6.975992202758789,6.995685577392578,6.784726619720459,6.798732757568359,7.1567301750183105,6.568859100341797,7.453400135040283,6.636582374572754,7.266475677490234,6.954992294311523,6.411581039428711,7.279386043548584,6.329058647155762,5.5832390785217285,6.238207817077637,7.159464359283447,7.089670658111572,7.081772804260254,7.059873104095459,7.232686519622803,6.758630752563477,6.532124996185303,7.512654781341553,6.949493885040283,6.389363765716553,7.0846686363220215,7.444119930267334,6.203991889953613,7.224967002868652,7.184366703033447,7.312071323394775,6.485525131225586,6.478879928588867,5.421188831329346,6.075878620147705,7.129185199737549,6.849398136138916,6.078650951385498,6.561210632324219,6.108699321746826,6.997525215148926,6.854953765869141,5.577433109283447,6.475827693939209,7.170844078063965,6.356395721435547,6.607156276702881,5.791802406311035,5.471877098083496,5.595681667327881,7.110945224761963,6.343651294708252,5.940224647521973,6.879827976226807,6.553097724914551,6.644942283630371,6.647491931915283,7.194187164306641,5.329249858856201,6.5985107421875,5.865883827209473,6.931343078613281,6.546063423156738,7.096142292022705,6.975421905517578,6.387837886810303,6.53986120223999,7.156613826751709,7.196218490600586,6.970693111419678,7.218640327453613,5.732707500457764,6.311952590942383,7.073349475860596,6.783454895019531,6.974732398986816,6.77838134765625,6.42447566986084,6.966734886169434,6.03459358215332,5.753026485443115,6.624990463256836,6.802176475524902,6.864750385284424,6.845145225524902,7.139463901519775,6.999388217926025,5.727364540100098,6.990334510803223,5.748346328735352,6.4262309074401855,6.256380558013916,6.9998698234558105,6.985994338989258,6.505524635314941,6.7394843101501465,6.767404079437256,7.075189590454102,6.685779094696045,5.691329002380371,6.693328380584717,6.67014741897583,5.910706996917725,6.464311122894287,6.435011386871338,7.650578498840332,6.593796253204346,6.965169429779053,6.107128143310547,6.449575901031494,6.2539825439453125,6.257673740386963,6.344833850860596,6.307720184326172,5.906643390655518,6.522736549377441,5.830878734588623,6.110285758972168,6.06380033493042,6.900402545928955,6.332468509674072,5.2819905281066895,6.067058563232422,6.116511821746826,6.03351354598999,6.5280256271362305,6.606076240539551,5.9351396560668945,6.751510143280029,6.923635005950928,6.8015313148498535,6.78061056137085,5.453446865081787,6.023611545562744,6.499387741088867,5.654852867126465,7.031008243560791,6.8134942054748535,6.802123546600342,6.266812801361084,6.395312309265137,6.712294101715088,6.02863073348999,6.589493751525879,6.966573715209961,5.960556983947754,6.403720855712891,6.855593204498291,6.758410453796387,6.035693645477295,6.264219760894775,6.968389987945557,7.17946195602417,5.643788814544678,7.0378241539001465,5.4616851806640625,6.868210315704346,7.201201915740967,6.240981578826904,6.873684406280518,5.442558288574219,6.440022945404053,6.594667434692383,7.197161674499512,5.985750198364258,5.701900005340576,5.630733489990234,6.723006248474121,7.011436939239502,6.57301664352417,6.377288818359375,6.809165954589844,6.034230709075928,6.764871120452881,6.113399505615234,6.550485134124756,6.402710914611816,6.611823081970215,6.841595649719238,5.835833549499512,6.173199653625488,6.32311487197876,6.199147701263428,5.791232109069824,6.753564357757568,6.368760108947754,6.492026329040527,6.172197341918945,6.587162971496582,6.426387786865234,6.527207851409912,5.751584053039551,6.256824493408203,6.8548102378845215,6.903064250946045,6.636432647705078,5.916758060455322,6.226014614105225,6.750131130218506,5.683041572570801,6.588019847869873,6.677070140838623,6.276010036468506,6.476827621459961,6.431723117828369,5.064056873321533,6.561606407165527,6.538302421569824,6.871793270111084,5.543502330780029,6.702789306640625,6.476027965545654,6.6695733070373535,6.96799898147583,5.062193870544434,6.8938212394714355,6.826789855957031,6.791561126708984,7.158283233642578,6.083188056945801,6.281136512756348,6.576849937438965,6.626672267913818,7.189568519592285,6.26201868057251,5.635047435760498,5.696661472320557,5.336979389190674,6.799833297729492,6.129302978515625,6.3491291999816895,6.5262131690979,7.0577545166015625,6.374166488647461,6.550516605377197,6.088181495666504,6.40852689743042,5.816067218780518,6.366161823272705,5.594695568084717,6.687566757202148,7.012472629547119,5.673819065093994,6.777829647064209,6.567508220672607,6.644207000732422,5.321937561035156,6.779867172241211,6.985942840576172,6.165423393249512,5.667593479156494,6.829540252685547,6.2861127853393555,5.316249370574951,5.855470180511475,5.33860445022583,6.377381801605225,6.5249762535095215,6.879714488983154,6.372623920440674,6.750439643859863,6.424778461456299,7.028292655944824,6.078324794769287,6.762481212615967,6.515964508056641,5.971428394317627,6.645633697509766,6.835143566131592,5.413219451904297,6.108758926391602,6.1391282081604,6.288865089416504,6.90709114074707,6.097844123840332,6.949990272521973,6.472819805145264,5.243885517120361,6.746312618255615,6.7654337882995605,6.585689067840576,6.5954365730285645,6.549580097198486,6.1877665519714355,5.7817559242248535,5.652416229248047,6.495050430297852,6.692127704620361,6.593299865722656,5.081721305847168,6.593079566955566,6.559086799621582,6.758780002593994,7.059959411621094,5.716184139251709,6.371801853179932,6.376967906951904,5.659743785858154,6.431994438171387,6.103333473205566,6.549016952514648,5.371052265167236,5.879424095153809,6.574393272399902,5.989671230316162,6.19647216796875,6.446158409118652,5.569386005401611,6.092051029205322,7.124127388000488,6.740438938140869,5.931512832641602,6.566296100616455,6.434192657470703,6.306012153625488,5.327273845672607,6.623347759246826,6.904051780700684,6.548275470733643,5.86425256729126,5.576560020446777,6.173104286193848,5.785899639129639,6.601572513580322,5.6448140144348145,5.295223712921143,6.158956050872803,6.165317535400391,6.878233909606934,5.683440685272217,6.848714828491211,6.073716163635254,6.724649906158447,6.334878921508789,6.579278469085693,5.092685699462891,6.562750339508057,5.81058931350708,6.621575355529785,6.879255294799805,5.39467716217041,7.082271575927734,6.5719122886657715,5.4614644050598145,6.163697242736816,5.461133003234863,6.169329643249512,6.234163761138916,6.343210697174072,5.791793346405029,5.694726943969727,6.136246681213379,6.108211040496826,6.041054725646973,5.529758453369141,6.506494045257568,5.919506549835205,6.181149959564209,5.907184600830078,6.455920696258545,5.29693078994751,5.738527774810791,6.7061614990234375,5.392673969268799,6.838134765625,5.996531009674072,6.178915977478027,5.957133769989014,5.4109883308410645,6.769015789031982,5.832162857055664,6.225521087646484,6.211503505706787,5.559903621673584,6.139289855957031,6.082295894622803,6.161879062652588,5.815490245819092,6.8305230140686035,6.405505657196045,5.707529544830322,5.842552185058594,5.186496257781982,6.576231479644775,6.472076416015625,5.623207092285156,6.6466264724731445,5.614886283874512,6.166575908660889,5.934268951416016,5.550079345703125,6.762407302856445,6.152293682098389,6.000232219696045,5.183602809906006,5.639004230499268,5.387418746948242,6.2490763664245605,6.2243332862854,6.677920818328857,5.985259056091309,6.594528675079346,6.4806294441223145,4.611690521240234,5.933086395263672,4.778149604797363,7.16059684753418,6.769087314605713,6.545405387878418,4.988596439361572,5.984415531158447,5.441843032836914,5.705813407897949,5.908013820648193,5.667555332183838,5.535074710845947,6.53688383102417,6.061832904815674,6.307494163513184,5.9360527992248535,6.4384446144104,5.473759174346924,6.318369388580322,6.59478235244751,6.06240701675415,6.4330244064331055,6.4090657234191895,7.1378350257873535,5.550604820251465,6.3944091796875,6.657074451446533,6.09999942779541,5.939814567565918,5.356346130371094,6.72329044342041,6.376232624053955,6.041956901550293,5.575747013092041,6.693106174468994,5.623856067657471,6.603500843048096,6.241672992706299,6.447749614715576,6.441227912902832,6.359440803527832,5.771117210388184,6.641005516052246,6.552849292755127,5.440950870513916,6.745148181915283,6.707870960235596,6.460810661315918,5.974265098571777,6.735474109649658,5.069273471832275,6.852532863616943,5.958487033843994,6.620229721069336,6.032578468322754,6.202413558959961,6.1067094802856445,5.786272048950195,6.476507186889648,5.334905624389648,6.387103080749512,6.7140984535217285,5.295062065124512,5.731989860534668,6.934628009796143,5.886474132537842,6.047281265258789,5.531027317047119,6.259624481201172,5.712533950805664,5.133908748626709,5.012686252593994,5.7255778312683105,5.80166482925415,6.773518085479736,6.034251689910889,5.908360004425049,6.581005096435547,5.458897590637207,6.260307312011719,6.000126838684082,5.040565490722656,5.633289813995361,6.274074554443359,6.074206829071045,6.554011821746826,5.55139684677124,5.611433982849121,6.202302932739258,5.932627201080322,6.350945472717285,5.507530212402344,6.159492015838623,5.005768775939941,5.866588115692139,6.475925445556641,6.32281494140625,6.533336639404297,6.573014736175537,6.609882831573486,7.25452995300293,6.411787033081055,6.15435791015625,5.598108291625977,6.3740763664245605,6.052282810211182,6.78073787689209,5.339473247528076,6.656380653381348,5.086986064910889,5.047558784484863,4.894546985626221,5.933548927307129,6.839876174926758,5.98504638671875,4.813537120819092,5.6479573249816895,6.481342315673828,6.710541725158691,5.939772129058838,6.344861030578613,6.522456645965576,5.231003284454346,6.617959976196289,5.530948638916016,6.0634002685546875,5.10380220413208,5.872527599334717,6.687047004699707,5.061882019042969,6.354995250701904,5.875914096832275,5.609393119812012,5.724611759185791,5.211040019989014,6.378485202789307,5.577101230621338,5.56796407699585,5.099602699279785,6.549997329711914,5.917593955993652,6.301352024078369,6.047785758972168,6.806419849395752,5.259117603302002,6.132932662963867,6.067479133605957,5.920977592468262,6.565421104431152,6.234935760498047,4.965314865112305,6.060481071472168,6.393029689788818,5.724167346954346,6.64398193359375,5.339052677154541,6.029218673706055,5.8236212730407715,6.112518310546875,6.242260932922363,5.368574619293213,6.719598770141602,6.402144908905029,6.340591907501221,6.303947448730469,6.175937652587891,5.932205677032471,6.493907928466797,5.783843994140625,5.661386489868164,6.495619773864746,5.76931619644165,5.694956302642822,6.551372528076172,5.008810997009277,5.019659042358398,5.783591270446777,6.070546627044678,5.448563098907471,6.297511100769043,4.762655258178711,5.732369422912598,5.838732719421387,5.574128150939941,5.805910587310791,6.657123565673828,6.200189113616943,6.234944820404053,5.937824726104736,6.351794719696045,5.651734828948975,6.106949329376221,4.942287445068359,6.2249369621276855,5.949487209320068,5.6548285484313965,5.810013771057129,5.99784517288208,6.667746067047119,5.934925079345703,6.1816887855529785,6.152261734008789,6.1778669357299805,5.392158031463623,5.733408451080322,5.6564741134643555,5.922253608703613,6.4491167068481445,6.250338077545166,6.008471488952637,5.550739288330078,6.096260070800781,6.017374038696289,5.567146301269531,6.118741512298584,6.851099491119385,6.379087448120117,6.280828952789307,5.742415904998779,6.260411262512207,6.697079658508301,4.645105361938477,6.1155266761779785,6.247791767120361,6.111467361450195,5.484246730804443,6.236369609832764,5.9209747314453125,6.057094573974609,5.871359348297119,6.4534807205200195,5.360917568206787,5.72355318069458,5.091026306152344,5.550237655639648,5.3423991203308105,6.479997158050537,6.576565742492676,6.069416522979736,5.534485340118408,5.9676513671875,5.951220989227295,6.121552467346191,5.917789936065674,6.431272029876709,6.032625198364258,6.334909439086914,5.668815612792969,5.79232931137085,5.670017242431641,5.589811325073242,5.811044216156006,5.816509246826172,6.349242210388184,6.160610198974609,5.906307697296143,6.295799732208252,6.343445777893066,6.178195953369141,5.97856330871582,4.729189395904541,5.967781066894531,6.348791122436523,4.836503505706787,5.549200057983398,4.797698497772217,6.179803371429443,6.233519077301025,6.080811023712158,5.711197853088379,5.095273494720459,5.535083293914795,5.185543060302734,5.888796806335449,5.659970760345459,5.784579277038574,5.534470081329346,6.524552345275879,5.465388774871826,5.698366165161133,5.105620384216309,5.807820796966553,5.354104042053223,5.897741317749023,5.988034725189209,4.503979682922363,6.807337284088135,5.790120601654053,6.1518635749816895,6.308647632598877,4.936069011688232,5.850616931915283,6.037449836730957,5.853507041931152,5.77784538269043,5.754405975341797,6.318171501159668,6.074901103973389,6.216838836669922,6.331904888153076,5.309866428375244,6.000636100769043,6.381753921508789,6.526237487792969,5.493170261383057,5.327292442321777,5.8351593017578125,5.986975193023682,5.887758731842041,5.947628974914551,5.6412272453308105,5.844040870666504,6.349274635314941,5.626133918762207,5.613784313201904,5.861568927764893,6.034397125244141,6.38456392288208,5.991281032562256,5.815762042999268,6.106187343597412,6.077724456787109,6.6019392013549805,6.581410884857178,4.311973571777344,6.088840007781982,6.078784942626953,5.920717716217041,6.466136932373047,6.117687702178955,6.15886116027832,6.3979315757751465,5.800539493560791,5.112084865570068,5.877331733703613,5.354435443878174,6.56104040145874,5.87701940536499,5.863763809204102,5.6028947830200195,5.562103271484375,5.757908344268799,6.2713494300842285,6.093207359313965,6.0119853019714355,5.376500606536865,6.112300395965576,6.372137069702148,6.06150484085083,5.661655902862549,5.4538984298706055,6.699355125427246,5.692776203155518,6.216505527496338,5.170968532562256,6.2571492195129395,5.798459053039551,5.005188941955566,5.4644694328308105,5.780699729919434,5.785229206085205,5.359696865081787,6.46621561050415,5.798621654510498,6.225507736206055,5.800431251525879,6.548908710479736,5.215789318084717,5.970525741577148,5.574824810028076,4.615332126617432,6.460248947143555,6.402869701385498,5.935418128967285,4.849767684936523,5.447293758392334,6.765388011932373,5.734405994415283,4.6643218994140625,6.258786201477051,6.4086737632751465,5.79335880279541,6.251597881317139,4.995948791503906,6.127970218658447,5.99060583114624,6.419496536254883,6.930622577667236,6.360290050506592,5.883601665496826,6.0530805587768555,5.446792125701904,5.780511379241943,6.819052696228027,6.130094528198242,5.711724281311035,5.687847137451172,5.755163192749023,5.587241172790527,6.218040943145752,5.971580505371094,4.622128486633301,6.144931316375732,5.252673149108887,5.935065746307373,5.243071556091309],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tokens\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Training curve for my tiny demo model!\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fe6d38d1-f141-46a1-a9d6-2c7063fbd468');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Crée un graphique de ligne avec la perte en fonction du nombre de jetons traités\n",
        "px.line(y=losses, x=np.arange(len(losses))*(model_cfg.n_ctx * batch_size), labels={\"y\":\"Perte\", \"x\":\"Jetons\"}, title=\"Courbe d'entraînement pour mon petit modèle de démonstration !\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La courbe montre que l'erreur du modèle diminue au fur et à mesure qu'il est entraîné sur plus de données. Cela signifie que le modèle apprend à identifier des modèles dans les données et à faire des prédictions plus précises.\n",
        "\n",
        "La courbe montre également que l'erreur se stabilise après un certain nombre d'étapes d'entraînement. Cela signifie que le modèle ne s'améliore plus significativement avec un entraînement supplémentaire. C'est un phénomène courant en apprentissage automatique, et cela indique souvent que le modèle a tiré le maximum de leçons possible des données d'entraînement."
      ],
      "metadata": {
        "id": "D8sbP88nEaRT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZ63mwwoEivg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}